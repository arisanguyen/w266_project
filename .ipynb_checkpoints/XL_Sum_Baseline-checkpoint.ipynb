{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d870553",
   "metadata": {},
   "source": [
    "**Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dacdaf3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "\n",
    "#let's make longer output readable without horizontal scrolling\n",
    "from pprint import pprint\n",
    "\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f29e293",
   "metadata": {},
   "source": [
    "**Necessary Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f96edd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rouge = evaluate.load('rouge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "312bbea0-61d2-4582-98ff-a7cf52f2dbb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chrf = evaluate.load(\"chrf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586a6d00",
   "metadata": {},
   "source": [
    "**Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec6c665e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset xlsum (/home/ubuntu/.cache/huggingface/datasets/csebuetnlp___xlsum/english/2.0.0/518ab0af76048660bcc2240ca6e8692a977c80e384ffb18fdddebaca6daebdce)\n",
      "100%|████████████████████████████████████████████| 3/3 [00:00<00:00, 304.36it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"csebuetnlp/xlsum\", \"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "111f7985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "306522"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EDA\n",
    "len(dataset['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f538fd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'uk-scotland-highlands-islands-11069985',\n",
       " 'url': 'https://www.bbc.com/news/uk-scotland-highlands-islands-11069985',\n",
       " 'title': 'Huge tidal turbine installed at Orkney test site',\n",
       " 'summary': 'The massive tidal turbine AK1000 has been installed in 35m (114.8ft) of water at a test site in Orkney.',\n",
       " 'text': 'Atlantis Resources unveiled the marine energy device at Invergordon ahead of it being shipped to Kirkwall. Trials on the device will now be run at the European Marine Energy Centre test site off Eday. The device stands 22.5m (73ft) tall, weighs 1,300 tonnes and has two sets of blades on a single unit. It could generate enough power for 1,000 homes.'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EDA\n",
    "dataset['train'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "296f3f54-85c7-4446-ae73-fa54ac3123a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>235420</th>\n",
       "      <td>235420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172024</th>\n",
       "      <td>172024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253546</th>\n",
       "      <td>253546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224954</th>\n",
       "      <td>224954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214134</th>\n",
       "      <td>214134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index\n",
       "235420  235420\n",
       "172024  172024\n",
       "253546  253546\n",
       "224954  224954\n",
       "214134  214134"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = pd.DataFrame({\"index\": list(range(len(dataset['train'])))})\n",
    "sample_index = index.sample(n=2000, replace=False, random_state=1004)\n",
    "sample_index[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6656d7bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "id = []\n",
    "url = []\n",
    "title = []\n",
    "article = []\n",
    "summary = []\n",
    "\n",
    "for i in sample_index[\"index\"]:\n",
    "    id.append(dataset[\"train\"][i]['id'])\n",
    "    url.append(dataset[\"train\"][i]['url'])\n",
    "    title.append(dataset[\"train\"][i]['title'])\n",
    "    summary.append(dataset[\"train\"][i]['summary'])\n",
    "    article.append(dataset[\"train\"][i]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66def3a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>article</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>uk-england-cornwall-55191422</td>\n",
       "      <td>https://www.bbc.com/news/uk-england-cornwall-5...</td>\n",
       "      <td>Care home manager: 'It felt like we were losin...</td>\n",
       "      <td>By Rebecca Ricks &amp; Johnny O'SheaBBC Spotlight ...</td>\n",
       "      <td>During the spring, at the height of the Covid-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>uk-43893709</td>\n",
       "      <td>https://www.bbc.com/news/uk-43893709</td>\n",
       "      <td>Tafida Raqeeb: Who decides the care of sick ch...</td>\n",
       "      <td>By Rachel SchraerBBC Reality Check So, why did...</td>\n",
       "      <td>The parents of five-year-old Tafida Raqeeb, wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>uk-politics-57050659</td>\n",
       "      <td>https://www.bbc.com/news/uk-politics-57050659</td>\n",
       "      <td>Labour reshuffle: Anneliese Dodds out in Starm...</td>\n",
       "      <td>Anneliese Dodds will now become the Labour Par...</td>\n",
       "      <td>Sir Keir Starmer has sacked his shadow chancel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>entertainment-arts-38221420</td>\n",
       "      <td>https://www.bbc.com/news/entertainment-arts-38...</td>\n",
       "      <td>Vinyl sales made more than downloads last week</td>\n",
       "      <td>By Mark SavageBBC Music reporter Vinyl sales m...</td>\n",
       "      <td>More money was spent on vinyl than downloaded ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entertainment-arts-24046991</td>\n",
       "      <td>https://www.bbc.com/news/entertainment-arts-24...</td>\n",
       "      <td>Pirates of the Caribbean sequel delayed</td>\n",
       "      <td>Disney's Pirates of The Caribbean: Dead Men Te...</td>\n",
       "      <td>The next Pirates of the Caribbean film has bee...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             id  \\\n",
       "0  uk-england-cornwall-55191422   \n",
       "1                   uk-43893709   \n",
       "2          uk-politics-57050659   \n",
       "3   entertainment-arts-38221420   \n",
       "4   entertainment-arts-24046991   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.bbc.com/news/uk-england-cornwall-5...   \n",
       "1               https://www.bbc.com/news/uk-43893709   \n",
       "2      https://www.bbc.com/news/uk-politics-57050659   \n",
       "3  https://www.bbc.com/news/entertainment-arts-38...   \n",
       "4  https://www.bbc.com/news/entertainment-arts-24...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Care home manager: 'It felt like we were losin...   \n",
       "1  Tafida Raqeeb: Who decides the care of sick ch...   \n",
       "2  Labour reshuffle: Anneliese Dodds out in Starm...   \n",
       "3     Vinyl sales made more than downloads last week   \n",
       "4            Pirates of the Caribbean sequel delayed   \n",
       "\n",
       "                                             article  \\\n",
       "0  By Rebecca Ricks & Johnny O'SheaBBC Spotlight ...   \n",
       "1  By Rachel SchraerBBC Reality Check So, why did...   \n",
       "2  Anneliese Dodds will now become the Labour Par...   \n",
       "3  By Mark SavageBBC Music reporter Vinyl sales m...   \n",
       "4  Disney's Pirates of The Caribbean: Dead Men Te...   \n",
       "\n",
       "                                             summary  \n",
       "0  During the spring, at the height of the Covid-...  \n",
       "1  The parents of five-year-old Tafida Raqeeb, wh...  \n",
       "2  Sir Keir Starmer has sacked his shadow chancel...  \n",
       "3  More money was spent on vinyl than downloaded ...  \n",
       "4  The next Pirates of the Caribbean film has bee...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'id': id, 'url': url, \"title\": title, 'article': article, 'summary': summary}\n",
    "df = pd.DataFrame(data=d)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a0a517",
   "metadata": {},
   "source": [
    "**Baseline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c151fd43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "1999\n"
     ]
    }
   ],
   "source": [
    "base_r1 = []\n",
    "base_r2 = []\n",
    "base_rL = []\n",
    "base_rLs = []\n",
    "base_chrf = []\n",
    "\n",
    "for i in range(len(df['article'])): \n",
    "    \n",
    "    \n",
    "    # first three sentences \n",
    "    candidate = \". \".join(df[\"article\"][i].split('. ')[0:3]) + \".\"\n",
    "    candidate = [candidate]\n",
    "    \n",
    "    ref = [df['summary'][i]]\n",
    "    \n",
    "    results = rouge.compute(predictions=candidate,\n",
    "                            references= ref)\n",
    "    \n",
    "    results2 = chrf.compute(predictions=candidate,\n",
    "                            references= ref)\n",
    "    \n",
    "    base_r1.append(results['rouge1'])\n",
    "    base_r2.append(results['rouge2'])\n",
    "    base_rL.append(results['rougeL'])\n",
    "    base_rLs.append(results['rougeLsum'])\n",
    "    \n",
    "    base_chrf.append(results2['score'])\n",
    "    \n",
    "    if i in np.arange(0, 2000, 100):\n",
    "        data = {'rouge1': base_r1, 'rouge2': base_r2, 'rogueL': base_rL, 'rogueLs': base_rLs, 'chrf': base_chrf}\n",
    "        scores = pd.DataFrame(data)\n",
    "        scores.to_csv(r'base_scores.csv', index=False)\n",
    "        print(i)\n",
    "        \n",
    "data = {'rouge1': base_r1, 'rouge2': base_r2, 'rogueL': base_rL, 'rogueLs': base_rLs, 'chrf': base_chrf}\n",
    "scores = pd.DataFrame(data)\n",
    "scores.to_csv(r'base_scores.csv', index=False)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "888889b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average of all 2000\n",
      "rouge1 average:  0.18615699708157343\n",
      "rouge2 average:  0.02667181874604599\n",
      "rougeL average:  0.12080542692742077\n",
      "rougeLs average: 0.12080542692742077\n",
      "chrf average: 26.710645519890537\n"
     ]
    }
   ],
   "source": [
    "print(\"Average of all 2000\")\n",
    "print('rouge1 average: ', np.mean(base_r1))\n",
    "print('rouge2 average: ', np.mean(base_r2))\n",
    "print('rougeL average: ', np.mean(base_rL))\n",
    "print('rougeLs average:', np.mean(base_rLs))\n",
    "print('chrf average:', np.mean(base_chrf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80bd6a76-3a9b-408c-aac8-ad3de85917db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average of First 1000\n",
      "rouge1 average:  0.18572856885833472\n",
      "rouge2 average:  0.025796662812245914\n",
      "rougeL average:  0.12019463217968686\n",
      "rougeLs average: 0.12019463217968686\n",
      "chrf average: 26.625614296560503\n"
     ]
    }
   ],
   "source": [
    "print(\"Average of First 1000\")\n",
    "print('rouge1 average: ', np.mean(base_r1[:1000]))\n",
    "print('rouge2 average: ', np.mean(base_r2[:1000]))\n",
    "print('rougeL average: ', np.mean(base_rL[:1000]))\n",
    "print('rougeLs average:', np.mean(base_rLs[:1000]))\n",
    "print('chrf average:', np.mean(base_chrf[:1000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "84cce401-63ca-405d-a19a-ac5ee4821c6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average of Last 1000\n",
      "rouge1 average:  0.18658542530481215\n",
      "rouge2 average:  0.027546974679846067\n",
      "rougeL average:  0.12141622167515467\n",
      "rougeLs average: 0.12141622167515467\n",
      "chrf average: 26.795676743220575\n"
     ]
    }
   ],
   "source": [
    "print(\"Average of Last 1000\")\n",
    "print('rouge1 average: ', np.mean(base_r1[1000:]))\n",
    "print('rouge2 average: ', np.mean(base_r2[1000:]))\n",
    "print('rougeL average: ', np.mean(base_rL[1000:]))\n",
    "print('rougeLs average:', np.mean(base_rLs[1000:]))\n",
    "print('chrf average:', np.mean(base_chrf[1000:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a07eaf-d714-4eb8-8a30-7b7ce3d67568",
   "metadata": {},
   "source": [
    "**Baseline by Top 5 Largest Categories**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "166c0e3e-5f58-4bdd-b736-2a82a8e2ebba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_indices(list_to_check, item_to_find):\n",
    "    indices = []\n",
    "    for idx, value in enumerate(list_to_check):\n",
    "        if value == item_to_find:\n",
    "            indices.append(idx)\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "00575bc4-9300-4039-a966-5ca140ad5904",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "categories = []\n",
    "\n",
    "for i in range(len(dataset['train'])):\n",
    "    cat = dataset['train'][i]['id']\n",
    "    result = re.sub('\\d','',cat)[:-1]\n",
    "    result = result.split('-')[0].split('.')[0]\n",
    "    categories.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e36b9ce-d5db-412d-be54-a2a8f4cc2794",
   "metadata": {},
   "source": [
    "**Category 1: uk**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1e47be26-34e7-4e14-8857-42e216988554",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>103144</th>\n",
       "      <td>184549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135979</th>\n",
       "      <td>242139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122918</th>\n",
       "      <td>219346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41576</th>\n",
       "      <td>76571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23230</th>\n",
       "      <td>44271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index\n",
       "103144  184549\n",
       "135979  242139\n",
       "122918  219346\n",
       "41576    76571\n",
       "23230    44271"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uk = find_indices(categories, 'uk')\n",
    "index = pd.DataFrame({\"index\": uk})\n",
    "sample_index = index.sample(n=1000, replace=False, random_state=1004)\n",
    "sample_index[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "95d655b3-88eb-4aba-8477-ea1369be9662",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "id = []\n",
    "url = []\n",
    "title = []\n",
    "article = []\n",
    "summary = []\n",
    "\n",
    "for i in sample_index[\"index\"]:\n",
    "    id.append(dataset[\"train\"][i]['id'])\n",
    "    url.append(dataset[\"train\"][i]['url'])\n",
    "    title.append(dataset[\"train\"][i]['title'])\n",
    "    summary.append(dataset[\"train\"][i]['summary'])\n",
    "    article.append(dataset[\"train\"][i]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "674339b5-bb42-4883-96da-e4ba7565ee2e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>article</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>uk-england-bristol-51032231</td>\n",
       "      <td>https://www.bbc.com/news/uk-england-bristol-51...</td>\n",
       "      <td>Author Emily Koch: 'I'm not angry at the drive...</td>\n",
       "      <td>Emily Koch suffered two broken legs and ligame...</td>\n",
       "      <td>A woman left seriously injured after being hit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>uk-england-birmingham-54264699</td>\n",
       "      <td>https://www.bbc.com/news/uk-england-birmingham...</td>\n",
       "      <td>Blind TikTok star Lucy Edwards says reaction t...</td>\n",
       "      <td>Lucy Edwards, who became Radio 1's first blind...</td>\n",
       "      <td>A blind vlogger hopes her TikTok videos on liv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>uk-england-london-16091997</td>\n",
       "      <td>https://www.bbc.com/news/uk-england-london-160...</td>\n",
       "      <td>Bendy bus makes final journey for Transport fo...</td>\n",
       "      <td>The vehicles were used on 12 routes over the p...</td>\n",
       "      <td>The last of London's bendy buses was taken off...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>uk-england-norfolk-54058083</td>\n",
       "      <td>https://www.bbc.com/news/uk-england-norfolk-54...</td>\n",
       "      <td>Horsey seals: Volunteers remove rubber ring fr...</td>\n",
       "      <td>Four members of Friends of Horsey Seals netted...</td>\n",
       "      <td>Volunteers have helped capture a \"feisty\" seal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>uk-scotland-edinburgh-east-fife-28838287</td>\n",
       "      <td>https://www.bbc.com/news/uk-scotland-edinburgh...</td>\n",
       "      <td>Tim Vine wins funniest Edinburgh Fringe joke a...</td>\n",
       "      <td>He won with the one-liner: \"I decided to sell ...</td>\n",
       "      <td>A joke by comedian Tim Vine about a vacuum cle...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         id  \\\n",
       "0               uk-england-bristol-51032231   \n",
       "1            uk-england-birmingham-54264699   \n",
       "2                uk-england-london-16091997   \n",
       "3               uk-england-norfolk-54058083   \n",
       "4  uk-scotland-edinburgh-east-fife-28838287   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.bbc.com/news/uk-england-bristol-51...   \n",
       "1  https://www.bbc.com/news/uk-england-birmingham...   \n",
       "2  https://www.bbc.com/news/uk-england-london-160...   \n",
       "3  https://www.bbc.com/news/uk-england-norfolk-54...   \n",
       "4  https://www.bbc.com/news/uk-scotland-edinburgh...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Author Emily Koch: 'I'm not angry at the drive...   \n",
       "1  Blind TikTok star Lucy Edwards says reaction t...   \n",
       "2  Bendy bus makes final journey for Transport fo...   \n",
       "3  Horsey seals: Volunteers remove rubber ring fr...   \n",
       "4  Tim Vine wins funniest Edinburgh Fringe joke a...   \n",
       "\n",
       "                                             article  \\\n",
       "0  Emily Koch suffered two broken legs and ligame...   \n",
       "1  Lucy Edwards, who became Radio 1's first blind...   \n",
       "2  The vehicles were used on 12 routes over the p...   \n",
       "3  Four members of Friends of Horsey Seals netted...   \n",
       "4  He won with the one-liner: \"I decided to sell ...   \n",
       "\n",
       "                                             summary  \n",
       "0  A woman left seriously injured after being hit...  \n",
       "1  A blind vlogger hopes her TikTok videos on liv...  \n",
       "2  The last of London's bendy buses was taken off...  \n",
       "3  Volunteers have helped capture a \"feisty\" seal...  \n",
       "4  A joke by comedian Tim Vine about a vacuum cle...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'id': id, 'url': url, \"title\": title, 'article': article, 'summary': summary}\n",
    "df = pd.DataFrame(data=d)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1d3e3888-2cd3-47c0-ab04-cfa209cec560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "999\n"
     ]
    }
   ],
   "source": [
    "base_r1 = []\n",
    "base_r2 = []\n",
    "base_rL = []\n",
    "base_rLs = []\n",
    "base_chrf = []\n",
    "\n",
    "for i in range(len(df['article'])): \n",
    "    \n",
    "    \n",
    "    # first three sentences \n",
    "    candidate = \". \".join(df[\"article\"][i].split('. ')[0:3]) + \".\"\n",
    "    candidate = [candidate]\n",
    "    \n",
    "    ref = [df['summary'][i]]\n",
    "    \n",
    "    results = rouge.compute(predictions=candidate,\n",
    "                            references= ref)\n",
    "    \n",
    "    results2 = chrf.compute(predictions=candidate,\n",
    "                            references= ref)\n",
    "    \n",
    "    base_r1.append(results['rouge1'])\n",
    "    base_r2.append(results['rouge2'])\n",
    "    base_rL.append(results['rougeL'])\n",
    "    base_rLs.append(results['rougeLsum'])\n",
    "    \n",
    "    base_chrf.append(results2['score'])\n",
    "    \n",
    "    if i in np.arange(0, 2000, 100):\n",
    "        data = {'rouge1': base_r1, 'rouge2': base_r2, 'rogueL': base_rL, 'rogueLs': base_rLs, 'chrf': base_chrf}\n",
    "        scores = pd.DataFrame(data)\n",
    "        scores.to_csv(r'base_scores_uk.csv', index=False)\n",
    "        print(i)\n",
    "        \n",
    "data = {'rouge1': base_r1, 'rouge2': base_r2, 'rogueL': base_rL, 'rogueLs': base_rLs, 'chrf': base_chrf}\n",
    "scores = pd.DataFrame(data)\n",
    "scores.to_csv(r'base_scores_uk.csv', index=False)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6b959c5d-fe1b-45b4-936f-12ed993daa54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rouge1 average:  0.18939253006007692\n",
      "rouge2 average:  0.027133586978308793\n",
      "rougeL average:  0.12278381086366534\n",
      "rougeLs average: 0.12278381086366534\n",
      "chrf average: 26.572484469570067\n"
     ]
    }
   ],
   "source": [
    "print('rouge1 average: ', np.mean(base_r1))\n",
    "print('rouge2 average: ', np.mean(base_r2))\n",
    "print('rougeL average: ', np.mean(base_rL))\n",
    "print('rougeLs average:', np.mean(base_rLs))\n",
    "print('chrf average:', np.mean(base_chrf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a961a3a-826a-4cb3-9b85-e903e624e30d",
   "metadata": {},
   "source": [
    "**Category 2: world**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "08636602-5dca-4af5-8159-e29985ed7c88",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38266</th>\n",
       "      <td>209050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5910</th>\n",
       "      <td>25805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14047</th>\n",
       "      <td>71645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23996</th>\n",
       "      <td>127936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25699</th>\n",
       "      <td>137681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        index\n",
       "38266  209050\n",
       "5910    25805\n",
       "14047   71645\n",
       "23996  127936\n",
       "25699  137681"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_inx = find_indices(categories, 'world')\n",
    "index = pd.DataFrame({\"index\": cat_inx})\n",
    "sample_index = index.sample(n=1000, replace=False, random_state=1004)\n",
    "sample_index[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e575dffd-6525-408f-885c-41c71c123c8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "id = []\n",
    "url = []\n",
    "title = []\n",
    "article = []\n",
    "summary = []\n",
    "\n",
    "for i in sample_index[\"index\"]:\n",
    "    id.append(dataset[\"train\"][i]['id'])\n",
    "    url.append(dataset[\"train\"][i]['url'])\n",
    "    title.append(dataset[\"train\"][i]['title'])\n",
    "    summary.append(dataset[\"train\"][i]['summary'])\n",
    "    article.append(dataset[\"train\"][i]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "152a37f6-f8ea-4020-9305-95b2d3d94915",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>article</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>world-asia-53847400</td>\n",
       "      <td>https://www.bbc.com/news/world-asia-53847400</td>\n",
       "      <td>Kim Jong-un gives sister Yo-jong 'more respons...</td>\n",
       "      <td>Mr Kim still maintains \"absolute authority\", b...</td>\n",
       "      <td>North Korean leader Kim Jong-un has delegated ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>world-europe-guernsey-18129181</td>\n",
       "      <td>https://www.bbc.com/news/world-europe-guernsey...</td>\n",
       "      <td>Guernsey overgrown trees prompt road crash fears</td>\n",
       "      <td>Overgrown bushes and trees could result in peo...</td>\n",
       "      <td>Residents are being urged to trim vegetation o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>world-africa-44629681</td>\n",
       "      <td>https://www.bbc.co.uk/news/world-africa-44629681</td>\n",
       "      <td>Bringing Gay Pride to Africa's last absolute m...</td>\n",
       "      <td>And anyone doubting the determination needed t...</td>\n",
       "      <td>Africa's last absolute monarchy is holding its...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>world-asia-41840069</td>\n",
       "      <td>https://www.bbc.com/news/world-asia-41840069</td>\n",
       "      <td>Pakistan polygamy: Lahore man jailed over unap...</td>\n",
       "      <td>The court in Lahore also ordered Shahzad Saqib...</td>\n",
       "      <td>A Pakistan court has jailed a man for six mont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>world-europe-guernsey-13052445</td>\n",
       "      <td>https://www.bbc.com/news/world-europe-guernsey...</td>\n",
       "      <td>Alternative recycling bank site proposed</td>\n",
       "      <td>The old facility at Manor Stores closed last y...</td>\n",
       "      <td>Work is continuing to try to find a permanent ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               id  \\\n",
       "0             world-asia-53847400   \n",
       "1  world-europe-guernsey-18129181   \n",
       "2           world-africa-44629681   \n",
       "3             world-asia-41840069   \n",
       "4  world-europe-guernsey-13052445   \n",
       "\n",
       "                                                 url  \\\n",
       "0       https://www.bbc.com/news/world-asia-53847400   \n",
       "1  https://www.bbc.com/news/world-europe-guernsey...   \n",
       "2   https://www.bbc.co.uk/news/world-africa-44629681   \n",
       "3       https://www.bbc.com/news/world-asia-41840069   \n",
       "4  https://www.bbc.com/news/world-europe-guernsey...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Kim Jong-un gives sister Yo-jong 'more respons...   \n",
       "1   Guernsey overgrown trees prompt road crash fears   \n",
       "2  Bringing Gay Pride to Africa's last absolute m...   \n",
       "3  Pakistan polygamy: Lahore man jailed over unap...   \n",
       "4           Alternative recycling bank site proposed   \n",
       "\n",
       "                                             article  \\\n",
       "0  Mr Kim still maintains \"absolute authority\", b...   \n",
       "1  Overgrown bushes and trees could result in peo...   \n",
       "2  And anyone doubting the determination needed t...   \n",
       "3  The court in Lahore also ordered Shahzad Saqib...   \n",
       "4  The old facility at Manor Stores closed last y...   \n",
       "\n",
       "                                             summary  \n",
       "0  North Korean leader Kim Jong-un has delegated ...  \n",
       "1  Residents are being urged to trim vegetation o...  \n",
       "2  Africa's last absolute monarchy is holding its...  \n",
       "3  A Pakistan court has jailed a man for six mont...  \n",
       "4  Work is continuing to try to find a permanent ...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'id': id, 'url': url, \"title\": title, 'article': article, 'summary': summary}\n",
    "df = pd.DataFrame(data=d)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a1de4c-11f4-4e03-8e8e-0648d9e966d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "base_r1 = []\n",
    "base_r2 = []\n",
    "base_rL = []\n",
    "base_rLs = []\n",
    "base_chrf = []\n",
    "\n",
    "for i in range(len(df['article'])): \n",
    "    \n",
    "    \n",
    "    # first three sentences \n",
    "    candidate = \". \".join(df[\"article\"][i].split('. ')[0:3]) + \".\"\n",
    "    candidate = [candidate]\n",
    "    \n",
    "    ref = [df['summary'][i]]\n",
    "    \n",
    "    results = rouge.compute(predictions=candidate,\n",
    "                            references= ref)\n",
    "    \n",
    "    results2 = chrf.compute(predictions=candidate,\n",
    "                            references= ref)\n",
    "    \n",
    "    base_r1.append(results['rouge1'])\n",
    "    base_r2.append(results['rouge2'])\n",
    "    base_rL.append(results['rougeL'])\n",
    "    base_rLs.append(results['rougeLsum'])\n",
    "    \n",
    "    base_chrf.append(results2['score'])\n",
    "    \n",
    "    if i in np.arange(0, 2000, 100):\n",
    "        data = {'rouge1': base_r1, 'rouge2': base_r2, 'rogueL': base_rL, 'rogueLs': base_rLs, 'chrf': base_chrf}\n",
    "        scores = pd.DataFrame(data)\n",
    "        scores.to_csv(r'base_scores_world.csv', index=False)\n",
    "        print(i)\n",
    "        \n",
    "data = {'rouge1': base_r1, 'rouge2': base_r2, 'rogueL': base_rL, 'rogueLs': base_rLs, 'chrf': base_chrf}\n",
    "scores = pd.DataFrame(data)\n",
    "scores.to_csv(r'base_scores_world.csv', index=False)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c105de6-5a55-4487-9531-17496769c30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('rouge1 average: ', np.mean(base_r1))\n",
    "print('rouge2 average: ', np.mean(base_r2))\n",
    "print('rougeL average: ', np.mean(base_rL))\n",
    "print('rougeLs average:', np.mean(base_rLs))\n",
    "print('chrf average:', np.mean(base_chrf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395f61ba-a5a9-4ff2-81e0-26657a95b508",
   "metadata": {},
   "source": [
    "**Category 3: business**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe5e05c-78c9-4156-97f7-5ee537d09be0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cat_inx = find_indices(categories, 'business')\n",
    "index = pd.DataFrame({\"index\": cat_inx})\n",
    "sample_index = index.sample(n=1000, replace=False, random_state=1004)\n",
    "sample_index[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d639e9-3fb8-4738-84e9-70678b90e52c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "id = []\n",
    "url = []\n",
    "title = []\n",
    "article = []\n",
    "summary = []\n",
    "\n",
    "for i in sample_index[\"index\"]:\n",
    "    id.append(dataset[\"train\"][i]['id'])\n",
    "    url.append(dataset[\"train\"][i]['url'])\n",
    "    title.append(dataset[\"train\"][i]['title'])\n",
    "    summary.append(dataset[\"train\"][i]['summary'])\n",
    "    article.append(dataset[\"train\"][i]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672849f1-ba2d-4867-9f5c-d3acc4f476f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "d = {'id': id, 'url': url, \"title\": title, 'article': article, 'summary': summary}\n",
    "df = pd.DataFrame(data=d)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0dbc0d-1d0b-4766-bcad-245b1cf40b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_r1 = []\n",
    "base_r2 = []\n",
    "base_rL = []\n",
    "base_rLs = []\n",
    "base_chrf = []\n",
    "\n",
    "for i in range(len(df['article'])): \n",
    "    \n",
    "    \n",
    "    # first three sentences \n",
    "    candidate = \". \".join(df[\"article\"][i].split('. ')[0:3]) + \".\"\n",
    "    candidate = [candidate]\n",
    "    \n",
    "    ref = [df['summary'][i]]\n",
    "    \n",
    "    results = rouge.compute(predictions=candidate,\n",
    "                            references= ref)\n",
    "    \n",
    "    results2 = chrf.compute(predictions=candidate,\n",
    "                            references= ref)\n",
    "    \n",
    "    base_r1.append(results['rouge1'])\n",
    "    base_r2.append(results['rouge2'])\n",
    "    base_rL.append(results['rougeL'])\n",
    "    base_rLs.append(results['rougeLsum'])\n",
    "    \n",
    "    base_chrf.append(results2['score'])\n",
    "    \n",
    "    if i in np.arange(0, 2000, 100):\n",
    "        data = {'rouge1': base_r1, 'rouge2': base_r2, 'rogueL': base_rL, 'rogueLs': base_rLs, 'chrf': base_chrf}\n",
    "        scores = pd.DataFrame(data)\n",
    "        scores.to_csv(r'base_scores_business.csv', index=False)\n",
    "        print(i)\n",
    "        \n",
    "data = {'rouge1': base_r1, 'rouge2': base_r2, 'rogueL': base_rL, 'rogueLs': base_rLs, 'chrf': base_chrf}\n",
    "scores = pd.DataFrame(data)\n",
    "scores.to_csv(r'base_scores_business.csv', index=False)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5196a242-9634-487c-bc3d-afa24eec6c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('rouge1 average: ', np.mean(base_r1))\n",
    "print('rouge2 average: ', np.mean(base_r2))\n",
    "print('rougeL average: ', np.mean(base_rL))\n",
    "print('rougeLs average:', np.mean(base_rLs))\n",
    "print('chrf average:', np.mean(base_chrf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9211a4a1-6b7d-4e6d-b941-39cd616d91e1",
   "metadata": {},
   "source": [
    "**Category 4: entertainment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2be6d1-48b0-4eb7-a6a4-c21a293acd10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cat_inx = find_indices(categories, 'entertainment')\n",
    "index = pd.DataFrame({\"index\": cat_inx})\n",
    "sample_index = index.sample(n=1000, replace=False, random_state=1004)\n",
    "sample_index[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c65350-a3be-4474-8a56-e515e93ffb5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "id = []\n",
    "url = []\n",
    "title = []\n",
    "article = []\n",
    "summary = []\n",
    "\n",
    "for i in sample_index[\"index\"]:\n",
    "    id.append(dataset[\"train\"][i]['id'])\n",
    "    url.append(dataset[\"train\"][i]['url'])\n",
    "    title.append(dataset[\"train\"][i]['title'])\n",
    "    summary.append(dataset[\"train\"][i]['summary'])\n",
    "    article.append(dataset[\"train\"][i]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48e97dc-5cc9-4d6e-b811-2d92b95c3328",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "d = {'id': id, 'url': url, \"title\": title, 'article': article, 'summary': summary}\n",
    "df = pd.DataFrame(data=d)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459aa5a7-62e1-4fab-b15b-d9be859d58f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_r1 = []\n",
    "base_r2 = []\n",
    "base_rL = []\n",
    "base_rLs = []\n",
    "base_chrf = []\n",
    "\n",
    "for i in range(len(df['article'])): \n",
    "    \n",
    "    \n",
    "    # first three sentences \n",
    "    candidate = \". \".join(df[\"article\"][i].split('. ')[0:3]) + \".\"\n",
    "    candidate = [candidate]\n",
    "    \n",
    "    ref = [df['summary'][i]]\n",
    "    \n",
    "    results = rouge.compute(predictions=candidate,\n",
    "                            references= ref)\n",
    "    \n",
    "    results2 = chrf.compute(predictions=candidate,\n",
    "                            references= ref)\n",
    "    \n",
    "    base_r1.append(results['rouge1'])\n",
    "    base_r2.append(results['rouge2'])\n",
    "    base_rL.append(results['rougeL'])\n",
    "    base_rLs.append(results['rougeLsum'])\n",
    "    \n",
    "    base_chrf.append(results2['score'])\n",
    "    \n",
    "    if i in np.arange(0, 2000, 100):\n",
    "        data = {'rouge1': base_r1, 'rouge2': base_r2, 'rogueL': base_rL, 'rogueLs': base_rLs, 'chrf': base_chrf}\n",
    "        scores = pd.DataFrame(data)\n",
    "        scores.to_csv(r'base_scores_entertainment.csv', index=False)\n",
    "        print(i)\n",
    "        \n",
    "data = {'rouge1': base_r1, 'rouge2': base_r2, 'rogueL': base_rL, 'rogueLs': base_rLs, 'chrf': base_chrf}\n",
    "scores = pd.DataFrame(data)\n",
    "scores.to_csv(r'base_scores_entertainment.csv', index=False)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb43531-1bee-4d75-b833-9c94904b0481",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('rouge1 average: ', np.mean(base_r1))\n",
    "print('rouge2 average: ', np.mean(base_r2))\n",
    "print('rougeL average: ', np.mean(base_rL))\n",
    "print('rougeLs average:', np.mean(base_rLs))\n",
    "print('chrf average:', np.mean(base_chrf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9d608b-1751-4b97-810a-2ea235b8c54d",
   "metadata": {},
   "source": [
    "**Category 5: technology**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7717381-bb26-4531-8a73-cdcb40207a7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cat_inx = find_indices(categories, 'technology')\n",
    "index = pd.DataFrame({\"index\": cat_inx})\n",
    "sample_index = index.sample(n=1000, replace=False, random_state=1004)\n",
    "sample_index[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9b08ab-3f9a-4475-b15e-1c856fb7dcd3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "id = []\n",
    "url = []\n",
    "title = []\n",
    "article = []\n",
    "summary = []\n",
    "\n",
    "for i in sample_index[\"index\"]:\n",
    "    id.append(dataset[\"train\"][i]['id'])\n",
    "    url.append(dataset[\"train\"][i]['url'])\n",
    "    title.append(dataset[\"train\"][i]['title'])\n",
    "    summary.append(dataset[\"train\"][i]['summary'])\n",
    "    article.append(dataset[\"train\"][i]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0bc0fa-3018-46bb-bd7f-ec0291500d8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "d = {'id': id, 'url': url, \"title\": title, 'article': article, 'summary': summary}\n",
    "df = pd.DataFrame(data=d)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb50b13-8092-4072-b5d7-eb9e5fc4aecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_r1 = []\n",
    "base_r2 = []\n",
    "base_rL = []\n",
    "base_rLs = []\n",
    "base_chrf = []\n",
    "\n",
    "for i in range(len(df['article'])): \n",
    "    \n",
    "    \n",
    "    # first three sentences \n",
    "    candidate = \". \".join(df[\"article\"][i].split('. ')[0:3]) + \".\"\n",
    "    candidate = [candidate]\n",
    "    \n",
    "    ref = [df['summary'][i]]\n",
    "    \n",
    "    results = rouge.compute(predictions=candidate,\n",
    "                            references= ref)\n",
    "    \n",
    "    results2 = chrf.compute(predictions=candidate,\n",
    "                            references= ref)\n",
    "    \n",
    "    base_r1.append(results['rouge1'])\n",
    "    base_r2.append(results['rouge2'])\n",
    "    base_rL.append(results['rougeL'])\n",
    "    base_rLs.append(results['rougeLsum'])\n",
    "    \n",
    "    base_chrf.append(results2['score'])\n",
    "    \n",
    "    if i in np.arange(0, 2000, 100):\n",
    "        data = {'rouge1': base_r1, 'rouge2': base_r2, 'rogueL': base_rL, 'rogueLs': base_rLs, 'chrf': base_chrf}\n",
    "        scores = pd.DataFrame(data)\n",
    "        scores.to_csv(r'base_scores_tech.csv', index=False)\n",
    "        print(i)\n",
    "        \n",
    "data = {'rouge1': base_r1, 'rouge2': base_r2, 'rogueL': base_rL, 'rogueLs': base_rLs, 'chrf': base_chrf}\n",
    "scores = pd.DataFrame(data)\n",
    "scores.to_csv(r'base_scores_tech.csv', index=False)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5140a02-f213-4911-a91b-44a2504b9620",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('rouge1 average: ', np.mean(base_r1))\n",
    "print('rouge2 average: ', np.mean(base_r2))\n",
    "print('rougeL average: ', np.mean(base_rL))\n",
    "print('rougeLs average:', np.mean(base_rLs))\n",
    "print('chrf average:', np.mean(base_chrf))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
