{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d870553",
   "metadata": {},
   "source": [
    "**Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dacdaf3d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/w266/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "\n",
    "#let's make longer output readable without horizontal scrolling\n",
    "from pprint import pprint\n",
    "\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f29e293",
   "metadata": {},
   "source": [
    "**Necessary Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f96edd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rouge = evaluate.load('rouge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "312bbea0-61d2-4582-98ff-a7cf52f2dbb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chrf = evaluate.load(\"chrf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a0a517",
   "metadata": {},
   "source": [
    "**Baseline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d34d652-d960-4849-9999-8387dad31c29",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/w266_project/Datasets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/w266_project/Datasets'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd\n",
    "%cd Datasets\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf0a470c-b079-4fb1-aa1a-4068194bd9d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('xl_sum_sample_test.csv')\n",
    "df.rename(columns={\"text\": \"article\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c151fd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_r1 = []\n",
    "base_r2 = []\n",
    "base_rL = []\n",
    "base_rLs = []\n",
    "base_chrf = []\n",
    "\n",
    "for i in range(len(df['article'])): \n",
    "    \n",
    "    \n",
    "    # first three sentences \n",
    "    candidate = \". \".join(df[\"article\"][i].split('. ')[0:3]) + \".\"\n",
    "    candidate = [candidate]\n",
    "    \n",
    "    ref = [df['summary'][i]]\n",
    "    \n",
    "    results = rouge.compute(predictions=candidate,\n",
    "                            references= ref)\n",
    "    \n",
    "    results2 = chrf.compute(predictions=candidate,\n",
    "                            references= ref)\n",
    "    \n",
    "    base_r1.append(results['rouge1'])\n",
    "    base_r2.append(results['rouge2'])\n",
    "    base_rL.append(results['rougeL'])\n",
    "    base_rLs.append(results['rougeLsum'])\n",
    "    \n",
    "    base_chrf.append(results2['score'])\n",
    "    \n",
    "#     if i in np.arange(0, 2000, 100):\n",
    "#         data = {'rouge1': base_r1, 'rouge2': base_r2, 'rogueL': base_rL, 'rogueLs': base_rLs, 'chrf': base_chrf}\n",
    "#         scores = pd.DataFrame(data)\n",
    "#         scores.to_csv(r'base_scores.csv', index=False)\n",
    "#         print(i)\n",
    "        \n",
    "# data = {'rouge1': base_r1, 'rouge2': base_r2, 'rogueL': base_rL, 'rogueLs': base_rLs, 'chrf': base_chrf}\n",
    "# scores = pd.DataFrame(data)\n",
    "# scores.to_csv(r'base_scores.csv', index=False)\n",
    "# print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "888889b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rouge1 average:  0.19133312513637057\n",
      "rouge2 average:  0.02937056797124805\n",
      "rougeL average:  0.12669268518181787\n",
      "rougeLs average: 0.12669268518181787\n",
      "chrf average: 27.03051908844659\n"
     ]
    }
   ],
   "source": [
    "print('rouge1 average: ', np.mean(base_r1))\n",
    "print('rouge2 average: ', np.mean(base_r2))\n",
    "print('rougeL average: ', np.mean(base_rL))\n",
    "print('rougeLs average:', np.mean(base_rLs))\n",
    "print('chrf average:', np.mean(base_chrf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a07eaf-d714-4eb8-8a30-7b7ce3d67568",
   "metadata": {},
   "source": [
    "**Baseline by Top 5 Largest Categories**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a74f47-ce27-4fbf-b27c-33afe7d6af73",
   "metadata": {},
   "source": [
    "**Category 1: uk**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d3e3888-2cd3-47c0-ab04-cfa209cec560",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('xl_sum_sample_test_uk.csv')\n",
    "df.rename(columns={\"text\": \"article\"}, inplace=True)\n",
    "\n",
    "base_r1 = []\n",
    "base_r2 = []\n",
    "base_rL = []\n",
    "base_rLs = []\n",
    "base_chrf = []\n",
    "\n",
    "for i in range(len(df['article'])): \n",
    "    \n",
    "    \n",
    "    # first three sentences \n",
    "    candidate = \". \".join(df[\"article\"][i].split('. ')[0:3]) + \".\"\n",
    "    candidate = [candidate]\n",
    "    \n",
    "    ref = [df['summary'][i]]\n",
    "    \n",
    "    results = rouge.compute(predictions=candidate,\n",
    "                            references= ref)\n",
    "    \n",
    "    results2 = chrf.compute(predictions=candidate,\n",
    "                            references= ref)\n",
    "    \n",
    "    base_r1.append(results['rouge1'])\n",
    "    base_r2.append(results['rouge2'])\n",
    "    base_rL.append(results['rougeL'])\n",
    "    base_rLs.append(results['rougeLsum'])\n",
    "    \n",
    "    base_chrf.append(results2['score'])\n",
    "    \n",
    "#     if i in np.arange(0, 2000, 100):\n",
    "#         data = {'rouge1': base_r1, 'rouge2': base_r2, 'rogueL': base_rL, 'rogueLs': base_rLs, 'chrf': base_chrf}\n",
    "#         scores = pd.DataFrame(data)\n",
    "#         scores.to_csv(r'base_scores_uk.csv', index=False)\n",
    "#         print(i)\n",
    "        \n",
    "# data = {'rouge1': base_r1, 'rouge2': base_r2, 'rogueL': base_rL, 'rogueLs': base_rLs, 'chrf': base_chrf}\n",
    "# scores = pd.DataFrame(data)\n",
    "# scores.to_csv(r'base_scores_uk.csv', index=False)\n",
    "# print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b959c5d-fe1b-45b4-936f-12ed993daa54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rouge1 average:  0.18111051452589635\n",
      "rouge2 average:  0.022696344156556383\n",
      "rougeL average:  0.1154848733930737\n",
      "rougeLs average: 0.1154848733930737\n",
      "chrf average: 26.570064095134985\n"
     ]
    }
   ],
   "source": [
    "print('rouge1 average: ', np.mean(base_r1))\n",
    "print('rouge2 average: ', np.mean(base_r2))\n",
    "print('rougeL average: ', np.mean(base_rL))\n",
    "print('rougeLs average:', np.mean(base_rLs))\n",
    "print('chrf average:', np.mean(base_chrf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a961a3a-826a-4cb3-9b85-e903e624e30d",
   "metadata": {},
   "source": [
    "**Category 2: world**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0f41da3-6fb5-4fcd-85be-b286038c563d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('xl_sum_sample_test_world.csv')\n",
    "df.rename(columns={\"text\": \"article\"}, inplace=True)\n",
    "\n",
    "base_r1 = []\n",
    "base_r2 = []\n",
    "base_rL = []\n",
    "base_rLs = []\n",
    "base_chrf = []\n",
    "\n",
    "for i in range(len(df['article'])): \n",
    "    \n",
    "    \n",
    "    # first three sentences \n",
    "    candidate = \". \".join(df[\"article\"][i].split('. ')[0:3]) + \".\"\n",
    "    candidate = [candidate]\n",
    "    \n",
    "    ref = [df['summary'][i]]\n",
    "    \n",
    "    results = rouge.compute(predictions=candidate,\n",
    "                            references= ref)\n",
    "    \n",
    "    results2 = chrf.compute(predictions=candidate,\n",
    "                            references= ref)\n",
    "    \n",
    "    base_r1.append(results['rouge1'])\n",
    "    base_r2.append(results['rouge2'])\n",
    "    base_rL.append(results['rougeL'])\n",
    "    base_rLs.append(results['rougeLsum'])\n",
    "    \n",
    "    base_chrf.append(results2['score'])\n",
    "    \n",
    "#     if i in np.arange(0, 2000, 100):\n",
    "#         data = {'rouge1': base_r1, 'rouge2': base_r2, 'rogueL': base_rL, 'rogueLs': base_rLs, 'chrf': base_chrf}\n",
    "#         scores = pd.DataFrame(data)\n",
    "#         scores.to_csv(r'base_scores_uk.csv', index=False)\n",
    "#         print(i)\n",
    "        \n",
    "# data = {'rouge1': base_r1, 'rouge2': base_r2, 'rogueL': base_rL, 'rogueLs': base_rLs, 'chrf': base_chrf}\n",
    "# scores = pd.DataFrame(data)\n",
    "# scores.to_csv(r'base_scores_uk.csv', index=False)\n",
    "# print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44ae5904-ba6f-465f-9370-6fbc38501ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rouge1 average:  0.1909124946444825\n",
      "rouge2 average:  0.02620089004274868\n",
      "rougeL average:  0.12632325279673057\n",
      "rougeLs average: 0.12632325279673057\n",
      "chrf average: 27.557929211258628\n"
     ]
    }
   ],
   "source": [
    "print('rouge1 average: ', np.mean(base_r1))\n",
    "print('rouge2 average: ', np.mean(base_r2))\n",
    "print('rougeL average: ', np.mean(base_rL))\n",
    "print('rougeLs average:', np.mean(base_rLs))\n",
    "print('chrf average:', np.mean(base_chrf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395f61ba-a5a9-4ff2-81e0-26657a95b508",
   "metadata": {},
   "source": [
    "**Category 3: business**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fdda4f96-7bf0-4baa-a170-781c63d0ceec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('xl_sum_sample_test_business.csv')\n",
    "df.rename(columns={\"text\": \"article\"}, inplace=True)\n",
    "\n",
    "base_r1 = []\n",
    "base_r2 = []\n",
    "base_rL = []\n",
    "base_rLs = []\n",
    "base_chrf = []\n",
    "\n",
    "for i in range(len(df['article'])): \n",
    "    \n",
    "    \n",
    "    # first three sentences \n",
    "    candidate = \". \".join(df[\"article\"][i].split('. ')[0:3]) + \".\"\n",
    "    candidate = [candidate]\n",
    "    \n",
    "    ref = [df['summary'][i]]\n",
    "    \n",
    "    results = rouge.compute(predictions=candidate,\n",
    "                            references= ref)\n",
    "    \n",
    "    results2 = chrf.compute(predictions=candidate,\n",
    "                            references= ref)\n",
    "    \n",
    "    base_r1.append(results['rouge1'])\n",
    "    base_r2.append(results['rouge2'])\n",
    "    base_rL.append(results['rougeL'])\n",
    "    base_rLs.append(results['rougeLsum'])\n",
    "    \n",
    "    base_chrf.append(results2['score'])\n",
    "    \n",
    "#     if i in np.arange(0, 2000, 100):\n",
    "#         data = {'rouge1': base_r1, 'rouge2': base_r2, 'rogueL': base_rL, 'rogueLs': base_rLs, 'chrf': base_chrf}\n",
    "#         scores = pd.DataFrame(data)\n",
    "#         scores.to_csv(r'base_scores_uk.csv', index=False)\n",
    "#         print(i)\n",
    "        \n",
    "# data = {'rouge1': base_r1, 'rouge2': base_r2, 'rogueL': base_rL, 'rogueLs': base_rLs, 'chrf': base_chrf}\n",
    "# scores = pd.DataFrame(data)\n",
    "# scores.to_csv(r'base_scores_uk.csv', index=False)\n",
    "# print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea4073cc-19c1-4d36-9e6f-65412cdd1662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rouge1 average:  0.17993152421793193\n",
      "rouge2 average:  0.02166476459588301\n",
      "rougeL average:  0.11799526986328442\n",
      "rougeLs average: 0.11799526986328442\n",
      "chrf average: 26.00362024266716\n"
     ]
    }
   ],
   "source": [
    "print('rouge1 average: ', np.mean(base_r1))\n",
    "print('rouge2 average: ', np.mean(base_r2))\n",
    "print('rougeL average: ', np.mean(base_rL))\n",
    "print('rougeLs average:', np.mean(base_rLs))\n",
    "print('chrf average:', np.mean(base_chrf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9211a4a1-6b7d-4e6d-b941-39cd616d91e1",
   "metadata": {},
   "source": [
    "**Category 4: entertainment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c901e241-fd1a-474f-9f6c-a58acded42aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('xl_sum_sample_test_entertainment.csv')\n",
    "df.rename(columns={\"text\": \"article\"}, inplace=True)\n",
    "\n",
    "base_r1 = []\n",
    "base_r2 = []\n",
    "base_rL = []\n",
    "base_rLs = []\n",
    "base_chrf = []\n",
    "\n",
    "for i in range(len(df['article'])): \n",
    "    \n",
    "    \n",
    "    # first three sentences \n",
    "    candidate = \". \".join(df[\"article\"][i].split('. ')[0:3]) + \".\"\n",
    "    candidate = [candidate]\n",
    "    \n",
    "    ref = [df['summary'][i]]\n",
    "    \n",
    "    results = rouge.compute(predictions=candidate,\n",
    "                            references= ref)\n",
    "    \n",
    "    results2 = chrf.compute(predictions=candidate,\n",
    "                            references= ref)\n",
    "    \n",
    "    base_r1.append(results['rouge1'])\n",
    "    base_r2.append(results['rouge2'])\n",
    "    base_rL.append(results['rougeL'])\n",
    "    base_rLs.append(results['rougeLsum'])\n",
    "    \n",
    "    base_chrf.append(results2['score'])\n",
    "    \n",
    "#     if i in np.arange(0, 2000, 100):\n",
    "#         data = {'rouge1': base_r1, 'rouge2': base_r2, 'rogueL': base_rL, 'rogueLs': base_rLs, 'chrf': base_chrf}\n",
    "#         scores = pd.DataFrame(data)\n",
    "#         scores.to_csv(r'base_scores_uk.csv', index=False)\n",
    "#         print(i)\n",
    "        \n",
    "# data = {'rouge1': base_r1, 'rouge2': base_r2, 'rogueL': base_rL, 'rogueLs': base_rLs, 'chrf': base_chrf}\n",
    "# scores = pd.DataFrame(data)\n",
    "# scores.to_csv(r'base_scores_uk.csv', index=False)\n",
    "# print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2dd4521a-89db-4eaa-a964-09267b828ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rouge1 average:  0.17938922043603683\n",
      "rouge2 average:  0.030559275203157477\n",
      "rougeL average:  0.11700412638808368\n",
      "rougeLs average: 0.11700412638808368\n",
      "chrf average: 25.389828483913558\n"
     ]
    }
   ],
   "source": [
    "print('rouge1 average: ', np.mean(base_r1))\n",
    "print('rouge2 average: ', np.mean(base_r2))\n",
    "print('rougeL average: ', np.mean(base_rL))\n",
    "print('rougeLs average:', np.mean(base_rLs))\n",
    "print('chrf average:', np.mean(base_chrf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9d608b-1751-4b97-810a-2ea235b8c54d",
   "metadata": {},
   "source": [
    "**Category 5: technology**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e3d2208f-c8f8-4d9d-8d3a-fa69ba5099d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('xl_sum_sample_test_technology.csv')\n",
    "df.rename(columns={\"text\": \"article\"}, inplace=True)\n",
    "\n",
    "base_r1 = []\n",
    "base_r2 = []\n",
    "base_rL = []\n",
    "base_rLs = []\n",
    "base_chrf = []\n",
    "\n",
    "for i in range(len(df['article'])): \n",
    "    \n",
    "    \n",
    "    # first three sentences \n",
    "    candidate = \". \".join(df[\"article\"][i].split('. ')[0:3]) + \".\"\n",
    "    candidate = [candidate]\n",
    "    \n",
    "    ref = [df['summary'][i]]\n",
    "    \n",
    "    results = rouge.compute(predictions=candidate,\n",
    "                            references= ref)\n",
    "    \n",
    "    results2 = chrf.compute(predictions=candidate,\n",
    "                            references= ref)\n",
    "    \n",
    "    base_r1.append(results['rouge1'])\n",
    "    base_r2.append(results['rouge2'])\n",
    "    base_rL.append(results['rougeL'])\n",
    "    base_rLs.append(results['rougeLsum'])\n",
    "    \n",
    "    base_chrf.append(results2['score'])\n",
    "    \n",
    "#     if i in np.arange(0, 2000, 100):\n",
    "#         data = {'rouge1': base_r1, 'rouge2': base_r2, 'rogueL': base_rL, 'rogueLs': base_rLs, 'chrf': base_chrf}\n",
    "#         scores = pd.DataFrame(data)\n",
    "#         scores.to_csv(r'base_scores_uk.csv', index=False)\n",
    "#         print(i)\n",
    "        \n",
    "# data = {'rouge1': base_r1, 'rouge2': base_r2, 'rogueL': base_rL, 'rogueLs': base_rLs, 'chrf': base_chrf}\n",
    "# scores = pd.DataFrame(data)\n",
    "# scores.to_csv(r'base_scores_uk.csv', index=False)\n",
    "# print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e096afcc-0067-4ace-a2c4-a364d40833c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rouge1 average:  0.17810940108876694\n",
      "rouge2 average:  0.016415796075101286\n",
      "rougeL average:  0.11251070995687218\n",
      "rougeLs average: 0.11251070995687218\n",
      "chrf average: 26.50763621173526\n"
     ]
    }
   ],
   "source": [
    "print('rouge1 average: ', np.mean(base_r1))\n",
    "print('rouge2 average: ', np.mean(base_r2))\n",
    "print('rougeL average: ', np.mean(base_rL))\n",
    "print('rougeLs average:', np.mean(base_rLs))\n",
    "print('chrf average:', np.mean(base_chrf))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
