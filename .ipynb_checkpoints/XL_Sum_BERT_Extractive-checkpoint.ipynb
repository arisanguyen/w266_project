{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d870553",
   "metadata": {},
   "source": [
    "**Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dacdaf3d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/w266/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-04-01 07:12:51.217992: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-01 07:12:52.070613: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/amazon/efa/lib:/opt/amazon/openmpi/lib:/usr/local/cuda/efa/lib:/usr/local/cuda/lib:/usr/local/cuda:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/targets/x86_64-linux/lib:/usr/local/lib:/usr/lib:/opt/amazon/efa/lib:/opt/amazon/openmpi/lib:/usr/local/cuda/efa/lib:/usr/local/cuda/lib:/usr/local/cuda:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/targets/x86_64-linux/lib:/usr/local/lib:/usr/lib:\n",
      "2023-04-01 07:12:52.070755: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/amazon/efa/lib:/opt/amazon/openmpi/lib:/usr/local/cuda/efa/lib:/usr/local/cuda/lib:/usr/local/cuda:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/targets/x86_64-linux/lib:/usr/local/lib:/usr/lib:/opt/amazon/efa/lib:/opt/amazon/openmpi/lib:/usr/local/cuda/efa/lib:/usr/local/cuda/lib:/usr/local/cuda:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/targets/x86_64-linux/lib:/usr/local/lib:/usr/lib:\n",
      "2023-04-01 07:12:52.070767: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "\n",
    "#let's make longer output readable without horizontal scrolling\n",
    "from pprint import pprint\n",
    "\n",
    "import warnings\n",
    "\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f29e293",
   "metadata": {},
   "source": [
    "**Necessary Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc5f44ab-39ad-49be-a367-c2ff78ac845a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import inspect\n",
    "\n",
    "def get_default_args(func):\n",
    "    signature = inspect.signature(func)\n",
    "    return {\n",
    "        k: v.default\n",
    "        for k, v in signature.parameters.items()\n",
    "        if v.default is not inspect.Parameter.empty\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f96edd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rouge = evaluate.load('rouge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e922d01-d029-42ee-bf38-6765115f1e04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chrf = evaluate.load(\"chrf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586a6d00",
   "metadata": {},
   "source": [
    "**Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec6c665e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset xlsum (/home/ubuntu/.cache/huggingface/datasets/csebuetnlp___xlsum/english/2.0.0/518ab0af76048660bcc2240ca6e8692a977c80e384ffb18fdddebaca6daebdce)\n",
      "100%|████████████████████████████████████████████| 3/3 [00:00<00:00, 339.65it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"csebuetnlp/xlsum\", \"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "296f3f54-85c7-4446-ae73-fa54ac3123a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>235420</th>\n",
       "      <td>235420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172024</th>\n",
       "      <td>172024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253546</th>\n",
       "      <td>253546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224954</th>\n",
       "      <td>224954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214134</th>\n",
       "      <td>214134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index\n",
       "235420  235420\n",
       "172024  172024\n",
       "253546  253546\n",
       "224954  224954\n",
       "214134  214134"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = pd.DataFrame({\"index\": list(range(len(dataset['train'])))})\n",
    "sample_index = index.sample(n=2000, replace=False, random_state=1004)\n",
    "sample_index[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6656d7bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "id = []\n",
    "url = []\n",
    "title = []\n",
    "article = []\n",
    "article_num_sentences = []\n",
    "article_num_characters = []\n",
    "summary = []\n",
    "summary_num_sentences = []\n",
    "summary_num_characters = []\n",
    "\n",
    "for i in sample_index[\"index\"]:\n",
    "    id.append(dataset[\"train\"][i]['id'])\n",
    "    url.append(dataset[\"train\"][i]['url'])\n",
    "    title.append(dataset[\"train\"][i]['title'])\n",
    "    summary.append(dataset[\"train\"][i]['summary'])\n",
    "    summary_num_sentences.append(len(dataset[\"train\"][i]['summary'].split(\".\")))\n",
    "    summary_num_characters.append(len(dataset[\"train\"][i]['summary']))\n",
    "    article.append(dataset[\"train\"][i]['text'])\n",
    "    article_num_sentences.append(len(dataset[\"train\"][i]['text'].split(\".\")))\n",
    "    article_num_characters.append(len(dataset[\"train\"][i]['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66def3a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>article</th>\n",
       "      <th>article_num_sentences</th>\n",
       "      <th>article_num_characters</th>\n",
       "      <th>summary</th>\n",
       "      <th>summary_num_sentences</th>\n",
       "      <th>summary_num_characters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>uk-england-cornwall-55191422</td>\n",
       "      <td>https://www.bbc.com/news/uk-england-cornwall-5...</td>\n",
       "      <td>Care home manager: 'It felt like we were losin...</td>\n",
       "      <td>By Rebecca Ricks &amp; Johnny O'SheaBBC Spotlight ...</td>\n",
       "      <td>37</td>\n",
       "      <td>3755</td>\n",
       "      <td>During the spring, at the height of the Covid-...</td>\n",
       "      <td>2</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>uk-43893709</td>\n",
       "      <td>https://www.bbc.com/news/uk-43893709</td>\n",
       "      <td>Tafida Raqeeb: Who decides the care of sick ch...</td>\n",
       "      <td>By Rachel SchraerBBC Reality Check So, why did...</td>\n",
       "      <td>33</td>\n",
       "      <td>4531</td>\n",
       "      <td>The parents of five-year-old Tafida Raqeeb, wh...</td>\n",
       "      <td>2</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>uk-politics-57050659</td>\n",
       "      <td>https://www.bbc.com/news/uk-politics-57050659</td>\n",
       "      <td>Labour reshuffle: Anneliese Dodds out in Starm...</td>\n",
       "      <td>Anneliese Dodds will now become the Labour Par...</td>\n",
       "      <td>36</td>\n",
       "      <td>4845</td>\n",
       "      <td>Sir Keir Starmer has sacked his shadow chancel...</td>\n",
       "      <td>2</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>entertainment-arts-38221420</td>\n",
       "      <td>https://www.bbc.com/news/entertainment-arts-38...</td>\n",
       "      <td>Vinyl sales made more than downloads last week</td>\n",
       "      <td>By Mark SavageBBC Music reporter Vinyl sales m...</td>\n",
       "      <td>27</td>\n",
       "      <td>2082</td>\n",
       "      <td>More money was spent on vinyl than downloaded ...</td>\n",
       "      <td>2</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entertainment-arts-24046991</td>\n",
       "      <td>https://www.bbc.com/news/entertainment-arts-24...</td>\n",
       "      <td>Pirates of the Caribbean sequel delayed</td>\n",
       "      <td>Disney's Pirates of The Caribbean: Dead Men Te...</td>\n",
       "      <td>14</td>\n",
       "      <td>1569</td>\n",
       "      <td>The next Pirates of the Caribbean film has bee...</td>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             id  \\\n",
       "0  uk-england-cornwall-55191422   \n",
       "1                   uk-43893709   \n",
       "2          uk-politics-57050659   \n",
       "3   entertainment-arts-38221420   \n",
       "4   entertainment-arts-24046991   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.bbc.com/news/uk-england-cornwall-5...   \n",
       "1               https://www.bbc.com/news/uk-43893709   \n",
       "2      https://www.bbc.com/news/uk-politics-57050659   \n",
       "3  https://www.bbc.com/news/entertainment-arts-38...   \n",
       "4  https://www.bbc.com/news/entertainment-arts-24...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Care home manager: 'It felt like we were losin...   \n",
       "1  Tafida Raqeeb: Who decides the care of sick ch...   \n",
       "2  Labour reshuffle: Anneliese Dodds out in Starm...   \n",
       "3     Vinyl sales made more than downloads last week   \n",
       "4            Pirates of the Caribbean sequel delayed   \n",
       "\n",
       "                                             article  article_num_sentences  \\\n",
       "0  By Rebecca Ricks & Johnny O'SheaBBC Spotlight ...                     37   \n",
       "1  By Rachel SchraerBBC Reality Check So, why did...                     33   \n",
       "2  Anneliese Dodds will now become the Labour Par...                     36   \n",
       "3  By Mark SavageBBC Music reporter Vinyl sales m...                     27   \n",
       "4  Disney's Pirates of The Caribbean: Dead Men Te...                     14   \n",
       "\n",
       "   article_num_characters                                            summary  \\\n",
       "0                    3755  During the spring, at the height of the Covid-...   \n",
       "1                    4531  The parents of five-year-old Tafida Raqeeb, wh...   \n",
       "2                    4845  Sir Keir Starmer has sacked his shadow chancel...   \n",
       "3                    2082  More money was spent on vinyl than downloaded ...   \n",
       "4                    1569  The next Pirates of the Caribbean film has bee...   \n",
       "\n",
       "   summary_num_sentences  summary_num_characters  \n",
       "0                      2                     147  \n",
       "1                      2                     121  \n",
       "2                      2                     115  \n",
       "3                      2                      83  \n",
       "4                      2                      88  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'id': id, 'url': url, \"title\": title, 'article': article, \"article_num_sentences\": article_num_sentences, \"article_num_characters\": article_num_characters, 'summary': summary,\"summary_num_sentences\": summary_num_sentences, \"summary_num_characters\": summary_num_characters}\n",
    "df = pd.DataFrame(data=d)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564f872e-a7c8-4058-8ba0-7935db2207b0",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Default Hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a312a65-1c63-4251-8553-c66959b057a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-01 07:12:58.971816: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2023-04-01 07:12:58.971873: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-55-240): /proc/driver/nvidia/version does not exist\n",
      "loading configuration file config.json from cache at /home/ubuntu/.cache/huggingface/hub/models--bert-large-uncased/snapshots/80792f8e8216b29f3c846b653a0ff0a37c210431/config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"output_hidden_states\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.27.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /home/ubuntu/.cache/huggingface/hub/models--bert-large-uncased/snapshots/80792f8e8216b29f3c846b653a0ff0a37c210431/pytorch_model.bin\n",
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at bert-large-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "loading file vocab.txt from cache at /home/ubuntu/.cache/huggingface/hub/models--bert-large-uncased/snapshots/80792f8e8216b29f3c846b653a0ff0a37c210431/vocab.txt\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /home/ubuntu/.cache/huggingface/hub/models--bert-large-uncased/snapshots/80792f8e8216b29f3c846b653a0ff0a37c210431/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /home/ubuntu/.cache/huggingface/hub/models--bert-large-uncased/snapshots/80792f8e8216b29f3c846b653a0ff0a37c210431/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-large-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.27.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from summarizer import Summarizer\n",
    "\n",
    "model = Summarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8edfe31-ebe3-4c38-b8ef-7df7a013d1fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'bert-large-uncased',\n",
       " 'custom_model': None,\n",
       " 'custom_tokenizer': None,\n",
       " 'hidden': -2,\n",
       " 'reduce_option': 'mean',\n",
       " 'sentence_handler': <summarizer.sentence_handler.SentenceHandler at 0x7f694e91d8b0>,\n",
       " 'random_state': 12345,\n",
       " 'hidden_concat': False}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_default_args(Summarizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8c09bea-3299-40b8-a6a2-a7a38c9c0c26",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ratio': 0.2,\n",
       " 'min_length': 40,\n",
       " 'max_length': 600,\n",
       " 'use_first': True,\n",
       " 'algorithm': 'kmeans',\n",
       " 'num_sentences': None,\n",
       " 'return_as_list': False}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_default_args(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4266569",
   "metadata": {},
   "source": [
    "**BERT Extractive Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201c76d1-50eb-4560-b78c-3f05e2c0fe3e",
   "metadata": {},
   "source": [
    "Model 0: Default Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89fd59b8-44ed-4497-9f64-f0d14abbdecd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/ubuntu/.cache/huggingface/hub/models--bert-large-uncased/snapshots/80792f8e8216b29f3c846b653a0ff0a37c210431/config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"output_hidden_states\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.27.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /home/ubuntu/.cache/huggingface/hub/models--bert-large-uncased/snapshots/80792f8e8216b29f3c846b653a0ff0a37c210431/pytorch_model.bin\n",
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at bert-large-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "loading file vocab.txt from cache at /home/ubuntu/.cache/huggingface/hub/models--bert-large-uncased/snapshots/80792f8e8216b29f3c846b653a0ff0a37c210431/vocab.txt\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /home/ubuntu/.cache/huggingface/hub/models--bert-large-uncased/snapshots/80792f8e8216b29f3c846b653a0ff0a37c210431/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /home/ubuntu/.cache/huggingface/hub/models--bert-large-uncased/snapshots/80792f8e8216b29f3c846b653a0ff0a37c210431/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-large-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.27.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from summarizer import Summarizer\n",
    "\n",
    "model = Summarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af9232aa-5fa4-4beb-a11a-e25092a1cdda",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "999\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "bert_r1 = []\n",
    "bert_r2 = []\n",
    "bert_rL = []\n",
    "bert_rLs = []\n",
    "bert_chrf = []\n",
    "\n",
    "for i in range(int(len(df['article'])/2)):\n",
    "    \n",
    "    candidate = model(df['article'][i],\n",
    "                     )\n",
    "    candidate = [candidate]\n",
    "    #pprint(candidate[0], compact=True)\n",
    "    \n",
    "    ref = [df['summary'][i]]\n",
    "    \n",
    "    results = rouge.compute(predictions=candidate,\n",
    "                            references=ref)\n",
    "    \n",
    "    results2 = chrf.compute(predictions=candidate,\n",
    "                            references= ref)\n",
    "    \n",
    "    bert_r1.append(results['rouge1'])\n",
    "    bert_r2.append(results['rouge2'])\n",
    "    bert_rL.append(results['rougeL'])\n",
    "    bert_rLs.append(results['rougeLsum'])\n",
    "    \n",
    "    bert_chrf.append(results2['score'])\n",
    "    \n",
    "    if i in np.arange(0, (len(df['article']) + 101), 100):\n",
    "        data = {'rouge1': bert_r1, 'rouge2': bert_r2, 'rogueL': bert_rL, 'rogueLs': bert_rLs, 'chrf': bert_chrf}\n",
    "        scores = pd.DataFrame(data)\n",
    "        scores.to_csv(r'BERT_0_scores.csv', index=False)\n",
    "        print(i)\n",
    "\n",
    "data = {'rouge1': bert_r1, 'rouge2': bert_r2, 'rogueL': bert_rL, 'rogueLs': bert_rLs, 'chrf': bert_chrf}\n",
    "scores = pd.DataFrame(data)\n",
    "scores.to_csv(r'BERT_0_scores.csv', index=False)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3230aee-fe28-4099-ae35-b9fd18f5d2f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rouge1 average : 0.1555884135260613\n",
      "rouge2 average : 0.02396541867504151\n",
      "rougeL average : 0.1019488717714199\n",
      "rougeLs average : 0.1019488717714199\n",
      "chrf average: 24.023480987952347\n"
     ]
    }
   ],
   "source": [
    "print('rouge1 average :', np.mean(bert_r1))\n",
    "print('rouge2 average :', np.mean(bert_r2))\n",
    "print('rougeL average :', np.mean(bert_rL))\n",
    "print('rougeLs average :', np.mean(bert_rLs))\n",
    "print('chrf average:', np.mean(bert_chrf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c846d219-5c6b-47b6-ae81-9a61e241ac74",
   "metadata": {
    "tags": []
   },
   "source": [
    "Finetuning On First 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d9ce16-2e35-453d-8c3a-f1e1d354c68c",
   "metadata": {},
   "source": [
    "Model 1. Adjusted min_length, max_length, num_sentences (which overrides ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79dde227-1016-4f35-a0cd-b6a2f3d5f587",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from summarizer import Summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "462afc0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/ubuntu/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_hidden_states\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.27.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /home/ubuntu/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/pytorch_model.bin\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "loading file vocab.txt from cache at /home/ubuntu/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/vocab.txt\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /home/ubuntu/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /home/ubuntu/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.27.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using bert-base instead of bert-large to reduce run times\n",
    "model = Summarizer(model='bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2595b5cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "999\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "bert_r1 = []\n",
    "bert_r2 = []\n",
    "bert_rL = []\n",
    "bert_rLs = []\n",
    "bert_chrf = []\n",
    "\n",
    "for i in range(int(len(df['article'])/2)):\n",
    "    \n",
    "    # Limiting number sentences in each summary generated to 2 sentences \n",
    "    candidate = model(df['article'][i], \n",
    "                      num_sentences = round(df[\"summary_num_sentences\"][:1000].mean()), \n",
    "                      min_length = min(df[\"summary_num_characters\"][:1000]),\n",
    "                      max_length = max(df[\"summary_num_characters\"][:1000]),        \n",
    "                      ratio = None,\n",
    "                      use_first = None,\n",
    "                     )\n",
    "    candidate = [candidate]\n",
    "    #pprint(candidate[0], compact=True)\n",
    "    \n",
    "    ref = [df['summary'][i]]\n",
    "    \n",
    "    results = rouge.compute(predictions=candidate,\n",
    "                            references=ref)\n",
    "    \n",
    "    results2 = chrf.compute(predictions=candidate,\n",
    "                            references= ref)\n",
    "    \n",
    "    bert_r1.append(results['rouge1'])\n",
    "    bert_r2.append(results['rouge2'])\n",
    "    bert_rL.append(results['rougeL'])\n",
    "    bert_rLs.append(results['rougeLsum'])\n",
    "    \n",
    "    bert_chrf.append(results2['score'])\n",
    "    \n",
    "    if i in np.arange(0, (len(df['article']) + 101), 100):\n",
    "        data = {'rouge1': bert_r1, 'rouge2': bert_r2, 'rogueL': bert_rL, 'rogueLs': bert_rLs, 'chrf': bert_chrf}\n",
    "        scores = pd.DataFrame(data)\n",
    "        scores.to_csv(r'BERT_1_scores.csv', index=False)\n",
    "        print(i)\n",
    "        \n",
    "data = {'rouge1': bert_r1, 'rouge2': bert_r2, 'rogueL': bert_rL, 'rogueLs': bert_rLs, 'chrf': bert_chrf}\n",
    "scores = pd.DataFrame(data)\n",
    "scores.to_csv(r'BERT_1_scores.csv', index=False)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97555fa3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rouge1 average : 0.178192403298457\n",
      "rouge2 average : 0.026733936113222955\n",
      "rougeL average : 0.11966303460985027\n",
      "rougeLs average : 0.11966303460985027\n",
      "chrf average: 26.369458875111786\n"
     ]
    }
   ],
   "source": [
    "print('rouge1 average :', np.mean(bert_r1))\n",
    "print('rouge2 average :', np.mean(bert_r2))\n",
    "print('rougeL average :', np.mean(bert_rL))\n",
    "print('rougeLs average :', np.mean(bert_rLs))\n",
    "print('chrf average:', np.mean(bert_chrf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec631b8-e0a8-40ac-8f16-fe3094b118cc",
   "metadata": {},
   "source": [
    "Tuning Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96727286-a2e4-4e08-a014-1d205a55dc44",
   "metadata": {},
   "source": [
    "2. Made num_sentences based off number of clusters instead of average "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68b71359-02c7-4236-b22e-5eb077d02a0a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/ubuntu/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_hidden_states\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.27.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /home/ubuntu/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/pytorch_model.bin\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "loading file vocab.txt from cache at /home/ubuntu/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/vocab.txt\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /home/ubuntu/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /home/ubuntu/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.27.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from summarizer import Summarizer\n",
    "\n",
    "model = Summarizer(model='bert-base-uncased',\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e007312b-1348-45d4-ab1b-f32c270bb415",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "999\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "bert_r1 = []\n",
    "bert_r2 = []\n",
    "bert_rL = []\n",
    "bert_rLs = []\n",
    "bert_chrf = []\n",
    "\n",
    "for i in range(int(len(df['article'])/2)):\n",
    "\n",
    "    res = model.calculate_optimal_k(df['article'][i], k_max=10)\n",
    "    \n",
    "    candidate = model(df['article'][i], \n",
    "                      num_sentences = res, # number of sentences determined by number of clusters\n",
    "                      min_length = min(df[\"summary_num_characters\"][:1000]),\n",
    "                      max_length = max(df[\"summary_num_characters\"][:1000]),        \n",
    "                      ratio = None,\n",
    "                      use_first = None,)\n",
    "    candidate = [candidate]\n",
    "    #pprint(candidate[0], compact=True)\n",
    "    \n",
    "    ref = [df['summary'][i]]\n",
    "    \n",
    "    results = rouge.compute(predictions=candidate,\n",
    "                            references=ref)\n",
    "    \n",
    "    results2 = chrf.compute(predictions=candidate,\n",
    "                            references= ref)\n",
    "    \n",
    "    bert_chrf.append(results2['score'])\n",
    "    \n",
    "    bert_r1.append(results['rouge1'])\n",
    "    bert_r2.append(results['rouge2'])\n",
    "    bert_rL.append(results['rougeL'])\n",
    "    bert_rLs.append(results['rougeLsum'])\n",
    "    \n",
    "    if i in np.arange(0, (len(df['article']) + 101), 100):\n",
    "        data = {'rouge1': bert_r1, 'rouge2': bert_r2, 'rogueL': bert_rL, 'rogueLs': bert_rLs, 'chrf': bert_chrf}\n",
    "        scores = pd.DataFrame(data)\n",
    "        scores.to_csv(r'BERT_2_scores.csv', index=False)\n",
    "        print(i)\n",
    "        \n",
    "data = {'rouge1': bert_r1, 'rouge2': bert_r2, 'rogueL': bert_rL, 'rogueLs': bert_rLs, 'chrf': bert_chrf}\n",
    "scores = pd.DataFrame(data)\n",
    "scores.to_csv(r'BERT_2_scores.csv', index=False)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "701447ab-000a-4aea-865a-c5244b0f342c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rouge1 average : 0.16466988117522663\n",
      "rouge2 average : 0.026490759507054564\n",
      "rougeL average : 0.1089025377167142\n",
      "rougeLs average : 0.1089025377167142\n",
      "chrf average: 25.491807322933525\n"
     ]
    }
   ],
   "source": [
    "print('rouge1 average :', np.mean(bert_r1))\n",
    "print('rouge2 average :', np.mean(bert_r2))\n",
    "print('rougeL average :', np.mean(bert_rL))\n",
    "print('rougeLs average :', np.mean(bert_rLs))\n",
    "print('chrf average:', np.mean(bert_chrf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fd8b62-7d3b-4a03-af4c-c9ecec023faa",
   "metadata": {},
   "source": [
    "3. Setting number of sentences with clusters didn't help in second model, so we are reverting back to first model but setting use_first = False bc many examples have meta data in first sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b74b6df2-673c-4083-9939-6e30b722df4e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/ubuntu/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_hidden_states\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.27.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /home/ubuntu/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/pytorch_model.bin\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "loading file vocab.txt from cache at /home/ubuntu/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/vocab.txt\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /home/ubuntu/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /home/ubuntu/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.27.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from summarizer import Summarizer\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "model = Summarizer(model='bert-base-uncased',\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "815245f2-2673-4ac4-a2c3-4085e5b920aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "999\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "bert_r1 = []\n",
    "bert_r2 = []\n",
    "bert_rL = []\n",
    "bert_rLs = []\n",
    "bert_chrf = []\n",
    "\n",
    "for i in range(int(len(df['article'])/2)):\n",
    "    \n",
    "    # Limiting number sentences in each summary generated to 2 sentences \n",
    "    candidate = model(df['article'][i], \n",
    "                      num_sentences = round(df[\"summary_num_sentences\"][:1000].mean()), \n",
    "                      min_length = min(df[\"summary_num_characters\"][:1000]),\n",
    "                      max_length = max(df[\"summary_num_characters\"][:1000]),        \n",
    "                      ratio = None,\n",
    "                      use_first = False,\n",
    "                     )\n",
    "    candidate = [candidate]\n",
    "    #pprint(candidate[0], compact=True)\n",
    "    \n",
    "    ref = [df['summary'][i]]\n",
    "    \n",
    "    results = rouge.compute(predictions=candidate,\n",
    "                            references=ref)\n",
    "    \n",
    "    results2 = chrf.compute(predictions=candidate,\n",
    "                            references= ref)\n",
    "    \n",
    "    bert_chrf.append(results2['score'])\n",
    "                            \n",
    "    bert_r1.append(results['rouge1'])\n",
    "    bert_r2.append(results['rouge2'])\n",
    "    bert_rL.append(results['rougeL'])\n",
    "    bert_rLs.append(results['rougeLsum'])\n",
    "    \n",
    "    if i in np.arange(0, (len(df['article']) + 101), 100):\n",
    "        data = {'rouge1': bert_r1, 'rouge2': bert_r2, 'rogueL': bert_rL, 'rogueLs': bert_rLs, 'chrf': bert_chrf}\n",
    "        scores = pd.DataFrame(data)\n",
    "        scores.to_csv(r'BERT_3_scores.csv', index=False)\n",
    "        print(i)\n",
    "\n",
    "data = {'rouge1': bert_r1, 'rouge2': bert_r2, 'rogueL': bert_rL, 'rogueLs': bert_rLs, 'chrf': bert_chrf}\n",
    "scores = pd.DataFrame(data)\n",
    "scores.to_csv(r'BERT_3_scores.csv', index=False)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "29baf035-e761-40da-abc0-9dd6ac2de9b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rouge1 average : 0.178192403298457\n",
      "rouge2 average : 0.026733936113222955\n",
      "rougeL average : 0.11966303460985027\n",
      "rougeLs average : 0.11966303460985027\n",
      "chrf average: 26.369458875111786\n"
     ]
    }
   ],
   "source": [
    "print('rouge1 average :', np.mean(bert_r1))\n",
    "print('rouge2 average :', np.mean(bert_r2))\n",
    "print('rougeL average :', np.mean(bert_rL))\n",
    "print('rougeLs average :', np.mean(bert_rLs))\n",
    "print('chrf average:', np.mean(bert_chrf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1715530b-d2c9-45bb-9152-423e3acc7394",
   "metadata": {},
   "source": [
    "4. Setting use_first = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ce1bd98a-1738-4785-8d76-d463896cfc53",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/ubuntu/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_hidden_states\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.27.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /home/ubuntu/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/pytorch_model.bin\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "loading file vocab.txt from cache at /home/ubuntu/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/vocab.txt\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /home/ubuntu/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /home/ubuntu/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.27.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from summarizer import Summarizer\n",
    "\n",
    "model = Summarizer(model='bert-base-uncased',\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "72ef153b-ad2e-4059-b24a-0dd2db495bc6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "999\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "bert_r1 = []\n",
    "bert_r2 = []\n",
    "bert_rL = []\n",
    "bert_rLs = []\n",
    "bert_chrf = []\n",
    "\n",
    "for i in range(int(len(df['article'])/2)):\n",
    "    \n",
    "    # Limiting number sentences in each summary generated to 2 sentences \n",
    "    candidate = model(df['article'][i], \n",
    "                      num_sentences = round(df[\"summary_num_sentences\"][:1000].mean()), \n",
    "                      min_length = min(df[\"summary_num_characters\"][:1000]),\n",
    "                      max_length = max(df[\"summary_num_characters\"][:1000]),        \n",
    "                      ratio = None,\n",
    "                      use_first = True,\n",
    "                     )\n",
    "    candidate = [candidate]\n",
    "    #pprint(candidate[0], compact=True)\n",
    "    \n",
    "    ref = [df['summary'][i]]\n",
    "    \n",
    "    results = rouge.compute(predictions=candidate,\n",
    "                            references=ref)\n",
    "    \n",
    "    results2 = chrf.compute(predictions=candidate,\n",
    "                            references= ref)\n",
    "    \n",
    "    bert_chrf.append(results2['score'])\n",
    "    \n",
    "    bert_r1.append(results['rouge1'])\n",
    "    bert_r2.append(results['rouge2'])\n",
    "    bert_rL.append(results['rougeL'])\n",
    "    bert_rLs.append(results['rougeLsum'])\n",
    "    \n",
    "    if i in np.arange(0, (len(df['article']) + 101), 100):\n",
    "        data = {'rouge1': bert_r1, 'rouge2': bert_r2, 'rogueL': bert_rL, 'rogueLs': bert_rLs, 'chrf': bert_chrf}\n",
    "        scores = pd.DataFrame(data)\n",
    "        scores.to_csv(r'BERT_3_scores.csv', index=False)\n",
    "        print(i)\n",
    "\n",
    "data = {'rouge1': bert_r1, 'rouge2': bert_r2, 'rogueL': bert_rL, 'rogueLs': bert_rLs, 'chrf': bert_chrf}\n",
    "scores = pd.DataFrame(data)\n",
    "scores.to_csv(r'BERT_3_scores.csv', index=False)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "082a64a6-0e87-4e36-8b47-b65f4942e139",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rouge1 average : 0.1711426991129008\n",
      "rouge2 average : 0.026139674733637642\n",
      "rougeL average : 0.11264718864577299\n",
      "rougeLs average : 0.11264718864577299\n",
      "chrf average: 25.747682911450475\n"
     ]
    }
   ],
   "source": [
    "print('rouge1 average :', np.mean(bert_r1))\n",
    "print('rouge2 average :', np.mean(bert_r2))\n",
    "print('rougeL average :', np.mean(bert_rL))\n",
    "print('rougeLs average :', np.mean(bert_rLs))\n",
    "print('chrf average:', np.mean(bert_chrf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a566379-110d-4741-8439-1738fa5e3389",
   "metadata": {},
   "source": [
    "5. Use bert-large-uncased w/ best from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "87a140b7-6255-4b2a-93e8-fbb10dcf912d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/ubuntu/.cache/huggingface/hub/models--bert-large-uncased/snapshots/80792f8e8216b29f3c846b653a0ff0a37c210431/config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"output_hidden_states\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.27.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /home/ubuntu/.cache/huggingface/hub/models--bert-large-uncased/snapshots/80792f8e8216b29f3c846b653a0ff0a37c210431/pytorch_model.bin\n",
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at bert-large-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "loading file vocab.txt from cache at /home/ubuntu/.cache/huggingface/hub/models--bert-large-uncased/snapshots/80792f8e8216b29f3c846b653a0ff0a37c210431/vocab.txt\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /home/ubuntu/.cache/huggingface/hub/models--bert-large-uncased/snapshots/80792f8e8216b29f3c846b653a0ff0a37c210431/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /home/ubuntu/.cache/huggingface/hub/models--bert-large-uncased/snapshots/80792f8e8216b29f3c846b653a0ff0a37c210431/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-large-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.27.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from summarizer import Summarizer\n",
    "\n",
    "model = Summarizer(model='bert-large-uncased',\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2934abbd-5dae-4f94-8e90-dc2e45a6fe6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "999\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "bert_r1 = []\n",
    "bert_r2 = []\n",
    "bert_rL = []\n",
    "bert_rLs = []\n",
    "bert_chrf = []\n",
    "\n",
    "for i in range(int(len(df['article'])/2)):\n",
    "    \n",
    "    # Limiting number sentences in each summary generated to 2 sentences \n",
    "    candidate = model(df['article'][i], \n",
    "                      num_sentences = round(df[\"summary_num_sentences\"][:1000].mean()), \n",
    "                      min_length = min(df[\"summary_num_characters\"][:1000]),\n",
    "                      max_length = max(df[\"summary_num_characters\"][:1000]),        \n",
    "                      ratio = None,\n",
    "                      use_first = False,\n",
    "                     )\n",
    "    candidate = [candidate]\n",
    "    #pprint(candidate[0], compact=True)\n",
    "    \n",
    "    ref = [df['summary'][i]]\n",
    "    \n",
    "    results = rouge.compute(predictions=candidate,\n",
    "                            references=ref)\n",
    "    \n",
    "    results2 = chrf.compute(predictions=candidate,\n",
    "                            references= ref)\n",
    "    \n",
    "    bert_chrf.append(results2['score'])\n",
    "    \n",
    "    bert_r1.append(results['rouge1'])\n",
    "    bert_r2.append(results['rouge2'])\n",
    "    bert_rL.append(results['rougeL'])\n",
    "    bert_rLs.append(results['rougeLsum'])\n",
    "    \n",
    "    if i in np.arange(0, (len(df['article']) + 101), 100):\n",
    "        data = {'rouge1': bert_r1, 'rouge2': bert_r2, 'rogueL': bert_rL, 'rogueLs': bert_rLs, 'chrf': bert_chrf}\n",
    "        scores = pd.DataFrame(data)\n",
    "        scores.to_csv(r'BERT_4_scores.csv', index=False)\n",
    "        print(i)\n",
    "\n",
    "data = {'rouge1': bert_r1, 'rouge2': bert_r2, 'rogueL': bert_rL, 'rogueLs': bert_rLs, 'chrf': bert_chrf}\n",
    "scores = pd.DataFrame(data)\n",
    "scores.to_csv(r'BERT_4_scores.csv', index=False)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7192f7f4-028a-4abc-aa1a-925a1a8c3616",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rouge1 average : 0.17709196861695112\n",
      "rouge2 average : 0.025145083935109475\n",
      "rougeL average : 0.11939202129428797\n",
      "rougeLs average : 0.11939202129428797\n",
      "chrf average: 26.173252280733426\n"
     ]
    }
   ],
   "source": [
    "# this model took longer and performed worse\n",
    "print('rouge1 average :', np.mean(bert_r1))\n",
    "print('rouge2 average :', np.mean(bert_r2))\n",
    "print('rougeL average :', np.mean(bert_rL))\n",
    "print('rougeLs average :', np.mean(bert_rLs))\n",
    "print('chrf average:', np.mean(bert_chrf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cab172-dc0a-4962-990e-cefbec9f1366",
   "metadata": {},
   "source": [
    "6. Reduce option median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5e5fa0c9-a090-4dff-b250-459de6983da5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/ubuntu/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_hidden_states\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.27.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /home/ubuntu/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/pytorch_model.bin\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "loading file vocab.txt from cache at /home/ubuntu/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/vocab.txt\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /home/ubuntu/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /home/ubuntu/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.27.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from summarizer import Summarizer\n",
    "\n",
    "model = Summarizer(model='bert-base-uncased', reduce_option = 'median'\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9cad742a-6f5b-4add-b9b3-a6ab0c856630",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "999\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "bert_r1 = []\n",
    "bert_r2 = []\n",
    "bert_rL = []\n",
    "bert_rLs = []\n",
    "bert_chrf = []\n",
    "\n",
    "for i in range(int(len(df['article'])/2)):\n",
    "    \n",
    "    # Limiting number sentences in each summary generated to 2 sentences \n",
    "    candidate = model(df['article'][i], \n",
    "                      num_sentences = round(df[\"summary_num_sentences\"][:1000].mean()), \n",
    "                      min_length = min(df[\"summary_num_characters\"][:1000]),\n",
    "                      max_length = max(df[\"summary_num_characters\"][:1000]),        \n",
    "                      ratio = None,\n",
    "                      use_first = None,\n",
    "                     )\n",
    "    candidate = [candidate]\n",
    "    #pprint(candidate[0], compact=True)\n",
    "    \n",
    "    ref = [df['summary'][i]]\n",
    "    \n",
    "    results = rouge.compute(predictions=candidate,\n",
    "                            references=ref)\n",
    "    \n",
    "    results2 = chrf.compute(predictions=candidate,\n",
    "                            references= ref)\n",
    "    \n",
    "    bert_chrf.append(results2['score'])\n",
    "    \n",
    "    bert_r1.append(results['rouge1'])\n",
    "    bert_r2.append(results['rouge2'])\n",
    "    bert_rL.append(results['rougeL'])\n",
    "    bert_rLs.append(results['rougeLsum'])\n",
    "    \n",
    "    if i in np.arange(0, (len(df['article']) + 101), 100):\n",
    "        data = {'rouge1': bert_r1, 'rouge2': bert_r2, 'rogueL': bert_rL, 'rogueLs': bert_rLs, 'chrf': bert_chrf}\n",
    "        scores = pd.DataFrame(data)\n",
    "        scores.to_csv(r'BERT_4_scores.csv', index=False)\n",
    "        print(i)\n",
    "\n",
    "data = {'rouge1': bert_r1, 'rouge2': bert_r2, 'rogueL': bert_rL, 'rogueLs': bert_rLs, 'chrf': bert_chrf}\n",
    "scores = pd.DataFrame(data)\n",
    "scores.to_csv(r'BERT_6_scores.csv', index=False)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "81108fe5-f4f9-4509-ade6-75b9cb09815a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rouge1 average : 0.17604122934873215\n",
      "rouge2 average : 0.025439640514237527\n",
      "rougeL average : 0.11815625686666714\n",
      "rougeLs average : 0.11815625686666714\n",
      "chrf average: 26.217912847303975\n"
     ]
    }
   ],
   "source": [
    "print('rouge1 average :', np.mean(bert_r1))\n",
    "print('rouge2 average :', np.mean(bert_r2))\n",
    "print('rougeL average :', np.mean(bert_rL))\n",
    "print('rougeLs average :', np.mean(bert_rLs))\n",
    "print('chrf average:', np.mean(bert_chrf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd379e9-9b75-49c2-a336-f132b63281e1",
   "metadata": {},
   "source": [
    "**7. Reduce option max THIS WORKED THIS BEST!!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "382d244f-a422-49b0-b141-0a7b55c4c163",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/ubuntu/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_hidden_states\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.27.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /home/ubuntu/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/pytorch_model.bin\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "loading file vocab.txt from cache at /home/ubuntu/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/vocab.txt\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /home/ubuntu/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /home/ubuntu/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.27.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from summarizer import Summarizer\n",
    "\n",
    "model = Summarizer(model='bert-base-uncased', reduce_option = 'max'\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f92f9a41-6fd4-4320-b51c-e026c01e01a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "999\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "bert_r1 = []\n",
    "bert_r2 = []\n",
    "bert_rL = []\n",
    "bert_rLs = []\n",
    "bert_chrf = []\n",
    "\n",
    "for i in range(int(len(df['article'])/2)):\n",
    "    \n",
    "    # Limiting number sentences in each summary generated to 2 sentences \n",
    "    candidate = model(df['article'][i], \n",
    "                      num_sentences = round(df[\"summary_num_sentences\"][:1000].mean()), \n",
    "                      min_length = min(df[\"summary_num_characters\"][:1000]),\n",
    "                      max_length = max(df[\"summary_num_characters\"][:1000]),        \n",
    "                      ratio = None,\n",
    "                      use_first = None,\n",
    "                     )\n",
    "    candidate = [candidate]\n",
    "    #pprint(candidate[0], compact=True)\n",
    "    \n",
    "    ref = [df['summary'][i]]\n",
    "    \n",
    "    results = rouge.compute(predictions=candidate,\n",
    "                            references=ref)\n",
    "    \n",
    "    results2 = chrf.compute(predictions=candidate,\n",
    "                            references= ref)\n",
    "    \n",
    "    bert_chrf.append(results2['score'])\n",
    "    \n",
    "    bert_r1.append(results['rouge1'])\n",
    "    bert_r2.append(results['rouge2'])\n",
    "    bert_rL.append(results['rougeL'])\n",
    "    bert_rLs.append(results['rougeLsum'])\n",
    "    \n",
    "    if i in np.arange(0, (len(df['article']) + 101), 100):\n",
    "        data = {'rouge1': bert_r1, 'rouge2': bert_r2, 'rogueL': bert_rL, 'rogueLs': bert_rLs, 'chrf': bert_chrf}\n",
    "        scores = pd.DataFrame(data)\n",
    "        scores.to_csv(r'BERT_7_scores.csv', index=False)\n",
    "        print(i)\n",
    "\n",
    "data = {'rouge1': bert_r1, 'rouge2': bert_r2, 'rogueL': bert_rL, 'rogueLs': bert_rLs, 'chrf': bert_chrf}\n",
    "scores = pd.DataFrame(data)\n",
    "scores.to_csv(r'BERT_7_scores.csv', index=False)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "95cd8b50-8555-4b77-9a56-edc169ccc0eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rouge1 average : 0.18111656560761913\n",
      "rouge2 average : 0.025095740456991585\n",
      "rougeL average : 0.12307647067888493\n",
      "rougeLs average : 0.12307647067888493\n",
      "chrf average: 26.458573826280013\n"
     ]
    }
   ],
   "source": [
    "print('rouge1 average :', np.mean(bert_r1))\n",
    "print('rouge2 average :', np.mean(bert_r2))\n",
    "print('rougeL average :', np.mean(bert_rL))\n",
    "print('rougeLs average :', np.mean(bert_rLs))\n",
    "print('chrf average:', np.mean(bert_chrf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "50baf0e3-b028-4533-bc6c-7be20529119e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_sentences 2\n",
      "min_length 45\n",
      "max_length 497\n"
     ]
    }
   ],
   "source": [
    "print('num_sentences', round(df[\"summary_num_sentences\"][:1000].mean()))\n",
    "print('min_length', min(df[\"summary_num_characters\"][:1000]))\n",
    "print('max_length', max(df[\"summary_num_characters\"][:1000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fbb598-7393-4006-8886-707879a490e1",
   "metadata": {},
   "source": [
    "**Best BERT Extractive model based on ROUGE scores from finetuning above by category**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b40eb831-0089-44bd-aeaf-441de4acf8c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_indices(list_to_check, item_to_find):\n",
    "    indices = []\n",
    "    for idx, value in enumerate(list_to_check):\n",
    "        if value == item_to_find:\n",
    "            indices.append(idx)\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "593b516b-48f1-43fa-af11-997604ee9072",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "categories = []\n",
    "\n",
    "for i in range(len(dataset['train'])):\n",
    "    cat = dataset['train'][i]['id']\n",
    "    result = re.sub('\\d','',cat)[:-1]\n",
    "    result = result.split('-')[0].split('.')[0]\n",
    "    categories.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05fdfde-349d-4598-b490-1cbd3fda6c75",
   "metadata": {},
   "source": [
    "**Category 1: uk**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8837067b-6bcb-477c-9f31-c52038232b44",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>103144</th>\n",
       "      <td>184549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135979</th>\n",
       "      <td>242139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122918</th>\n",
       "      <td>219346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41576</th>\n",
       "      <td>76571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23230</th>\n",
       "      <td>44271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index\n",
       "103144  184549\n",
       "135979  242139\n",
       "122918  219346\n",
       "41576    76571\n",
       "23230    44271"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uk = find_indices(categories, 'uk')\n",
    "index = pd.DataFrame({\"index\": uk})\n",
    "sample_index = index.sample(n=1000, replace=False, random_state=1004)\n",
    "sample_index[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a64fecc1-9498-4a9c-821b-c4a02827b42a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "id = []\n",
    "url = []\n",
    "title = []\n",
    "article = []\n",
    "summary = []\n",
    "\n",
    "for i in sample_index[\"index\"]:\n",
    "    id.append(dataset[\"train\"][i]['id'])\n",
    "    url.append(dataset[\"train\"][i]['url'])\n",
    "    title.append(dataset[\"train\"][i]['title'])\n",
    "    summary.append(dataset[\"train\"][i]['summary'])\n",
    "    article.append(dataset[\"train\"][i]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "19da3f13-2c99-4d97-814f-682d2dda99db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>article</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>uk-england-bristol-51032231</td>\n",
       "      <td>https://www.bbc.com/news/uk-england-bristol-51...</td>\n",
       "      <td>Author Emily Koch: 'I'm not angry at the drive...</td>\n",
       "      <td>Emily Koch suffered two broken legs and ligame...</td>\n",
       "      <td>A woman left seriously injured after being hit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>uk-england-birmingham-54264699</td>\n",
       "      <td>https://www.bbc.com/news/uk-england-birmingham...</td>\n",
       "      <td>Blind TikTok star Lucy Edwards says reaction t...</td>\n",
       "      <td>Lucy Edwards, who became Radio 1's first blind...</td>\n",
       "      <td>A blind vlogger hopes her TikTok videos on liv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>uk-england-london-16091997</td>\n",
       "      <td>https://www.bbc.com/news/uk-england-london-160...</td>\n",
       "      <td>Bendy bus makes final journey for Transport fo...</td>\n",
       "      <td>The vehicles were used on 12 routes over the p...</td>\n",
       "      <td>The last of London's bendy buses was taken off...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>uk-england-norfolk-54058083</td>\n",
       "      <td>https://www.bbc.com/news/uk-england-norfolk-54...</td>\n",
       "      <td>Horsey seals: Volunteers remove rubber ring fr...</td>\n",
       "      <td>Four members of Friends of Horsey Seals netted...</td>\n",
       "      <td>Volunteers have helped capture a \"feisty\" seal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>uk-scotland-edinburgh-east-fife-28838287</td>\n",
       "      <td>https://www.bbc.com/news/uk-scotland-edinburgh...</td>\n",
       "      <td>Tim Vine wins funniest Edinburgh Fringe joke a...</td>\n",
       "      <td>He won with the one-liner: \"I decided to sell ...</td>\n",
       "      <td>A joke by comedian Tim Vine about a vacuum cle...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         id  \\\n",
       "0               uk-england-bristol-51032231   \n",
       "1            uk-england-birmingham-54264699   \n",
       "2                uk-england-london-16091997   \n",
       "3               uk-england-norfolk-54058083   \n",
       "4  uk-scotland-edinburgh-east-fife-28838287   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.bbc.com/news/uk-england-bristol-51...   \n",
       "1  https://www.bbc.com/news/uk-england-birmingham...   \n",
       "2  https://www.bbc.com/news/uk-england-london-160...   \n",
       "3  https://www.bbc.com/news/uk-england-norfolk-54...   \n",
       "4  https://www.bbc.com/news/uk-scotland-edinburgh...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Author Emily Koch: 'I'm not angry at the drive...   \n",
       "1  Blind TikTok star Lucy Edwards says reaction t...   \n",
       "2  Bendy bus makes final journey for Transport fo...   \n",
       "3  Horsey seals: Volunteers remove rubber ring fr...   \n",
       "4  Tim Vine wins funniest Edinburgh Fringe joke a...   \n",
       "\n",
       "                                             article  \\\n",
       "0  Emily Koch suffered two broken legs and ligame...   \n",
       "1  Lucy Edwards, who became Radio 1's first blind...   \n",
       "2  The vehicles were used on 12 routes over the p...   \n",
       "3  Four members of Friends of Horsey Seals netted...   \n",
       "4  He won with the one-liner: \"I decided to sell ...   \n",
       "\n",
       "                                             summary  \n",
       "0  A woman left seriously injured after being hit...  \n",
       "1  A blind vlogger hopes her TikTok videos on liv...  \n",
       "2  The last of London's bendy buses was taken off...  \n",
       "3  Volunteers have helped capture a \"feisty\" seal...  \n",
       "4  A joke by comedian Tim Vine about a vacuum cle...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'id': id, 'url': url, \"title\": title, 'article': article, 'summary': summary}\n",
    "df = pd.DataFrame(data=d)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "34265006-89d9-43b0-a9bf-8e12ffd174ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "999\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "bert_r1 = []\n",
    "bert_r2 = []\n",
    "bert_rL = []\n",
    "bert_rLs = []\n",
    "bert_chrf = []\n",
    "\n",
    "for i in range(int(len(df['article']))):\n",
    "    \n",
    "    # Limiting number sentences in each summary generated to 2 sentences \n",
    "    candidate = model(df['article'][i], \n",
    "                      num_sentences = 2, \n",
    "                      min_length = 45,\n",
    "                      max_length = 497,        \n",
    "                      ratio = None,\n",
    "                      use_first = None,\n",
    "                     )\n",
    "    candidate = [candidate]\n",
    "    #pprint(candidate[0], compact=True)\n",
    "    \n",
    "    ref = [df['summary'][i]]\n",
    "    \n",
    "    results = rouge.compute(predictions=candidate,\n",
    "                            references=ref)\n",
    "    \n",
    "    results2 = chrf.compute(predictions=candidate,\n",
    "                            references= ref)\n",
    "    \n",
    "    bert_chrf.append(results2['score'])\n",
    "    \n",
    "    bert_r1.append(results['rouge1'])\n",
    "    bert_r2.append(results['rouge2'])\n",
    "    bert_rL.append(results['rougeL'])\n",
    "    bert_rLs.append(results['rougeLsum'])\n",
    "    \n",
    "    if i in np.arange(0, (len(df['article']) + 101), 100):\n",
    "        data = {'rouge1': bert_r1, 'rouge2': bert_r2, 'rogueL': bert_rL, 'rogueLs': bert_rLs, 'chrf': bert_chrf}\n",
    "        scores = pd.DataFrame(data)\n",
    "        scores.to_csv(r'BERT_7_scores_uk.csv', index=False)\n",
    "        print(i)\n",
    "\n",
    "data = {'rouge1': bert_r1, 'rouge2': bert_r2, 'rogueL': bert_rL, 'rogueLs': bert_rLs, 'chrf': bert_chrf}\n",
    "scores = pd.DataFrame(data)\n",
    "scores.to_csv(r'BERT_7_scores_uk.csv', index=False)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9549992c-d3d4-42d8-a3a2-57b774e36e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rouge1 average:  0.1867497432269535\n",
      "rouge2 average:  0.029340134895117883\n",
      "rougeL average:  0.12861916655749933\n",
      "rougeLs average: 0.12861916655749933\n",
      "chrf average: 26.629013615609452\n"
     ]
    }
   ],
   "source": [
    "print('rouge1 average: ', np.mean(bert_r1))\n",
    "print('rouge2 average: ', np.mean(bert_r2))\n",
    "print('rougeL average: ', np.mean(bert_rL))\n",
    "print('rougeLs average:', np.mean(bert_rLs))\n",
    "print('chrf average:', np.mean(bert_chrf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ff031d-c333-4c0e-a319-6cba1f8b5da6",
   "metadata": {},
   "source": [
    "**Category 2: world**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "edff48ba-f34a-401b-bf1a-e22ccf5f173e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38266</th>\n",
       "      <td>209050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5910</th>\n",
       "      <td>25805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14047</th>\n",
       "      <td>71645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23996</th>\n",
       "      <td>127936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25699</th>\n",
       "      <td>137681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        index\n",
       "38266  209050\n",
       "5910    25805\n",
       "14047   71645\n",
       "23996  127936\n",
       "25699  137681"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_inx = find_indices(categories, 'world')\n",
    "index = pd.DataFrame({\"index\": cat_inx})\n",
    "sample_index = index.sample(n=1000, replace=False, random_state=1004)\n",
    "sample_index[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4b287371-9892-4a1f-84af-229c0037e7d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "id = []\n",
    "url = []\n",
    "title = []\n",
    "article = []\n",
    "summary = []\n",
    "\n",
    "for i in sample_index[\"index\"]:\n",
    "    id.append(dataset[\"train\"][i]['id'])\n",
    "    url.append(dataset[\"train\"][i]['url'])\n",
    "    title.append(dataset[\"train\"][i]['title'])\n",
    "    summary.append(dataset[\"train\"][i]['summary'])\n",
    "    article.append(dataset[\"train\"][i]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ff9d1553-d738-49a0-a63d-1e5ebc8db46e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>article</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>world-asia-53847400</td>\n",
       "      <td>https://www.bbc.com/news/world-asia-53847400</td>\n",
       "      <td>Kim Jong-un gives sister Yo-jong 'more respons...</td>\n",
       "      <td>Mr Kim still maintains \"absolute authority\", b...</td>\n",
       "      <td>North Korean leader Kim Jong-un has delegated ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>world-europe-guernsey-18129181</td>\n",
       "      <td>https://www.bbc.com/news/world-europe-guernsey...</td>\n",
       "      <td>Guernsey overgrown trees prompt road crash fears</td>\n",
       "      <td>Overgrown bushes and trees could result in peo...</td>\n",
       "      <td>Residents are being urged to trim vegetation o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>world-africa-44629681</td>\n",
       "      <td>https://www.bbc.co.uk/news/world-africa-44629681</td>\n",
       "      <td>Bringing Gay Pride to Africa's last absolute m...</td>\n",
       "      <td>And anyone doubting the determination needed t...</td>\n",
       "      <td>Africa's last absolute monarchy is holding its...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>world-asia-41840069</td>\n",
       "      <td>https://www.bbc.com/news/world-asia-41840069</td>\n",
       "      <td>Pakistan polygamy: Lahore man jailed over unap...</td>\n",
       "      <td>The court in Lahore also ordered Shahzad Saqib...</td>\n",
       "      <td>A Pakistan court has jailed a man for six mont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>world-europe-guernsey-13052445</td>\n",
       "      <td>https://www.bbc.com/news/world-europe-guernsey...</td>\n",
       "      <td>Alternative recycling bank site proposed</td>\n",
       "      <td>The old facility at Manor Stores closed last y...</td>\n",
       "      <td>Work is continuing to try to find a permanent ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               id  \\\n",
       "0             world-asia-53847400   \n",
       "1  world-europe-guernsey-18129181   \n",
       "2           world-africa-44629681   \n",
       "3             world-asia-41840069   \n",
       "4  world-europe-guernsey-13052445   \n",
       "\n",
       "                                                 url  \\\n",
       "0       https://www.bbc.com/news/world-asia-53847400   \n",
       "1  https://www.bbc.com/news/world-europe-guernsey...   \n",
       "2   https://www.bbc.co.uk/news/world-africa-44629681   \n",
       "3       https://www.bbc.com/news/world-asia-41840069   \n",
       "4  https://www.bbc.com/news/world-europe-guernsey...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Kim Jong-un gives sister Yo-jong 'more respons...   \n",
       "1   Guernsey overgrown trees prompt road crash fears   \n",
       "2  Bringing Gay Pride to Africa's last absolute m...   \n",
       "3  Pakistan polygamy: Lahore man jailed over unap...   \n",
       "4           Alternative recycling bank site proposed   \n",
       "\n",
       "                                             article  \\\n",
       "0  Mr Kim still maintains \"absolute authority\", b...   \n",
       "1  Overgrown bushes and trees could result in peo...   \n",
       "2  And anyone doubting the determination needed t...   \n",
       "3  The court in Lahore also ordered Shahzad Saqib...   \n",
       "4  The old facility at Manor Stores closed last y...   \n",
       "\n",
       "                                             summary  \n",
       "0  North Korean leader Kim Jong-un has delegated ...  \n",
       "1  Residents are being urged to trim vegetation o...  \n",
       "2  Africa's last absolute monarchy is holding its...  \n",
       "3  A Pakistan court has jailed a man for six mont...  \n",
       "4  Work is continuing to try to find a permanent ...  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'id': id, 'url': url, \"title\": title, 'article': article, 'summary': summary}\n",
    "df = pd.DataFrame(data=d)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f322b098-139a-487e-9078-7ad6de108469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "bert_r1 = []\n",
    "bert_r2 = []\n",
    "bert_rL = []\n",
    "bert_rLs = []\n",
    "bert_chrf = []\n",
    "\n",
    "for i in range(int(len(df['article']))):\n",
    "    \n",
    "    # Limiting number sentences in each summary generated to 2 sentences \n",
    "    candidate = model(df['article'][i], \n",
    "                      num_sentences = 2, \n",
    "                      min_length = 45,\n",
    "                      max_length = 497,        \n",
    "                      ratio = None,\n",
    "                      use_first = None,\n",
    "                     )\n",
    "    candidate = [candidate]\n",
    "    #pprint(candidate[0], compact=True)\n",
    "    \n",
    "    ref = [df['summary'][i]]\n",
    "    \n",
    "    results = rouge.compute(predictions=candidate,\n",
    "                            references=ref)\n",
    "    \n",
    "    results2 = chrf.compute(predictions=candidate,\n",
    "                            references= ref)\n",
    "    \n",
    "    bert_chrf.append(results2['score'])\n",
    "    \n",
    "    bert_r1.append(results['rouge1'])\n",
    "    bert_r2.append(results['rouge2'])\n",
    "    bert_rL.append(results['rougeL'])\n",
    "    bert_rLs.append(results['rougeLsum'])\n",
    "    \n",
    "    if i in np.arange(0, (len(df['article']) + 101), 100):\n",
    "        data = {'rouge1': bert_r1, 'rouge2': bert_r2, 'rogueL': bert_rL, 'rogueLs': bert_rLs, 'chrf': bert_chrf}\n",
    "        scores = pd.DataFrame(data)\n",
    "        scores.to_csv(r'BERT_7_scores_world.csv', index=False)\n",
    "        print(i)\n",
    "\n",
    "data = {'rouge1': bert_r1, 'rouge2': bert_r2, 'rogueL': bert_rL, 'rogueLs': bert_rLs, 'chrf': bert_chrf}\n",
    "scores = pd.DataFrame(data)\n",
    "scores.to_csv(r'BERT_7_scores_world.csv', index=False)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb5d47e-fd5a-4b36-a84b-cdce83404763",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('rouge1 average: ', np.mean(bert_r1))\n",
    "print('rouge2 average: ', np.mean(bert_r2))\n",
    "print('rougeL average: ', np.mean(bert_rL))\n",
    "print('rougeLs average:', np.mean(bert_rLs))\n",
    "print('chrf average:', np.mean(bert_chrf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9c3dcc-ecb5-434c-979f-3e60174819cf",
   "metadata": {},
   "source": [
    "**Category 3: business**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278c4350-fda9-41af-b3df-01c05c05dfaa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cat_inx = find_indices(categories, 'business')\n",
    "index = pd.DataFrame({\"index\": cat_inx})\n",
    "sample_index = index.sample(n=1000, replace=False, random_state=1004)\n",
    "sample_index[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e819c047-8508-4c2b-8c75-66d6053b9e3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "id = []\n",
    "url = []\n",
    "title = []\n",
    "article = []\n",
    "summary = []\n",
    "\n",
    "for i in sample_index[\"index\"]:\n",
    "    id.append(dataset[\"train\"][i]['id'])\n",
    "    url.append(dataset[\"train\"][i]['url'])\n",
    "    title.append(dataset[\"train\"][i]['title'])\n",
    "    summary.append(dataset[\"train\"][i]['summary'])\n",
    "    article.append(dataset[\"train\"][i]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc111fb4-f3ea-4441-a4b8-eda56fcb3dc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "d = {'id': id, 'url': url, \"title\": title, 'article': article, 'summary': summary}\n",
    "df = pd.DataFrame(data=d)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d219fd4-ba87-4828-bf37-407f78ec44e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "bert_r1 = []\n",
    "bert_r2 = []\n",
    "bert_rL = []\n",
    "bert_rLs = []\n",
    "bert_chrf = []\n",
    "\n",
    "for i in range(int(len(df['article']))):\n",
    "    \n",
    "    # Limiting number sentences in each summary generated to 2 sentences \n",
    "    candidate = model(df['article'][i], \n",
    "                      num_sentences = 2, \n",
    "                      min_length = 45,\n",
    "                      max_length = 497,         \n",
    "                      ratio = None,\n",
    "                      use_first = None,\n",
    "                     )\n",
    "    candidate = [candidate]\n",
    "    #pprint(candidate[0], compact=True)\n",
    "    \n",
    "    ref = [df['summary'][i]]\n",
    "    \n",
    "    results = rouge.compute(predictions=candidate,\n",
    "                            references=ref)\n",
    "    \n",
    "    results2 = chrf.compute(predictions=candidate,\n",
    "                            references= ref)\n",
    "    \n",
    "    bert_chrf.append(results2['score'])\n",
    "    \n",
    "    bert_r1.append(results['rouge1'])\n",
    "    bert_r2.append(results['rouge2'])\n",
    "    bert_rL.append(results['rougeL'])\n",
    "    bert_rLs.append(results['rougeLsum'])\n",
    "    \n",
    "    if i in np.arange(0, (len(df['article']) + 101), 100):\n",
    "        data = {'rouge1': bert_r1, 'rouge2': bert_r2, 'rogueL': bert_rL, 'rogueLs': bert_rLs, 'chrf': bert_chrf}\n",
    "        scores = pd.DataFrame(data)\n",
    "        scores.to_csv(r'BERT_7_scores_business.csv', index=False)\n",
    "        print(i)\n",
    "\n",
    "data = {'rouge1': bert_r1, 'rouge2': bert_r2, 'rogueL': bert_rL, 'rogueLs': bert_rLs, 'chrf': bert_chrf}\n",
    "scores = pd.DataFrame(data)\n",
    "scores.to_csv(r'BERT_7_scores_business.csv', index=False)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56801ea6-6e55-41e7-b984-c38c67221ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('rouge1 average: ', np.mean(bert_r1))\n",
    "print('rouge2 average: ', np.mean(bert_r2))\n",
    "print('rougeL average: ', np.mean(bert_rL))\n",
    "print('rougeLs average:', np.mean(bert_rLs))\n",
    "print('chrf average:', np.mean(bert_chrf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7408e182-dd09-4de7-8d0d-b7a349fe156d",
   "metadata": {},
   "source": [
    "**Category 4: entertainment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d9ba2f-bf45-444d-b325-a9dcac8a979d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cat_inx = find_indices(categories, 'entertainment')\n",
    "index = pd.DataFrame({\"index\": cat_inx})\n",
    "sample_index = index.sample(n=1000, replace=False, random_state=1004)\n",
    "sample_index[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42bb9e3-017a-481e-819c-c4a62ac80e43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "id = []\n",
    "url = []\n",
    "title = []\n",
    "article = []\n",
    "summary = []\n",
    "\n",
    "for i in sample_index[\"index\"]:\n",
    "    id.append(dataset[\"train\"][i]['id'])\n",
    "    url.append(dataset[\"train\"][i]['url'])\n",
    "    title.append(dataset[\"train\"][i]['title'])\n",
    "    summary.append(dataset[\"train\"][i]['summary'])\n",
    "    article.append(dataset[\"train\"][i]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dedd09-a0d1-443a-a326-6a0d4c974a70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "d = {'id': id, 'url': url, \"title\": title, 'article': article, 'summary': summary}\n",
    "df = pd.DataFrame(data=d)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c569a8a3-f050-4e8d-bf0a-1fe3f570077a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "bert_r1 = []\n",
    "bert_r2 = []\n",
    "bert_rL = []\n",
    "bert_rLs = []\n",
    "bert_chrf = []\n",
    "\n",
    "for i in range(int(len(df['article']))):\n",
    "    \n",
    "    # Limiting number sentences in each summary generated to 2 sentences \n",
    "    candidate = model(df['article'][i], \n",
    "                      num_sentences = 2, \n",
    "                      min_length = 45,\n",
    "                      max_length = 497,           \n",
    "                      ratio = None,\n",
    "                      use_first = None,\n",
    "                     )\n",
    "    candidate = [candidate]\n",
    "    #pprint(candidate[0], compact=True)\n",
    "    \n",
    "    ref = [df['summary'][i]]\n",
    "    \n",
    "    results = rouge.compute(predictions=candidate,\n",
    "                            references=ref)\n",
    "    \n",
    "    results2 = chrf.compute(predictions=candidate,\n",
    "                            references= ref)\n",
    "    \n",
    "    bert_chrf.append(results2['score'])\n",
    "    \n",
    "    bert_r1.append(results['rouge1'])\n",
    "    bert_r2.append(results['rouge2'])\n",
    "    bert_rL.append(results['rougeL'])\n",
    "    bert_rLs.append(results['rougeLsum'])\n",
    "    \n",
    "    if i in np.arange(0, (len(df['article']) + 101), 100):\n",
    "        data = {'rouge1': bert_r1, 'rouge2': bert_r2, 'rogueL': bert_rL, 'rogueLs': bert_rLs, 'chrf': bert_chrf}\n",
    "        scores = pd.DataFrame(data)\n",
    "        scores.to_csv(r'BERT_7_scores_entertainment.csv', index=False)\n",
    "        print(i)\n",
    "\n",
    "data = {'rouge1': bert_r1, 'rouge2': bert_r2, 'rogueL': bert_rL, 'rogueLs': bert_rLs, 'chrf': bert_chrf}\n",
    "scores = pd.DataFrame(data)\n",
    "scores.to_csv(r'BERT_7_scores_entertainment.csv', index=False)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e690109b-3068-4607-92de-a3af82689194",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('rouge1 average: ', np.mean(bert_r1))\n",
    "print('rouge2 average: ', np.mean(bert_r2))\n",
    "print('rougeL average: ', np.mean(bert_rL))\n",
    "print('rougeLs average:', np.mean(bert_rLs))\n",
    "print('chrf average:', np.mean(bert_chrf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9728c1f3-c8c7-4a86-97cd-65c9ad25bbc9",
   "metadata": {},
   "source": [
    "**Category 5: technology**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358d05ca-9d4f-451c-9203-69486e68fc21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cat_inx = find_indices(categories, 'technology')\n",
    "index = pd.DataFrame({\"index\": cat_inx})\n",
    "sample_index = index.sample(n=1000, replace=False, random_state=1004)\n",
    "sample_index[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d38b0ff-bc23-4bbc-b359-406f9615036e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "id = []\n",
    "url = []\n",
    "title = []\n",
    "article = []\n",
    "summary = []\n",
    "\n",
    "for i in sample_index[\"index\"]:\n",
    "    id.append(dataset[\"train\"][i]['id'])\n",
    "    url.append(dataset[\"train\"][i]['url'])\n",
    "    title.append(dataset[\"train\"][i]['title'])\n",
    "    summary.append(dataset[\"train\"][i]['summary'])\n",
    "    article.append(dataset[\"train\"][i]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88911c48-3f86-43b7-b620-fd9d3e6bec73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "d = {'id': id, 'url': url, \"title\": title, 'article': article, 'summary': summary}\n",
    "df = pd.DataFrame(data=d)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d48b76-35fd-41a3-ad6b-2fb5f516321f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "bert_r1 = []\n",
    "bert_r2 = []\n",
    "bert_rL = []\n",
    "bert_rLs = []\n",
    "bert_chrf = []\n",
    "\n",
    "for i in range(int(len(df['article']))):\n",
    "    \n",
    "    # Limiting number sentences in each summary generated to 2 sentences \n",
    "    candidate = model(df['article'][i], \n",
    "                      num_sentences = 2, \n",
    "                      min_length = 45,\n",
    "                      max_length = 497,          \n",
    "                      ratio = None,\n",
    "                      use_first = None,\n",
    "                     )\n",
    "    candidate = [candidate]\n",
    "    #pprint(candidate[0], compact=True)\n",
    "    \n",
    "    ref = [df['summary'][i]]\n",
    "    \n",
    "    results = rouge.compute(predictions=candidate,\n",
    "                            references=ref)\n",
    "    \n",
    "    results2 = chrf.compute(predictions=candidate,\n",
    "                            references= ref)\n",
    "    \n",
    "    bert_chrf.append(results2['score'])\n",
    "    \n",
    "    bert_r1.append(results['rouge1'])\n",
    "    bert_r2.append(results['rouge2'])\n",
    "    bert_rL.append(results['rougeL'])\n",
    "    bert_rLs.append(results['rougeLsum'])\n",
    "    \n",
    "    if i in np.arange(0, (len(df['article']) + 101), 100):\n",
    "        data = {'rouge1': bert_r1, 'rouge2': bert_r2, 'rogueL': bert_rL, 'rogueLs': bert_rLs, 'chrf': bert_chrf}\n",
    "        scores = pd.DataFrame(data)\n",
    "        scores.to_csv(r'BERT_7_scores_tech.csv', index=False)\n",
    "        print(i)\n",
    "\n",
    "data = {'rouge1': bert_r1, 'rouge2': bert_r2, 'rogueL': bert_rL, 'rogueLs': bert_rLs, 'chrf': bert_chrf}\n",
    "scores = pd.DataFrame(data)\n",
    "scores.to_csv(r'BERT_7_scores_tech.csv', index=False)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf940ada-ad3b-41ba-a68e-df45eef6b897",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('rouge1 average: ', np.mean(bert_r1))\n",
    "print('rouge2 average: ', np.mean(bert_r2))\n",
    "print('rougeL average: ', np.mean(bert_rL))\n",
    "print('rougeLs average:', np.mean(bert_rLs))\n",
    "print('chrf average:', np.mean(bert_chrf))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
