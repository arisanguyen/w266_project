{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b049999-077d-4d48-a02d-94c842050121",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Modeling with T5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d1de3e-85a6-4307-8abf-fbfcae0be263",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0dfe809d-a7a8-47b6-a2e0-2d7bf7d74fd7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/w266/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import math\n",
    "\n",
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "\n",
    "import inspect\n",
    "\n",
    "#let's make longer output readable without horizontal scrolling\n",
    "from pprint import pprint\n",
    "\n",
    "import warnings\n",
    "\n",
    "import regex as re\n",
    "\n",
    "import os, re\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# These auto classes load the right type of tokenizer and model based on a model name\n",
    "from transformers import AutoTokenizer, TFAutoModel\n",
    "from transformers import pipeline\n",
    "from transformers import AutoModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ef6ab7-aa59-479f-a0e8-e0e34a21dc7f",
   "metadata": {},
   "source": [
    "## Necessary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce3330d3-069e-48dc-8a0b-e2ef7d72a2bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rouge = evaluate.load('rouge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "216551a6-cb1e-4516-aa9b-b18d88807a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "chrf = evaluate.load(\"chrf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a32aaf5-c5bb-4052-8b50-af66dbb96312",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_args(func):\n",
    "    signature = inspect.signature(func)\n",
    "    return {\n",
    "        k: v.default\n",
    "        for k, v in signature.parameters.items()\n",
    "        if v.default is not inspect.Parameter.empty\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1843be3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is used to generate candidates and scores using a Huggingface model. \n",
    "\n",
    "# Default hyperparameters in this function are the same as those in the Huggingface models.  \n",
    "# https://huggingface.co/docs/transformers/main_classes/text_generation\n",
    "\n",
    "def t5_scores(mod, data, do_sample = False, num_beams = 1, top_k = 50, num_beam_groups = 1):\n",
    "\n",
    "    bart_r1 = []\n",
    "    bart_r2 = []\n",
    "    bart_rL = []\n",
    "    bart_rLs = []\n",
    "    bart_chrf = []\n",
    "\n",
    "    for i in range(int(len(data['text']))):\n",
    "\n",
    "\n",
    "        candidate = mod(data['text'][i], \n",
    "                               truncation = True, # truncated to first 1024 words, because that is all the model can handle\n",
    "                               max_length = 256, # same as one of the max reference lengths used in PEGASUS training\n",
    "                               min_length = 0, \n",
    "                               do_sample = do_sample,\n",
    "                               num_beams = num_beams, \n",
    "                               top_k = top_k,\n",
    "                               num_beam_groups = num_beam_groups,\n",
    "                                )[0]\n",
    "        candidate = [candidate['summary_text']]\n",
    "        #pprint(candidate[0], compact=True)\n",
    "\n",
    "        ref = [data['summary'][i]]\n",
    "\n",
    "        results = rouge.compute(predictions=candidate,\n",
    "                                references=ref)\n",
    "\n",
    "        bart_r1.append(results['rouge1'])\n",
    "        bart_r2.append(results['rouge2'])\n",
    "        bart_rL.append(results['rougeL'])\n",
    "        bart_rLs.append(results['rougeLsum'])\n",
    "\n",
    "        results = chrf.compute(predictions=candidate,\n",
    "                                references=ref)\n",
    "\n",
    "        bart_chrf.append(results['score'])\n",
    "    \n",
    "    print('Last Article', df['text'][i])\n",
    "    print('Last Reference Summary', ref)\n",
    "    print('Last Candidate Summary', candidate)\n",
    "\n",
    "    print('rouge1 average :', np.mean(bart_r1))\n",
    "    print('rouge2 average :', np.mean(bart_r2))\n",
    "    print('rougeL average :', np.mean(bart_rL))\n",
    "    print('rougeLs average :', np.mean(bart_rLs))\n",
    "    print('chrf average :', np.mean(bart_chrf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44de8cc2-471c-4ad3-b94d-8473c6c3c244",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Huggingface Transformers Training Script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6b616e-4e2b-46eb-83b7-75930d6a43ee",
   "metadata": {},
   "source": [
    "https://github.com/huggingface/transformers/blob/main/examples/pytorch/summarization/run_summarization.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec1fe99-d3bb-43ba-a41b-0dbf028797a1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a565c954",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anthony ZurcherNorth America reporter@awzurche...</td>\n",
       "      <td>On day three of public hearings in the impeach...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It made a net profit of $281m (£185m) in the t...</td>\n",
       "      <td>Yum Brands, owner of KFC and Pizza Hut restaur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Police sources told local media that the boy h...</td>\n",
       "      <td>Four members of the same family have been arre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Zelda Perkins told the Financial Times she sig...</td>\n",
       "      <td>A British former assistant of Harvey Weinstein...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bus workers walked out on Monday over changes ...</td>\n",
       "      <td>Bus drivers in Jersey have agreed to meet with...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Anthony ZurcherNorth America reporter@awzurche...   \n",
       "1  It made a net profit of $281m (£185m) in the t...   \n",
       "2  Police sources told local media that the boy h...   \n",
       "3  Zelda Perkins told the Financial Times she sig...   \n",
       "4  Bus workers walked out on Monday over changes ...   \n",
       "\n",
       "                                             summary  \n",
       "0  On day three of public hearings in the impeach...  \n",
       "1  Yum Brands, owner of KFC and Pizza Hut restaur...  \n",
       "2  Four members of the same family have been arre...  \n",
       "3  A British former assistant of Harvey Weinstein...  \n",
       "4  Bus drivers in Jersey have agreed to meet with...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validation Set\n",
    "df = pd.read_csv('../Data/xl_sum_sample_val.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3cd29df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test set \n",
    "dft = pd.read_csv('../Data/xl_sum_sample_test.csv')\n",
    "#dft.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137b3aff-e9d3-4c5c-a052-00781db74150",
   "metadata": {
    "id": "icBTG1L9HOV0"
   },
   "source": [
    "## Models (Untrained)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5eb6194-913c-4e64-9e7e-b3ec2b0e4fb1",
   "metadata": {},
   "source": [
    "### Model 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1ba9a30-e27d-48ce-b92b-5f61abee8538",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304,
     "referenced_widgets": [
      "ba7aedd20a6648ef8a185ccdafed7e8b",
      "933dc51c4da540548c0cfcf5e150ea91",
      "94df7115be184ffd8463594aac55bcdf",
      "5f197f56a4cd445ba05c85284ee3ec7e",
      "a2952a3f474a409cae3fa7b79d298e1b",
      "b964caed365641f1aeb45e854e6cc713",
      "6272d18c91b0410a9e7abe6fabc411f5",
      "7932031c215a4a1daa1a224466aefd71",
      "43eaf8ef47e24d21b026ed15c6bb1330",
      "347720887c674d5e8c3f3517640210b6",
      "e5c1a1acf50b4628bf49c5f12c957de5",
      "b08a484821a342be8cac89531bf1e819",
      "a23c9940ef754ad393b04ad53766d010",
      "422fc8045bee49929353e7f853a7fc55",
      "933edd679283492f807c6eb55e63ed5b",
      "19f63aeab94340ca8ce50452f8dff6fe",
      "4312bcd28cab4b44a74694c957a6aeca",
      "e786ad36ddec4e81853e5b7ff1aacd38",
      "78dcc03fa242497bbed02fe2f965b34c",
      "8de61bc8199e4d34804fefee0f629f1e",
      "d4105ed41406417daa6b85dbe6bd9292",
      "913a9b310bfc457aa4120b3f39771282",
      "8fab1db75a5347e5a0c4cdc21824e05b",
      "a74886c7792f479e9031f8ea465e1611",
      "8e03e758f15346078795ba5182fdf3af",
      "436e0775c66b43ee98ad1ae7b4d579c9",
      "2c663af838b3438f9a92784b77d90502",
      "06e7b3ca9aa3413ca74235631bf89d0c",
      "3da668068e0048a7a27d27380d876359",
      "46adf561fe584df2a7769a80c196135c",
      "1cce6ca7f0d6499fb90e0ac0539be31c",
      "697d24714a4a460691bd359e652fe57c",
      "d76ee6a160fa463bab9a39708f46fbe5",
      "1f2d56349cf644268faf5e024dfab11b",
      "2a689d9bf81d4d8aafdb800e5030e23d",
      "219f03a10fea4015b8e80ef187adf790",
      "1d3fc1246b0744c0b788f4d9782ec642",
      "59e9d042caae4429af6feed04a08e6a3",
      "a12aa51b863845649c6b2c8961a71154",
      "28b0d2253b9d4192938ea04acf6a9429",
      "1aa20fbd49024695ab54472a3b6a822b",
      "a263083685ea46668e45e9de47c831fc",
      "27629dcc14344e00a48ffaf1cf15bad4",
      "bf562048159c454ba24b3e57c8d10e1d",
      "e91c9346498d425283e4a14712ea0240",
      "055c13c11415442684e190a1c46aea79",
      "09d86116305e4b688241381b5fea2a68",
      "51cd0d37d90c490ea427af4e3b6db9d8",
      "f538b1c3da184d0bbacb33c1508c8c27",
      "3845e81cfe5148dbb0b082bf308c0ad8",
      "738c986517e3443eaf602626384e0d2a",
      "f7f1adc17d1f439e81e123f0c4d8b9a0",
      "36fa961e0abf424e9dfe4691ae1ab638",
      "4923e266703c4a18a45aadec39e65daa",
      "5fd5f773740140e1b769d2d786fab2b4"
     ]
    },
    "id": "WN8kYhZcHSvR",
    "outputId": "931472ef-df5d-4c9e-dbae-5abe2108c48d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading pytorch_model.bin: 100%|██████████| 892M/892M [00:01<00:00, 479MB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|█| 1.39M/1.39M [00:00<00:00, 68.6MB/s]\n",
      "/home/ubuntu/w266/lib/python3.8/site-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "t5_base_summarizer = pipeline(\"summarization\", model=\"t5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d8cc906-dec7-424e-b4dc-1dec59de1aa5",
   "metadata": {
    "id": "I6d2uxw5HSmP",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 256, but you input_length is only 180. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=90)\n",
      "Your max_length is set to 256, but you input_length is only 129. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=64)\n",
      "Your max_length is set to 256, but you input_length is only 232. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=116)\n",
      "Your max_length is set to 256, but you input_length is only 66. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=33)\n",
      "Your max_length is set to 256, but you input_length is only 174. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=87)\n",
      "Your max_length is set to 256, but you input_length is only 242. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=121)\n",
      "Your max_length is set to 256, but you input_length is only 230. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=115)\n",
      "Your max_length is set to 256, but you input_length is only 205. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=102)\n",
      "Your max_length is set to 256, but you input_length is only 235. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=117)\n",
      "Your max_length is set to 256, but you input_length is only 252. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=126)\n",
      "Your max_length is set to 256, but you input_length is only 94. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=47)\n",
      "Your max_length is set to 256, but you input_length is only 178. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=89)\n",
      "Your max_length is set to 256, but you input_length is only 219. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=109)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last Article She tweeted that the clothes would be \"archived & expertly cared for in the spirit & love of Michael Jackson, his bravery, & fans worldwide\". The auction included a jacket worn during Jackson's Bad tour, that went for $240,000 (£148,000) and two crystal gloves. The items were all made by designers Dennis Tompkins and Michael Bush. Lady Gaga also tweeted a picture of herself and her bidding paddle at the auction. More than $5m (£3.1m) was raised by the sale, according to LA-based Julien's Auctions. Other items that went under the hammer included jackets from Michael Jackson's Dangerous and Thriller tours and a pair of jeans that went for $50,000 (£31,000). Some of the money raised by the auction is being donated to a guide dogs charity and a hospice in Las Vegas. American costume designers Michael Bush and Dennis Tompkins created thousands of original pieces for Michael Jackson during his career. However, despite Lady Gaga's assurances, some fans expressed their anger online, claiming that Jackson wanted his costumes to end up in a museum. The singer died on 25 June 2009 from an overdose of the powerful anaesthetic propofol. His personal doctor, Conrad Murray, was later found guilty of his involuntary manslaughter and sentenced to four years in jail. Follow @BBCNewsbeat on Twitter\n",
      "Last Reference Summary ['Lady Gaga has bought 55 items at an auction of Michael Jackson costumes in Los Angeles.']\n",
      "Last Candidate Summary [\"more than $5m (£3.1m) raised by sale . jacket worn during 'bad tour' sold for $200,00 . costume designers handcrafted thousands of original pieces during career . singer died of overdose in 2009 .\"]\n",
      "rouge1 average : 0.19496676289664797\n",
      "rouge2 average : 0.025147069215210007\n",
      "rougeL average : 0.1264814391060289\n",
      "rougeLs average : 0.1264814391060289\n",
      "chrf average : 26.30471103286163\n"
     ]
    }
   ],
   "source": [
    "t5_scores(t5_base_summarizer, df, do_sample = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77e15bb-1171-450b-87d8-0abcaeeb6c86",
   "metadata": {},
   "source": [
    "### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276d8c3c-feba-4ec1-97a0-9c5bf1218397",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304,
     "referenced_widgets": [
      "ba7aedd20a6648ef8a185ccdafed7e8b",
      "933dc51c4da540548c0cfcf5e150ea91",
      "94df7115be184ffd8463594aac55bcdf",
      "5f197f56a4cd445ba05c85284ee3ec7e",
      "a2952a3f474a409cae3fa7b79d298e1b",
      "b964caed365641f1aeb45e854e6cc713",
      "6272d18c91b0410a9e7abe6fabc411f5",
      "7932031c215a4a1daa1a224466aefd71",
      "43eaf8ef47e24d21b026ed15c6bb1330",
      "347720887c674d5e8c3f3517640210b6",
      "e5c1a1acf50b4628bf49c5f12c957de5",
      "b08a484821a342be8cac89531bf1e819",
      "a23c9940ef754ad393b04ad53766d010",
      "422fc8045bee49929353e7f853a7fc55",
      "933edd679283492f807c6eb55e63ed5b",
      "19f63aeab94340ca8ce50452f8dff6fe",
      "4312bcd28cab4b44a74694c957a6aeca",
      "e786ad36ddec4e81853e5b7ff1aacd38",
      "78dcc03fa242497bbed02fe2f965b34c",
      "8de61bc8199e4d34804fefee0f629f1e",
      "d4105ed41406417daa6b85dbe6bd9292",
      "913a9b310bfc457aa4120b3f39771282",
      "8fab1db75a5347e5a0c4cdc21824e05b",
      "a74886c7792f479e9031f8ea465e1611",
      "8e03e758f15346078795ba5182fdf3af",
      "436e0775c66b43ee98ad1ae7b4d579c9",
      "2c663af838b3438f9a92784b77d90502",
      "06e7b3ca9aa3413ca74235631bf89d0c",
      "3da668068e0048a7a27d27380d876359",
      "46adf561fe584df2a7769a80c196135c",
      "1cce6ca7f0d6499fb90e0ac0539be31c",
      "697d24714a4a460691bd359e652fe57c",
      "d76ee6a160fa463bab9a39708f46fbe5",
      "1f2d56349cf644268faf5e024dfab11b",
      "2a689d9bf81d4d8aafdb800e5030e23d",
      "219f03a10fea4015b8e80ef187adf790",
      "1d3fc1246b0744c0b788f4d9782ec642",
      "59e9d042caae4429af6feed04a08e6a3",
      "a12aa51b863845649c6b2c8961a71154",
      "28b0d2253b9d4192938ea04acf6a9429",
      "1aa20fbd49024695ab54472a3b6a822b",
      "a263083685ea46668e45e9de47c831fc",
      "27629dcc14344e00a48ffaf1cf15bad4",
      "bf562048159c454ba24b3e57c8d10e1d",
      "e91c9346498d425283e4a14712ea0240",
      "055c13c11415442684e190a1c46aea79",
      "09d86116305e4b688241381b5fea2a68",
      "51cd0d37d90c490ea427af4e3b6db9d8",
      "f538b1c3da184d0bbacb33c1508c8c27",
      "3845e81cfe5148dbb0b082bf308c0ad8",
      "738c986517e3443eaf602626384e0d2a",
      "f7f1adc17d1f439e81e123f0c4d8b9a0",
      "36fa961e0abf424e9dfe4691ae1ab638",
      "4923e266703c4a18a45aadec39e65daa",
      "5fd5f773740140e1b769d2d786fab2b4"
     ]
    },
    "id": "WN8kYhZcHSvR",
    "outputId": "931472ef-df5d-4c9e-dbae-5abe2108c48d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba7aedd20a6648ef8a185ccdafed7e8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b08a484821a342be8cac89531bf1e819",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/892M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fab1db75a5347e5a0c4cdc21824e05b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f2d56349cf644268faf5e024dfab11b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ve/main/spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e91c9346498d425283e4a14712ea0240",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "t5_base_summarizer = pipeline(\"summarization\", model=\"t5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dccfceba-24d9-43c3-8c01-223366664023",
   "metadata": {
    "id": "I6d2uxw5HSmP",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 256, but you input_length is only 180. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=90)\n",
      "Your max_length is set to 256, but you input_length is only 129. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=64)\n",
      "Your max_length is set to 256, but you input_length is only 232. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=116)\n",
      "Your max_length is set to 256, but you input_length is only 66. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=33)\n",
      "Your max_length is set to 256, but you input_length is only 174. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=87)\n",
      "Your max_length is set to 256, but you input_length is only 242. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=121)\n",
      "Your max_length is set to 256, but you input_length is only 230. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=115)\n",
      "Your max_length is set to 256, but you input_length is only 205. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=102)\n",
      "Your max_length is set to 256, but you input_length is only 235. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=117)\n",
      "Your max_length is set to 256, but you input_length is only 252. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=126)\n",
      "Your max_length is set to 256, but you input_length is only 94. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=47)\n",
      "Your max_length is set to 256, but you input_length is only 178. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=89)\n",
      "Your max_length is set to 256, but you input_length is only 219. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=109)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last Article She tweeted that the clothes would be \"archived & expertly cared for in the spirit & love of Michael Jackson, his bravery, & fans worldwide\". The auction included a jacket worn during Jackson's Bad tour, that went for $240,000 (£148,000) and two crystal gloves. The items were all made by designers Dennis Tompkins and Michael Bush. Lady Gaga also tweeted a picture of herself and her bidding paddle at the auction. More than $5m (£3.1m) was raised by the sale, according to LA-based Julien's Auctions. Other items that went under the hammer included jackets from Michael Jackson's Dangerous and Thriller tours and a pair of jeans that went for $50,000 (£31,000). Some of the money raised by the auction is being donated to a guide dogs charity and a hospice in Las Vegas. American costume designers Michael Bush and Dennis Tompkins created thousands of original pieces for Michael Jackson during his career. However, despite Lady Gaga's assurances, some fans expressed their anger online, claiming that Jackson wanted his costumes to end up in a museum. The singer died on 25 June 2009 from an overdose of the powerful anaesthetic propofol. His personal doctor, Conrad Murray, was later found guilty of his involuntary manslaughter and sentenced to four years in jail. Follow @BBCNewsbeat on Twitter\n",
      "Last Reference Summary ['Lady Gaga has bought 55 items at an auction of Michael Jackson costumes in Los Angeles.']\n",
      "Last Candidate Summary [\"lady gaga tweets picture of herself and her bidding paddle at the auction . more than $5m (£3.1m) raised by the sale, according to Julien's Auctions . a jacket worn during the singer's Bad tour went for $240,000 (£148,000)\"]\n",
      "rouge1 average : 0.20265121698626604\n",
      "rouge2 average : 0.029902470458162526\n",
      "rougeL average : 0.13754112876388588\n",
      "rougeLs average : 0.13754112876388588\n",
      "chrf average : 26.751616313269505\n"
     ]
    }
   ],
   "source": [
    "t5_scores(t5_base_summarizer, df, do_sample = True, num_beams = 4, top_k = 75)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec23ffe-1420-42f6-b532-f71147fa7973",
   "metadata": {},
   "source": [
    "### Model 2 **BEST MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2202955-2292-42f4-8b1e-694c05662f4e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304,
     "referenced_widgets": [
      "ba7aedd20a6648ef8a185ccdafed7e8b",
      "933dc51c4da540548c0cfcf5e150ea91",
      "94df7115be184ffd8463594aac55bcdf",
      "5f197f56a4cd445ba05c85284ee3ec7e",
      "a2952a3f474a409cae3fa7b79d298e1b",
      "b964caed365641f1aeb45e854e6cc713",
      "6272d18c91b0410a9e7abe6fabc411f5",
      "7932031c215a4a1daa1a224466aefd71",
      "43eaf8ef47e24d21b026ed15c6bb1330",
      "347720887c674d5e8c3f3517640210b6",
      "e5c1a1acf50b4628bf49c5f12c957de5",
      "b08a484821a342be8cac89531bf1e819",
      "a23c9940ef754ad393b04ad53766d010",
      "422fc8045bee49929353e7f853a7fc55",
      "933edd679283492f807c6eb55e63ed5b",
      "19f63aeab94340ca8ce50452f8dff6fe",
      "4312bcd28cab4b44a74694c957a6aeca",
      "e786ad36ddec4e81853e5b7ff1aacd38",
      "78dcc03fa242497bbed02fe2f965b34c",
      "8de61bc8199e4d34804fefee0f629f1e",
      "d4105ed41406417daa6b85dbe6bd9292",
      "913a9b310bfc457aa4120b3f39771282",
      "8fab1db75a5347e5a0c4cdc21824e05b",
      "a74886c7792f479e9031f8ea465e1611",
      "8e03e758f15346078795ba5182fdf3af",
      "436e0775c66b43ee98ad1ae7b4d579c9",
      "2c663af838b3438f9a92784b77d90502",
      "06e7b3ca9aa3413ca74235631bf89d0c",
      "3da668068e0048a7a27d27380d876359",
      "46adf561fe584df2a7769a80c196135c",
      "1cce6ca7f0d6499fb90e0ac0539be31c",
      "697d24714a4a460691bd359e652fe57c",
      "d76ee6a160fa463bab9a39708f46fbe5",
      "1f2d56349cf644268faf5e024dfab11b",
      "2a689d9bf81d4d8aafdb800e5030e23d",
      "219f03a10fea4015b8e80ef187adf790",
      "1d3fc1246b0744c0b788f4d9782ec642",
      "59e9d042caae4429af6feed04a08e6a3",
      "a12aa51b863845649c6b2c8961a71154",
      "28b0d2253b9d4192938ea04acf6a9429",
      "1aa20fbd49024695ab54472a3b6a822b",
      "a263083685ea46668e45e9de47c831fc",
      "27629dcc14344e00a48ffaf1cf15bad4",
      "bf562048159c454ba24b3e57c8d10e1d",
      "e91c9346498d425283e4a14712ea0240",
      "055c13c11415442684e190a1c46aea79",
      "09d86116305e4b688241381b5fea2a68",
      "51cd0d37d90c490ea427af4e3b6db9d8",
      "f538b1c3da184d0bbacb33c1508c8c27",
      "3845e81cfe5148dbb0b082bf308c0ad8",
      "738c986517e3443eaf602626384e0d2a",
      "f7f1adc17d1f439e81e123f0c4d8b9a0",
      "36fa961e0abf424e9dfe4691ae1ab638",
      "4923e266703c4a18a45aadec39e65daa",
      "5fd5f773740140e1b769d2d786fab2b4"
     ]
    },
    "id": "WN8kYhZcHSvR",
    "outputId": "931472ef-df5d-4c9e-dbae-5abe2108c48d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba7aedd20a6648ef8a185ccdafed7e8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b08a484821a342be8cac89531bf1e819",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/892M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fab1db75a5347e5a0c4cdc21824e05b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f2d56349cf644268faf5e024dfab11b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ve/main/spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e91c9346498d425283e4a14712ea0240",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "t5_base_summarizer = pipeline(\"summarization\", model=\"t5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "112af5e8-0e4f-46c5-93ce-686106dc5f41",
   "metadata": {
    "id": "I6d2uxw5HSmP",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 256, but you input_length is only 180. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=90)\n",
      "Your max_length is set to 256, but you input_length is only 129. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=64)\n",
      "Your max_length is set to 256, but you input_length is only 232. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=116)\n",
      "Your max_length is set to 256, but you input_length is only 66. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=33)\n",
      "Your max_length is set to 256, but you input_length is only 174. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=87)\n",
      "Your max_length is set to 256, but you input_length is only 242. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=121)\n",
      "Your max_length is set to 256, but you input_length is only 230. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=115)\n",
      "Your max_length is set to 256, but you input_length is only 205. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=102)\n",
      "Your max_length is set to 256, but you input_length is only 235. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=117)\n",
      "Your max_length is set to 256, but you input_length is only 252. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=126)\n",
      "Your max_length is set to 256, but you input_length is only 94. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=47)\n",
      "Your max_length is set to 256, but you input_length is only 178. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=89)\n",
      "Your max_length is set to 256, but you input_length is only 219. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=109)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last Article She tweeted that the clothes would be \"archived & expertly cared for in the spirit & love of Michael Jackson, his bravery, & fans worldwide\". The auction included a jacket worn during Jackson's Bad tour, that went for $240,000 (£148,000) and two crystal gloves. The items were all made by designers Dennis Tompkins and Michael Bush. Lady Gaga also tweeted a picture of herself and her bidding paddle at the auction. More than $5m (£3.1m) was raised by the sale, according to LA-based Julien's Auctions. Other items that went under the hammer included jackets from Michael Jackson's Dangerous and Thriller tours and a pair of jeans that went for $50,000 (£31,000). Some of the money raised by the auction is being donated to a guide dogs charity and a hospice in Las Vegas. American costume designers Michael Bush and Dennis Tompkins created thousands of original pieces for Michael Jackson during his career. However, despite Lady Gaga's assurances, some fans expressed their anger online, claiming that Jackson wanted his costumes to end up in a museum. The singer died on 25 June 2009 from an overdose of the powerful anaesthetic propofol. His personal doctor, Conrad Murray, was later found guilty of his involuntary manslaughter and sentenced to four years in jail. Follow @BBCNewsbeat on Twitter\n",
      "Last Reference Summary ['Lady Gaga has bought 55 items at an auction of Michael Jackson costumes in Los Angeles.']\n",
      "Last Candidate Summary [\"lady gaga tweets picture of herself and her bidding paddle at the auction . more than $5m (£3.1m) raised by the sale, according to Julien's Auctions . some of the money raised is being donated to a guide dogs charity and a hospice .\"]\n",
      "rouge1 average : 0.19838410684555607\n",
      "rouge2 average : 0.03184249989663364\n",
      "rougeL average : 0.13755103535459642\n",
      "rougeLs average : 0.13755103535459642\n",
      "chrf average : 26.815952650020275\n"
     ]
    }
   ],
   "source": [
    "t5_scores(t5_base_summarizer, df, do_sample = False, num_beams = 4, top_k = 75, num_beam_groups = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c119fd-ad02-41d4-be6b-4469950f840d",
   "metadata": {},
   "source": [
    "### Testing Best Untrained Model From Above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a17e2ec-f3f2-4731-9c2f-0362036de24f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t5_base_summarizer = pipeline(\"summarization\", model=\"t5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38e2ece1-4f35-4270-ad4b-c84d2cab4e33",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 256, but you input_length is only 99. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=49)\n",
      "Your max_length is set to 256, but you input_length is only 96. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=48)\n",
      "Your max_length is set to 256, but you input_length is only 204. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=102)\n",
      "Your max_length is set to 256, but you input_length is only 213. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=106)\n",
      "Your max_length is set to 256, but you input_length is only 243. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=121)\n",
      "Your max_length is set to 256, but you input_length is only 192. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=96)\n",
      "Your max_length is set to 256, but you input_length is only 223. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=111)\n",
      "Your max_length is set to 256, but you input_length is only 211. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=105)\n",
      "Your max_length is set to 256, but you input_length is only 206. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=103)\n",
      "Your max_length is set to 256, but you input_length is only 202. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=101)\n",
      "Your max_length is set to 256, but you input_length is only 230. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=115)\n",
      "Your max_length is set to 256, but you input_length is only 76. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=38)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last Article She tweeted that the clothes would be \"archived & expertly cared for in the spirit & love of Michael Jackson, his bravery, & fans worldwide\". The auction included a jacket worn during Jackson's Bad tour, that went for $240,000 (£148,000) and two crystal gloves. The items were all made by designers Dennis Tompkins and Michael Bush. Lady Gaga also tweeted a picture of herself and her bidding paddle at the auction. More than $5m (£3.1m) was raised by the sale, according to LA-based Julien's Auctions. Other items that went under the hammer included jackets from Michael Jackson's Dangerous and Thriller tours and a pair of jeans that went for $50,000 (£31,000). Some of the money raised by the auction is being donated to a guide dogs charity and a hospice in Las Vegas. American costume designers Michael Bush and Dennis Tompkins created thousands of original pieces for Michael Jackson during his career. However, despite Lady Gaga's assurances, some fans expressed their anger online, claiming that Jackson wanted his costumes to end up in a museum. The singer died on 25 June 2009 from an overdose of the powerful anaesthetic propofol. His personal doctor, Conrad Murray, was later found guilty of his involuntary manslaughter and sentenced to four years in jail. Follow @BBCNewsbeat on Twitter\n",
      "Last Reference Summary [\"The widespread coverage and high drama of the Fifa Women's World Cup has sparked football fever across the UK, with a record-breaking 6.9 million people watching England's most recent clash. There were still far more people watching men's World Cup matches, with 26.5 million viewers tuning in to see England knocked out last year. But there are some ways women's football is hitting the back of the net - while the male strand of the sometimes-beautiful game bounces disappointingly off the crossbar.\"]\n",
      "Last Candidate Summary [\"the best seats in the house for the men's final cost an eye-watering 66,000 roubles (£824.44) but it's still possible for you to go to a world cup final . at the women's world cup in France this year, you can actually watch a game for as little as £8.05 (9EUR)\"]\n",
      "rouge1 average : 0.20696283047603609\n",
      "rouge2 average : 0.04017271566660005\n",
      "rougeL average : 0.1447713155898578\n",
      "rougeLs average : 0.1447713155898578\n",
      "chrf average : 27.761420857966414\n"
     ]
    }
   ],
   "source": [
    "t5_scores(t5_base_summarizer, dft, do_sample = False, num_beams = 4, top_k = 75, num_beam_groups = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3168e22",
   "metadata": {},
   "source": [
    "## Models (Trained)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdae58a-e4c0-4a6c-8f67-b8309a24c665",
   "metadata": {},
   "source": [
    "### Model 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "41489617-caa3-421b-861a-7716cb853985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/home/ubuntu/w266/lib/python3.8/site-packages/torch/cuda/__init__.py:546: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "04/08/2023 03:12:28 - WARNING - __main__ - Process rank: -1, device: cpu, n_gpu: 0distributed training: False, 16-bits training: False\n",
      "04/08/2023 03:12:28 - INFO - __main__ - Training/evaluation parameters Seq2SeqTrainingArguments(\n",
      "_n_gpu=0,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "generation_config=None,\n",
      "generation_max_length=None,\n",
      "generation_num_beams=None,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=5e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=T5/model_0/runs/Apr08_03-12-28_ip-172-31-55-240,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=500,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=linear,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=5.0,\n",
      "optim=adamw_hf,\n",
      "optim_args=None,\n",
      "output_dir=T5/model_0/,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=32,\n",
      "predict_with_generate=True,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=['tensorboard'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=T5/model_0/,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=steps,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "sortish_sampler=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "04/08/2023 03:12:28 - INFO - datasets.builder - Using custom data configuration default-6794da18f7676227\n",
      "04/08/2023 03:12:28 - INFO - datasets.info - Loading Dataset Infos from /home/ubuntu/w266/lib/python3.8/site-packages/datasets/packaged_modules/csv\n",
      "04/08/2023 03:12:28 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "04/08/2023 03:12:28 - INFO - datasets.info - Loading Dataset info from /home/ubuntu/.cache/huggingface/datasets/csv/default-6794da18f7676227/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\n",
      "04/08/2023 03:12:28 - WARNING - datasets.builder - Found cached dataset csv (/home/ubuntu/.cache/huggingface/datasets/csv/default-6794da18f7676227/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n",
      "04/08/2023 03:12:28 - INFO - datasets.info - Loading Dataset info from /home/ubuntu/.cache/huggingface/datasets/csv/default-6794da18f7676227/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 665.13it/s]\n",
      "[INFO|configuration_utils.py:668] 2023-04-08 03:12:29,071 >> loading configuration file config.json from cache at /home/ubuntu/.cache/huggingface/hub/models--T5-small/snapshots/5bf53e1f76b1430d9302d735c613c5f5677e32a6/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-04-08 03:12:29,074 >> Model config T5Config {\n",
      "  \"_name_or_path\": \"T5-small\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.28.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_auto.py:494] 2023-04-08 03:12:29,129 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "[INFO|configuration_utils.py:668] 2023-04-08 03:12:29,182 >> loading configuration file config.json from cache at /home/ubuntu/.cache/huggingface/hub/models--T5-small/snapshots/5bf53e1f76b1430d9302d735c613c5f5677e32a6/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-04-08 03:12:29,183 >> Model config T5Config {\n",
      "  \"_name_or_path\": \"T5-small\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.28.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1809] 2023-04-08 03:12:29,291 >> loading file spiece.model from cache at /home/ubuntu/.cache/huggingface/hub/models--T5-small/snapshots/5bf53e1f76b1430d9302d735c613c5f5677e32a6/spiece.model\n",
      "[INFO|tokenization_utils_base.py:1809] 2023-04-08 03:12:29,292 >> loading file tokenizer.json from cache at /home/ubuntu/.cache/huggingface/hub/models--T5-small/snapshots/5bf53e1f76b1430d9302d735c613c5f5677e32a6/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:1809] 2023-04-08 03:12:29,292 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1809] 2023-04-08 03:12:29,292 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1809] 2023-04-08 03:12:29,292 >> loading file tokenizer_config.json from cache at None\n",
      "[INFO|configuration_utils.py:668] 2023-04-08 03:12:29,292 >> loading configuration file config.json from cache at /home/ubuntu/.cache/huggingface/hub/models--T5-small/snapshots/5bf53e1f76b1430d9302d735c613c5f5677e32a6/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-04-08 03:12:29,293 >> Model config T5Config {\n",
      "  \"_name_or_path\": \"T5-small\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.28.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:2451] 2023-04-08 03:12:29,355 >> loading weights file pytorch_model.bin from cache at /home/ubuntu/.cache/huggingface/hub/models--T5-small/snapshots/5bf53e1f76b1430d9302d735c613c5f5677e32a6/pytorch_model.bin\n",
      "[INFO|configuration_utils.py:575] 2023-04-08 03:12:29,486 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.28.0.dev0\"\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3100] 2023-04-08 03:12:30,391 >> All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
      "\n",
      "[INFO|modeling_utils.py:3108] 2023-04-08 03:12:30,391 >> All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at T5-small.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n",
      "[INFO|configuration_utils.py:537] 2023-04-08 03:12:30,456 >> loading configuration file generation_config.json from cache at /home/ubuntu/.cache/huggingface/hub/models--T5-small/snapshots/5bf53e1f76b1430d9302d735c613c5f5677e32a6/generation_config.json\n",
      "[INFO|configuration_utils.py:575] 2023-04-08 03:12:30,456 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.28.0.dev0\"\n",
      "}\n",
      "\n",
      "Running tokenizer on train dataset:   0%|       | 0/1000 [00:00<?, ? examples/s]04/08/2023 03:12:32 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/ubuntu/.cache/huggingface/datasets/csv/default-6794da18f7676227/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-0566c59384b447a2.arrow\n",
      "/home/ubuntu/w266/lib/python3.8/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "[INFO|trainer.py:1746] 2023-04-08 03:12:32,510 >> ***** Running training *****\n",
      "[INFO|trainer.py:1747] 2023-04-08 03:12:32,510 >>   Num examples = 1000\n",
      "[INFO|trainer.py:1748] 2023-04-08 03:12:32,510 >>   Num Epochs = 5\n",
      "[INFO|trainer.py:1749] 2023-04-08 03:12:32,510 >>   Instantaneous batch size per device = 32\n",
      "[INFO|trainer.py:1750] 2023-04-08 03:12:32,510 >>   Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "[INFO|trainer.py:1751] 2023-04-08 03:12:32,510 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1752] 2023-04-08 03:12:32,510 >>   Total optimization steps = 160\n",
      "[INFO|trainer.py:1753] 2023-04-08 03:12:32,511 >>   Number of trainable parameters = 60506624\n",
      "  0%|                                                   | 0/160 [00:00<?, ?it/s][WARNING|logging.py:280] 2023-04-08 03:12:32,532 >> You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "100%|█████████████████████████████████████████| 160/160 [26:07<00:00,  7.66s/it][INFO|trainer.py:2016] 2023-04-08 03:38:39,852 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "{'train_runtime': 1567.3408, 'train_samples_per_second': 3.19, 'train_steps_per_second': 0.102, 'train_loss': 3.0668127059936525, 'epoch': 5.0}\n",
      "100%|█████████████████████████████████████████| 160/160 [26:07<00:00,  9.80s/it]\n",
      "[INFO|trainer.py:2821] 2023-04-08 03:38:39,854 >> Saving model checkpoint to T5/model_0/\n",
      "[INFO|configuration_utils.py:457] 2023-04-08 03:38:39,855 >> Configuration saved in T5/model_0/config.json\n",
      "[INFO|configuration_utils.py:362] 2023-04-08 03:38:39,856 >> Configuration saved in T5/model_0/generation_config.json\n",
      "[INFO|modeling_utils.py:1812] 2023-04-08 03:38:40,916 >> Model weights saved in T5/model_0/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2170] 2023-04-08 03:38:40,917 >> tokenizer config file saved in T5/model_0/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2177] 2023-04-08 03:38:40,917 >> Special tokens file saved in T5/model_0/special_tokens_map.json\n",
      "[INFO|tokenization_t5_fast.py:186] 2023-04-08 03:38:40,958 >> Copy vocab file to T5/model_0/spiece.model\n",
      "***** train metrics *****\n",
      "  epoch                    =        5.0\n",
      "  train_loss               =     3.0668\n",
      "  train_runtime            = 0:26:07.34\n",
      "  train_samples            =       1000\n",
      "  train_samples_per_second =       3.19\n",
      "  train_steps_per_second   =      0.102\n",
      "[INFO|modelcard.py:451] 2023-04-08 03:38:41,047 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Summarization', 'type': 'summarization'}}\n"
     ]
    }
   ],
   "source": [
    "!python3 transformers/examples/pytorch/summarization/run_summarization.py \\\n",
    "    --model_name_or_path T5-small \\\n",
    "    --do_train \\\n",
    "    --train_file 'w266_project/Datasets/xl_sum_sample_train.csv' \\\n",
    "    --text_column text \\\n",
    "    --summary_column summary \\\n",
    "    --max_source_length 512 \\\n",
    "    --max_target_length 256 \\\n",
    "    --num_beams 5 \\\n",
    "    --num_train_epochs 5 \\\n",
    "    --source_prefix \"summarize: \" \\\n",
    "    --per_device_train_batch_size=32 \\\n",
    "    --output_dir='T5/model_0/' \\\n",
    "    --overwrite_output_dir=True \\\n",
    "    --predict_with_generate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7a1f378c-07b9-48ec-b77c-c4bc558143af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "summarizer = pipeline(\"summarization\", model=\"arisanguyen/finetuned_T5_all_categories\", revision = 'model_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5e2d5a66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Your max_length is set to 256, but you input_length is only 180. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=90)\n",
      "Your max_length is set to 256, but you input_length is only 129. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=64)\n",
      "Your max_length is set to 256, but you input_length is only 232. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=116)\n",
      "Your max_length is set to 256, but you input_length is only 66. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=33)\n",
      "Your max_length is set to 256, but you input_length is only 174. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=87)\n",
      "Your max_length is set to 256, but you input_length is only 242. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=121)\n",
      "Your max_length is set to 256, but you input_length is only 230. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=115)\n",
      "Your max_length is set to 256, but you input_length is only 205. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=102)\n",
      "Your max_length is set to 256, but you input_length is only 235. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=117)\n",
      "Your max_length is set to 256, but you input_length is only 252. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=126)\n",
      "Your max_length is set to 256, but you input_length is only 94. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=47)\n",
      "Your max_length is set to 256, but you input_length is only 178. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=89)\n",
      "Your max_length is set to 256, but you input_length is only 219. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=109)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last Article She tweeted that the clothes would be \"archived & expertly cared for in the spirit & love of Michael Jackson, his bravery, & fans worldwide\". The auction included a jacket worn during Jackson's Bad tour, that went for $240,000 (£148,000) and two crystal gloves. The items were all made by designers Dennis Tompkins and Michael Bush. Lady Gaga also tweeted a picture of herself and her bidding paddle at the auction. More than $5m (£3.1m) was raised by the sale, according to LA-based Julien's Auctions. Other items that went under the hammer included jackets from Michael Jackson's Dangerous and Thriller tours and a pair of jeans that went for $50,000 (£31,000). Some of the money raised by the auction is being donated to a guide dogs charity and a hospice in Las Vegas. American costume designers Michael Bush and Dennis Tompkins created thousands of original pieces for Michael Jackson during his career. However, despite Lady Gaga's assurances, some fans expressed their anger online, claiming that Jackson wanted his costumes to end up in a museum. The singer died on 25 June 2009 from an overdose of the powerful anaesthetic propofol. His personal doctor, Conrad Murray, was later found guilty of his involuntary manslaughter and sentenced to four years in jail. Follow @BBCNewsbeat on Twitter\n",
      "Last Reference Summary ['Lady Gaga has bought 55 items at an auction of Michael Jackson costumes in Los Angeles.']\n",
      "Last Candidate Summary ['The singer\\'s costume designer tweeted that the clothes would be \"archived & expertly cared for in the spirit & love of Michael Jackson, his bravery, & fans worldwide\".']\n",
      "rouge1 average : 0.2156110161066359\n",
      "rouge2 average : 0.046997075370725214\n",
      "rougeL average : 0.16316991423767827\n",
      "rougeLs average : 0.16316991423767827\n",
      "chrf average : 21.523406036627474\n"
     ]
    }
   ],
   "source": [
    "t5_scores(summarizer, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d13a90-11af-408d-83e4-525ef8b676ed",
   "metadata": {},
   "source": [
    "### Model 1: Increased epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b96ae72-4aca-4dbe-a1de-42b6770ac01a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/home/ubuntu/w266/lib/python3.8/site-packages/torch/cuda/__init__.py:546: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "04/16/2023 07:14:12 - WARNING - __main__ - Process rank: -1, device: cpu, n_gpu: 0distributed training: False, 16-bits training: False\n",
      "04/16/2023 07:14:12 - INFO - __main__ - Training/evaluation parameters Seq2SeqTrainingArguments(\n",
      "_n_gpu=0,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "generation_config=None,\n",
      "generation_max_length=None,\n",
      "generation_num_beams=None,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=5e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=T5/model_1/runs/Apr16_07-14-11_ip-172-31-55-240,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=500,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=linear,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=15.0,\n",
      "optim=adamw_hf,\n",
      "optim_args=None,\n",
      "output_dir=T5/model_1/,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=32,\n",
      "predict_with_generate=True,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=['tensorboard'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=T5/model_1/,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=steps,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "sortish_sampler=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "04/16/2023 07:14:12 - INFO - datasets.builder - Using custom data configuration default-484eaa2fa050cdb7\n",
      "04/16/2023 07:14:12 - INFO - datasets.info - Loading Dataset Infos from /home/ubuntu/w266/lib/python3.8/site-packages/datasets/packaged_modules/csv\n",
      "04/16/2023 07:14:12 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "04/16/2023 07:14:12 - INFO - datasets.info - Loading Dataset info from /home/ubuntu/.cache/huggingface/datasets/csv/default-484eaa2fa050cdb7/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\n",
      "04/16/2023 07:14:12 - WARNING - datasets.builder - Found cached dataset csv (/home/ubuntu/.cache/huggingface/datasets/csv/default-484eaa2fa050cdb7/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n",
      "04/16/2023 07:14:12 - INFO - datasets.info - Loading Dataset info from /home/ubuntu/.cache/huggingface/datasets/csv/default-484eaa2fa050cdb7/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 669.27it/s]\n",
      "[INFO|configuration_utils.py:668] 2023-04-16 07:14:12,378 >> loading configuration file config.json from cache at /home/ubuntu/.cache/huggingface/hub/models--T5-small/snapshots/5bf53e1f76b1430d9302d735c613c5f5677e32a6/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-04-16 07:14:12,381 >> Model config T5Config {\n",
      "  \"_name_or_path\": \"T5-small\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.28.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_auto.py:494] 2023-04-16 07:14:12,432 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "[INFO|configuration_utils.py:668] 2023-04-16 07:14:12,483 >> loading configuration file config.json from cache at /home/ubuntu/.cache/huggingface/hub/models--T5-small/snapshots/5bf53e1f76b1430d9302d735c613c5f5677e32a6/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-04-16 07:14:12,483 >> Model config T5Config {\n",
      "  \"_name_or_path\": \"T5-small\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.28.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1809] 2023-04-16 07:14:12,590 >> loading file spiece.model from cache at /home/ubuntu/.cache/huggingface/hub/models--T5-small/snapshots/5bf53e1f76b1430d9302d735c613c5f5677e32a6/spiece.model\n",
      "[INFO|tokenization_utils_base.py:1809] 2023-04-16 07:14:12,590 >> loading file tokenizer.json from cache at /home/ubuntu/.cache/huggingface/hub/models--T5-small/snapshots/5bf53e1f76b1430d9302d735c613c5f5677e32a6/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:1809] 2023-04-16 07:14:12,590 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1809] 2023-04-16 07:14:12,590 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1809] 2023-04-16 07:14:12,590 >> loading file tokenizer_config.json from cache at None\n",
      "[INFO|configuration_utils.py:668] 2023-04-16 07:14:12,590 >> loading configuration file config.json from cache at /home/ubuntu/.cache/huggingface/hub/models--T5-small/snapshots/5bf53e1f76b1430d9302d735c613c5f5677e32a6/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-04-16 07:14:12,591 >> Model config T5Config {\n",
      "  \"_name_or_path\": \"T5-small\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.28.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:2451] 2023-04-16 07:14:12,654 >> loading weights file pytorch_model.bin from cache at /home/ubuntu/.cache/huggingface/hub/models--T5-small/snapshots/5bf53e1f76b1430d9302d735c613c5f5677e32a6/pytorch_model.bin\n",
      "[INFO|configuration_utils.py:575] 2023-04-16 07:14:12,784 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.28.0.dev0\"\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3100] 2023-04-16 07:14:13,690 >> All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
      "\n",
      "[INFO|modeling_utils.py:3108] 2023-04-16 07:14:13,690 >> All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at T5-small.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n",
      "[INFO|configuration_utils.py:537] 2023-04-16 07:14:13,751 >> loading configuration file generation_config.json from cache at /home/ubuntu/.cache/huggingface/hub/models--T5-small/snapshots/5bf53e1f76b1430d9302d735c613c5f5677e32a6/generation_config.json\n",
      "[INFO|configuration_utils.py:575] 2023-04-16 07:14:13,752 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.28.0.dev0\"\n",
      "}\n",
      "\n",
      "04/16/2023 07:14:13 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/ubuntu/.cache/huggingface/datasets/csv/default-484eaa2fa050cdb7/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-c86d4ef66d6f61db.arrow\n",
      "/home/ubuntu/w266/lib/python3.8/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "[INFO|trainer.py:1746] 2023-04-16 07:14:13,862 >> ***** Running training *****\n",
      "[INFO|trainer.py:1747] 2023-04-16 07:14:13,862 >>   Num examples = 1000\n",
      "[INFO|trainer.py:1748] 2023-04-16 07:14:13,862 >>   Num Epochs = 15\n",
      "[INFO|trainer.py:1749] 2023-04-16 07:14:13,862 >>   Instantaneous batch size per device = 32\n",
      "[INFO|trainer.py:1750] 2023-04-16 07:14:13,862 >>   Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "[INFO|trainer.py:1751] 2023-04-16 07:14:13,862 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1752] 2023-04-16 07:14:13,862 >>   Total optimization steps = 480\n",
      "[INFO|trainer.py:1753] 2023-04-16 07:14:13,863 >>   Number of trainable parameters = 60506624\n",
      "  0%|                                                   | 0/480 [00:00<?, ?it/s][WARNING|logging.py:280] 2023-04-16 07:14:13,884 >> You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "100%|███████████████████████████████████████| 480/480 [1:37:00<00:00,  7.92s/it][INFO|trainer.py:2016] 2023-04-16 08:51:14,780 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "{'train_runtime': 5820.9169, 'train_samples_per_second': 2.577, 'train_steps_per_second': 0.082, 'train_loss': 2.8351732889811196, 'epoch': 15.0}\n",
      "100%|███████████████████████████████████████| 480/480 [1:37:00<00:00, 12.13s/it]\n",
      "[INFO|trainer.py:2821] 2023-04-16 08:51:14,783 >> Saving model checkpoint to T5/model_1/\n",
      "[INFO|configuration_utils.py:457] 2023-04-16 08:51:14,783 >> Configuration saved in T5/model_1/config.json\n",
      "[INFO|configuration_utils.py:362] 2023-04-16 08:51:14,785 >> Configuration saved in T5/model_1/generation_config.json\n",
      "[INFO|modeling_utils.py:1812] 2023-04-16 08:51:15,829 >> Model weights saved in T5/model_1/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2170] 2023-04-16 08:51:15,830 >> tokenizer config file saved in T5/model_1/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2177] 2023-04-16 08:51:15,830 >> Special tokens file saved in T5/model_1/special_tokens_map.json\n",
      "[INFO|tokenization_t5_fast.py:186] 2023-04-16 08:51:15,865 >> Copy vocab file to T5/model_1/spiece.model\n",
      "***** train metrics *****\n",
      "  epoch                    =       15.0\n",
      "  train_loss               =     2.8352\n",
      "  train_runtime            = 1:37:00.91\n",
      "  train_samples            =       1000\n",
      "  train_samples_per_second =      2.577\n",
      "  train_steps_per_second   =      0.082\n",
      "[INFO|modelcard.py:451] 2023-04-16 08:51:15,984 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Summarization', 'type': 'summarization'}}\n"
     ]
    }
   ],
   "source": [
    "!python3 ~/transformers/examples/pytorch/summarization/run_summarization.py \\\n",
    "    --model_name_or_path T5-small \\\n",
    "    --do_train \\\n",
    "    --train_file '../Data/xl_sum_sample_train.csv' \\\n",
    "    --text_column text \\\n",
    "    --summary_column summary \\\n",
    "    --max_source_length 512 \\\n",
    "    --max_target_length 256 \\\n",
    "    --num_beams 1 \\\n",
    "    --num_train_epochs 15 \\\n",
    "    --source_prefix \"summarize: \" \\\n",
    "    --per_device_train_batch_size=32 \\\n",
    "    --output_dir='T5/model_1/' \\\n",
    "    --overwrite_output_dir=True \\\n",
    "    --predict_with_generate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fcf4e642-73f8-4b03-911b-a7d7600ee6bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading pytorch_model.bin: 100%|██████████| 242M/242M [00:02<00:00, 103MB/s]\n",
      "Downloading (…)del_1/tokenizer.json: 100%|█| 2.42M/2.42M [00:00<00:00, 91.6MB/s]\n"
     ]
    }
   ],
   "source": [
    "summarizer = pipeline(\"summarization\", model=\"arisanguyen/finetuned_T5_all_categories\", revision = 'model_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2d395301-e194-4122-9e9c-a2ac2bb63fa4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 256, but you input_length is only 180. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=90)\n",
      "Your max_length is set to 256, but you input_length is only 129. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=64)\n",
      "Your max_length is set to 256, but you input_length is only 232. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=116)\n",
      "Your max_length is set to 256, but you input_length is only 66. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=33)\n",
      "Your max_length is set to 256, but you input_length is only 174. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=87)\n",
      "Your max_length is set to 256, but you input_length is only 242. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=121)\n",
      "Your max_length is set to 256, but you input_length is only 230. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=115)\n",
      "Your max_length is set to 256, but you input_length is only 205. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=102)\n",
      "Your max_length is set to 256, but you input_length is only 235. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=117)\n",
      "Your max_length is set to 256, but you input_length is only 252. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=126)\n",
      "Your max_length is set to 256, but you input_length is only 94. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=47)\n",
      "Your max_length is set to 256, but you input_length is only 178. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=89)\n",
      "Your max_length is set to 256, but you input_length is only 219. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=109)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last Article She tweeted that the clothes would be \"archived & expertly cared for in the spirit & love of Michael Jackson, his bravery, & fans worldwide\". The auction included a jacket worn during Jackson's Bad tour, that went for $240,000 (£148,000) and two crystal gloves. The items were all made by designers Dennis Tompkins and Michael Bush. Lady Gaga also tweeted a picture of herself and her bidding paddle at the auction. More than $5m (£3.1m) was raised by the sale, according to LA-based Julien's Auctions. Other items that went under the hammer included jackets from Michael Jackson's Dangerous and Thriller tours and a pair of jeans that went for $50,000 (£31,000). Some of the money raised by the auction is being donated to a guide dogs charity and a hospice in Las Vegas. American costume designers Michael Bush and Dennis Tompkins created thousands of original pieces for Michael Jackson during his career. However, despite Lady Gaga's assurances, some fans expressed their anger online, claiming that Jackson wanted his costumes to end up in a museum. The singer died on 25 June 2009 from an overdose of the powerful anaesthetic propofol. His personal doctor, Conrad Murray, was later found guilty of his involuntary manslaughter and sentenced to four years in jail. Follow @BBCNewsbeat on Twitter\n",
      "Last Reference Summary ['Lady Gaga has bought 55 items at an auction of Michael Jackson costumes in Los Angeles.']\n",
      "Last Candidate Summary ['The singer\\'s costume designer tweeted that the clothes would be \"archived & expertly cared for in the spirit & love of Michael Jackson, his bravery, & fans worldwide\".']\n",
      "rouge1 average : 0.2156110161066359\n",
      "rouge2 average : 0.046997075370725214\n",
      "rougeL average : 0.16316991423767827\n",
      "rougeLs average : 0.16316991423767827\n",
      "chrf average : 21.523406036627474\n"
     ]
    }
   ],
   "source": [
    "t5_scores(summarizer, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e923b21",
   "metadata": {},
   "source": [
    "### Model 2: Added beam groups for diversification. **BEST MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7b3a2a06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading pytorch_model.bin: 100%|██████████| 242M/242M [00:02<00:00, 102MB/s]\n",
      "Downloading (…)del_0/tokenizer.json: 100%|█| 2.42M/2.42M [00:00<00:00, 81.0MB/s]\n"
     ]
    }
   ],
   "source": [
    "summarizer = pipeline(\"summarization\", model=\"arisanguyen/finetuned_T5_all_categories\", revision = 'model_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0b9aa681",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 256, but you input_length is only 180. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=90)\n",
      "Your max_length is set to 256, but you input_length is only 129. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=64)\n",
      "Your max_length is set to 256, but you input_length is only 232. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=116)\n",
      "Your max_length is set to 256, but you input_length is only 66. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=33)\n",
      "Your max_length is set to 256, but you input_length is only 174. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=87)\n",
      "Your max_length is set to 256, but you input_length is only 242. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=121)\n",
      "Your max_length is set to 256, but you input_length is only 230. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=115)\n",
      "Your max_length is set to 256, but you input_length is only 205. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=102)\n",
      "Your max_length is set to 256, but you input_length is only 235. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=117)\n",
      "Your max_length is set to 256, but you input_length is only 252. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=126)\n",
      "Your max_length is set to 256, but you input_length is only 94. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=47)\n",
      "Your max_length is set to 256, but you input_length is only 178. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=89)\n",
      "Your max_length is set to 256, but you input_length is only 219. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=109)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last Article She tweeted that the clothes would be \"archived & expertly cared for in the spirit & love of Michael Jackson, his bravery, & fans worldwide\". The auction included a jacket worn during Jackson's Bad tour, that went for $240,000 (£148,000) and two crystal gloves. The items were all made by designers Dennis Tompkins and Michael Bush. Lady Gaga also tweeted a picture of herself and her bidding paddle at the auction. More than $5m (£3.1m) was raised by the sale, according to LA-based Julien's Auctions. Other items that went under the hammer included jackets from Michael Jackson's Dangerous and Thriller tours and a pair of jeans that went for $50,000 (£31,000). Some of the money raised by the auction is being donated to a guide dogs charity and a hospice in Las Vegas. American costume designers Michael Bush and Dennis Tompkins created thousands of original pieces for Michael Jackson during his career. However, despite Lady Gaga's assurances, some fans expressed their anger online, claiming that Jackson wanted his costumes to end up in a museum. The singer died on 25 June 2009 from an overdose of the powerful anaesthetic propofol. His personal doctor, Conrad Murray, was later found guilty of his involuntary manslaughter and sentenced to four years in jail. Follow @BBCNewsbeat on Twitter\n",
      "Last Reference Summary ['Lady Gaga has bought 55 items at an auction of Michael Jackson costumes in Los Angeles.']\n",
      "Last Candidate Summary [\"Michael Jackson's costumes were auctioned at a LA-based auction in 2009 .\"]\n",
      "rouge1 average : 0.22421392306785365\n",
      "rouge2 average : 0.04944011527345811\n",
      "rougeL average : 0.1697188215804628\n",
      "rougeLs average : 0.1697188215804628\n",
      "chrf average : 23.283361678177712\n"
     ]
    }
   ],
   "source": [
    "t5_scores(summarizer, df, do_sample = False, num_beams = 4, top_k = 75, num_beam_groups = 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
