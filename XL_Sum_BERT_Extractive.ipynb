{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d870553",
   "metadata": {},
   "source": [
    "**Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dacdaf3d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/w266/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-04-01 05:50:12.542574: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-01 05:50:13.397016: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/amazon/efa/lib:/opt/amazon/openmpi/lib:/usr/local/cuda/efa/lib:/usr/local/cuda/lib:/usr/local/cuda:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/targets/x86_64-linux/lib:/usr/local/lib:/usr/lib:/opt/amazon/efa/lib:/opt/amazon/openmpi/lib:/usr/local/cuda/efa/lib:/usr/local/cuda/lib:/usr/local/cuda:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/targets/x86_64-linux/lib:/usr/local/lib:/usr/lib:\n",
      "2023-04-01 05:50:13.397138: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/amazon/efa/lib:/opt/amazon/openmpi/lib:/usr/local/cuda/efa/lib:/usr/local/cuda/lib:/usr/local/cuda:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/targets/x86_64-linux/lib:/usr/local/lib:/usr/lib:/opt/amazon/efa/lib:/opt/amazon/openmpi/lib:/usr/local/cuda/efa/lib:/usr/local/cuda/lib:/usr/local/cuda:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/targets/x86_64-linux/lib:/usr/local/lib:/usr/lib:\n",
      "2023-04-01 05:50:13.397148: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "\n",
    "#let's make longer output readable without horizontal scrolling\n",
    "from pprint import pprint\n",
    "\n",
    "import warnings\n",
    "\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f29e293",
   "metadata": {},
   "source": [
    "**Necessary Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc5f44ab-39ad-49be-a367-c2ff78ac845a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import inspect\n",
    "\n",
    "def get_default_args(func):\n",
    "    signature = inspect.signature(func)\n",
    "    return {\n",
    "        k: v.default\n",
    "        for k, v in signature.parameters.items()\n",
    "        if v.default is not inspect.Parameter.empty\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f96edd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rouge = evaluate.load('rouge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e922d01-d029-42ee-bf38-6765115f1e04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chrf = evaluate.load(\"chrf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586a6d00",
   "metadata": {},
   "source": [
    "**Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec6c665e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset xlsum (/home/ubuntu/.cache/huggingface/datasets/csebuetnlp___xlsum/english/2.0.0/518ab0af76048660bcc2240ca6e8692a977c80e384ffb18fdddebaca6daebdce)\n",
      "100%|████████████████████████████████████████████| 3/3 [00:00<00:00, 324.73it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"csebuetnlp/xlsum\", \"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "296f3f54-85c7-4446-ae73-fa54ac3123a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>235420</th>\n",
       "      <td>235420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172024</th>\n",
       "      <td>172024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253546</th>\n",
       "      <td>253546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224954</th>\n",
       "      <td>224954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214134</th>\n",
       "      <td>214134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index\n",
       "235420  235420\n",
       "172024  172024\n",
       "253546  253546\n",
       "224954  224954\n",
       "214134  214134"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = pd.DataFrame({\"index\": list(range(len(dataset['train'])))})\n",
    "sample_index = index.sample(n=2000, replace=False, random_state=1004)\n",
    "sample_index[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6656d7bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m summary_num_sentences\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mlen\u001b[39m(dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m][i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msummary\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)))\n\u001b[1;32m     17\u001b[0m summary_num_characters\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mlen\u001b[39m(dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m][i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msummary\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[0;32m---> 18\u001b[0m article\u001b[38;5;241m.\u001b[39mappend(\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     19\u001b[0m article_num_sentences\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mlen\u001b[39m(dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m][i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)))\n\u001b[1;32m     20\u001b[0m article_num_characters\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mlen\u001b[39m(dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m][i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n",
      "File \u001b[0;32m~/w266/lib/python3.8/site-packages/datasets/arrow_dataset.py:2658\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2656\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):  \u001b[38;5;66;03m# noqa: F811\u001b[39;00m\n\u001b[1;32m   2657\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2658\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/w266/lib/python3.8/site-packages/datasets/arrow_dataset.py:2643\u001b[0m, in \u001b[0;36mDataset._getitem\u001b[0;34m(self, key, **kwargs)\u001b[0m\n\u001b[1;32m   2641\u001b[0m formatter \u001b[38;5;241m=\u001b[39m get_formatter(format_type, features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mformat_kwargs)\n\u001b[1;32m   2642\u001b[0m pa_subtable \u001b[38;5;241m=\u001b[39m query_table(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data, key, indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indices \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 2643\u001b[0m formatted_output \u001b[38;5;241m=\u001b[39m \u001b[43mformat_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2644\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpa_subtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformatter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformat_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformat_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_all_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_all_columns\u001b[49m\n\u001b[1;32m   2645\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2646\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m formatted_output\n",
      "File \u001b[0;32m~/w266/lib/python3.8/site-packages/datasets/formatting/formatting.py:634\u001b[0m, in \u001b[0;36mformat_table\u001b[0;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[1;32m    632\u001b[0m python_formatter \u001b[38;5;241m=\u001b[39m PythonFormatter(features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m format_columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 634\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    636\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m format_columns:\n",
      "File \u001b[0;32m~/w266/lib/python3.8/site-packages/datasets/formatting/formatting.py:406\u001b[0m, in \u001b[0;36mFormatter.__call__\u001b[0;34m(self, pa_table, query_type)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pa_table: pa\u001b[38;5;241m.\u001b[39mTable, query_type: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[RowFormat, ColumnFormat, BatchFormat]:\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 406\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_row\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    407\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    408\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_column(pa_table)\n",
      "File \u001b[0;32m~/w266/lib/python3.8/site-packages/datasets/formatting/formatting.py:441\u001b[0m, in \u001b[0;36mPythonFormatter.format_row\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlazy:\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m LazyRow(pa_table, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 441\u001b[0m row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpython_arrow_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_row\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    442\u001b[0m row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_features_decoder\u001b[38;5;241m.\u001b[39mdecode_row(row)\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m row\n",
      "File \u001b[0;32m~/w266/lib/python3.8/site-packages/datasets/formatting/formatting.py:144\u001b[0m, in \u001b[0;36mPythonArrowExtractor.extract_row\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_row\u001b[39m(\u001b[38;5;28mself\u001b[39m, pa_table: pa\u001b[38;5;241m.\u001b[39mTable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unnest(\u001b[43mpa_table\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_pydict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "id = []\n",
    "url = []\n",
    "title = []\n",
    "article = []\n",
    "article_num_sentences = []\n",
    "article_num_characters = []\n",
    "summary = []\n",
    "summary_num_sentences = []\n",
    "summary_num_characters = []\n",
    "\n",
    "for i in sample_index[\"index\"]:\n",
    "    id.append(dataset[\"train\"][i]['id'])\n",
    "    url.append(dataset[\"train\"][i]['url'])\n",
    "    title.append(dataset[\"train\"][i]['title'])\n",
    "    summary.append(dataset[\"train\"][i]['summary'])\n",
    "    summary_num_sentences.append(len(dataset[\"train\"][i]['summary'].split(\".\")))\n",
    "    summary_num_characters.append(len(dataset[\"train\"][i]['summary']))\n",
    "    article.append(dataset[\"train\"][i]['text'])\n",
    "    article_num_sentences.append(len(dataset[\"train\"][i]['text'].split(\".\")))\n",
    "    article_num_characters.append(len(dataset[\"train\"][i]['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66def3a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "d = {'id': id, 'url': url, \"title\": title, 'article': article, \"article_num_sentences\": article_num_sentences, \"article_num_characters\": article_num_characters, 'summary': summary,\"summary_num_sentences\": summary_num_sentences, \"summary_num_characters\": summary_num_characters}\n",
    "df = pd.DataFrame(data=d)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564f872e-a7c8-4058-8ba0-7935db2207b0",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Default Hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a312a65-1c63-4251-8553-c66959b057a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from summarizer import Summarizer\n",
    "\n",
    "model = Summarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8edfe31-ebe3-4c38-b8ef-7df7a013d1fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "get_default_args(Summarizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c09bea-3299-40b8-a6a2-a7a38c9c0c26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "get_default_args(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4266569",
   "metadata": {},
   "source": [
    "**BERT Extractive Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201c76d1-50eb-4560-b78c-3f05e2c0fe3e",
   "metadata": {},
   "source": [
    "Model 0: Default Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fd59b8-44ed-4497-9f64-f0d14abbdecd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from summarizer import Summarizer\n",
    "\n",
    "model = Summarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9232aa-5fa4-4beb-a11a-e25092a1cdda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "bert_r1 = []\n",
    "bert_r2 = []\n",
    "bert_rL = []\n",
    "bert_rLs = []\n",
    "bert_chrf = []\n",
    "\n",
    "for i in range(int(len(df['article'])/2)):\n",
    "    \n",
    "    candidate = model(df['article'][i],\n",
    "                     )\n",
    "    candidate = [candidate]\n",
    "    #pprint(candidate[0], compact=True)\n",
    "    \n",
    "    ref = [df['summary'][i]]\n",
    "    \n",
    "    results = rouge.compute(predictions=candidate,\n",
    "                            references=ref)\n",
    "    \n",
    "    results2 = chrf.compute(predictions=candidate,\n",
    "                            references= ref)\n",
    "    \n",
    "    bert_r1.append(results['rouge1'])\n",
    "    bert_r2.append(results['rouge2'])\n",
    "    bert_rL.append(results['rougeL'])\n",
    "    bert_rLs.append(results['rougeLsum'])\n",
    "    \n",
    "    bert_chrf.append(results2['score'])\n",
    "    \n",
    "    if i in np.arange(0, (len(df['article']) + 101), 100):\n",
    "        data = {'rouge1': bert_r1, 'rouge2': bert_r2, 'rogueL': bert_rL, 'rogueLs': bert_rLs, 'chrf': bert_chrf}\n",
    "        scores = pd.DataFrame(data)\n",
    "        scores.to_csv(r'BERT_0_scores.csv', index=False)\n",
    "        print(i)\n",
    "\n",
    "data = {'rouge1': bert_r1, 'rouge2': bert_r2, 'rogueL': bert_rL, 'rogueLs': bert_rLs, 'chrf': bert_chrf}\n",
    "scores = pd.DataFrame(data)\n",
    "scores.to_csv(r'BERT_0_scores.csv', index=False)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3230aee-fe28-4099-ae35-b9fd18f5d2f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('rouge1 average :', np.mean(bert_r1))\n",
    "print('rouge2 average :', np.mean(bert_r2))\n",
    "print('rougeL average :', np.mean(bert_rL))\n",
    "print('rougeLs average :', np.mean(bert_rLs))\n",
    "print('chrf average:', np.mean(bert_chrf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c846d219-5c6b-47b6-ae81-9a61e241ac74",
   "metadata": {
    "tags": []
   },
   "source": [
    "Finetuning On First 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d9ce16-2e35-453d-8c3a-f1e1d354c68c",
   "metadata": {},
   "source": [
    "Model 1. Adjusted min_length, max_length, num_sentences (which overrides ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dde227-1016-4f35-a0cd-b6a2f3d5f587",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from summarizer import Summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462afc0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Using bert-base instead of bert-large to reduce run times\n",
    "model = Summarizer(model='bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2595b5cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "bert_r1 = []\n",
    "bert_r2 = []\n",
    "bert_rL = []\n",
    "bert_rLs = []\n",
    "\n",
    "for i in range(int(len(df['article'])/2)):\n",
    "    \n",
    "    # Limiting number sentences in each summary generated to 2 sentences \n",
    "    candidate = model(df['article'][i], \n",
    "                      num_sentences = round(df[\"summary_num_sentences\"][:1000].mean()), \n",
    "                      min_length = min(df[\"summary_num_characters\"][:1000]),\n",
    "                      max_length = max(df[\"summary_num_characters\"][:1000]),        \n",
    "                      ratio = None,\n",
    "                      use_first = None,\n",
    "                     )\n",
    "    candidate = [candidate]\n",
    "    #pprint(candidate[0], compact=True)\n",
    "    \n",
    "    ref = [df['summary'][i]]\n",
    "    \n",
    "    results = rouge.compute(predictions=candidate,\n",
    "                            references=ref)\n",
    "    \n",
    "    results2 = chrf.compute(predictions=candidate,\n",
    "                            references= ref)\n",
    "    \n",
    "    bert_r1.append(results['rouge1'])\n",
    "    bert_r2.append(results['rouge2'])\n",
    "    bert_rL.append(results['rougeL'])\n",
    "    bert_rLs.append(results['rougeLsum'])\n",
    "    \n",
    "    bert_chrf.append(results2['score'])\n",
    "    \n",
    "    if i in np.arange(0, (len(df['article']) + 101), 100):\n",
    "        data = {'rouge1': bert_r1, 'rouge2': bert_r2, 'rogueL': bert_rL, 'rogueLs': bert_rLs, 'chrf': bert_chrf}\n",
    "        scores = pd.DataFrame(data)\n",
    "        scores.to_csv(r'BERT_1_scores.csv', index=False)\n",
    "        print(i)\n",
    "        \n",
    "data = {'rouge1': bert_r1, 'rouge2': bert_r2, 'rogueL': bert_rL, 'rogueLs': bert_rLs, 'chrf': bert_chrf}\n",
    "scores = pd.DataFrame(data)\n",
    "scores.to_csv(r'BERT_1_scores.csv', index=False)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97555fa3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('rouge1 average :', np.mean(bert_r1))\n",
    "print('rouge2 average :', np.mean(bert_r2))\n",
    "print('rougeL average :', np.mean(bert_rL))\n",
    "print('rougeLs average :', np.mean(bert_rLs))\n",
    "print('chrf average:', np.mean(bert_chrf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec631b8-e0a8-40ac-8f16-fe3094b118cc",
   "metadata": {},
   "source": [
    "Tuning Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96727286-a2e4-4e08-a014-1d205a55dc44",
   "metadata": {},
   "source": [
    "2. Made num_sentences based off number of clusters instead of average "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b71359-02c7-4236-b22e-5eb077d02a0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from summarizer import Summarizer\n",
    "\n",
    "model = Summarizer(model='bert-base-uncased',\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e007312b-1348-45d4-ab1b-f32c270bb415",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "bert_r1 = []\n",
    "bert_r2 = []\n",
    "bert_rL = []\n",
    "bert_rLs = []\n",
    "\n",
    "for i in range(int(len(df['article'])/2)):\n",
    "\n",
    "    res = model.calculate_optimal_k(df['article'][i], k_max=10)\n",
    "    \n",
    "    candidate = model(df['article'][i], \n",
    "                      num_sentences = res, # number of sentences determined by number of clusters\n",
    "                      min_length = min(df[\"summary_num_characters\"][:1000]),\n",
    "                      max_length = max(df[\"summary_num_characters\"][:1000]),        \n",
    "                      ratio = None,\n",
    "                      use_first = None,)\n",
    "    candidate = [candidate]\n",
    "    #pprint(candidate[0], compact=True)\n",
    "    \n",
    "    ref = [df['summary'][i]]\n",
    "    \n",
    "    results = rouge.compute(predictions=candidate,\n",
    "                            references=ref)\n",
    "    \n",
    "    results2 = chrf.compute(predictions=candidate,\n",
    "                            references= ref)\n",
    "    \n",
    "    bert_chrf.append(results2['score'])\n",
    "    \n",
    "    bert_r1.append(results['rouge1'])\n",
    "    bert_r2.append(results['rouge2'])\n",
    "    bert_rL.append(results['rougeL'])\n",
    "    bert_rLs.append(results['rougeLsum'])\n",
    "    \n",
    "    if i in np.arange(0, (len(df['article']) + 101), 100):\n",
    "        data = {'rouge1': bert_r1, 'rouge2': bert_r2, 'rogueL': bert_rL, 'rogueLs': bert_rLs, 'chrf': bert_chrf}\n",
    "        scores = pd.DataFrame(data)\n",
    "        scores.to_csv(r'BERT_2_scores.csv', index=False)\n",
    "        print(i)\n",
    "        \n",
    "data = {'rouge1': bert_r1, 'rouge2': bert_r2, 'rogueL': bert_rL, 'rogueLs': bert_rLs, 'chrf': bert_chrf}\n",
    "scores = pd.DataFrame(data)\n",
    "scores.to_csv(r'BERT_2_scores.csv', index=False)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701447ab-000a-4aea-865a-c5244b0f342c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('rouge1 average :', np.mean(bert_r1))\n",
    "print('rouge2 average :', np.mean(bert_r2))\n",
    "print('rougeL average :', np.mean(bert_rL))\n",
    "print('rougeLs average :', np.mean(bert_rLs))\n",
    "print('chrf average:', np.mean(bert_chrf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fd8b62-7d3b-4a03-af4c-c9ecec023faa",
   "metadata": {},
   "source": [
    "3. Setting number of sentences with clusters didn't help in second model, so we are reverting back to first model but setting use_first = False bc many examples have meta data in first sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74b6df2-673c-4083-9939-6e30b722df4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from summarizer import Summarizer\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "model = Summarizer(model='bert-base-uncased',\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815245f2-2673-4ac4-a2c3-4085e5b920aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "bert_r1 = []\n",
    "bert_r2 = []\n",
    "bert_rL = []\n",
    "bert_rLs = []\n",
    "\n",
    "for i in range(int(len(df['article'])/2)):\n",
    "    \n",
    "    # Limiting number sentences in each summary generated to 2 sentences \n",
    "    candidate = model(df['article'][i], \n",
    "                      num_sentences = round(df[\"summary_num_sentences\"][:1000].mean()), \n",
    "                      min_length = min(df[\"summary_num_characters\"][:1000]),\n",
    "                      max_length = max(df[\"summary_num_characters\"][:1000]),        \n",
    "                      ratio = None,\n",
    "                      use_first = False,\n",
    "                     )\n",
    "    candidate = [candidate]\n",
    "    #pprint(candidate[0], compact=True)\n",
    "    \n",
    "    ref = [df['summary'][i]]\n",
    "    \n",
    "    results = rouge.compute(predictions=candidate,\n",
    "                            references=ref)\n",
    "    \n",
    "    results2 = chrf.compute(predictions=candidate,\n",
    "                            references= ref\n",
    "    \n",
    "    bert_chrf.append(results2['score'])\n",
    "                            \n",
    "    bert_r1.append(results['rouge1'])\n",
    "    bert_r2.append(results['rouge2'])\n",
    "    bert_rL.append(results['rougeL'])\n",
    "    bert_rLs.append(results['rougeLsum'])\n",
    "    \n",
    "    if i in np.arange(0, (len(df['article']) + 101), 100):\n",
    "        data = {'rouge1': bert_r1, 'rouge2': bert_r2, 'rogueL': bert_rL, 'rogueLs': bert_rLs, 'chrf': bert_chrf}\n",
    "        scores = pd.DataFrame(data)\n",
    "        scores.to_csv(r'BERT_3_scores.csv', index=False)\n",
    "        print(i)\n",
    "\n",
    "data = {'rouge1': bert_r1, 'rouge2': bert_r2, 'rogueL': bert_rL, 'rogueLs': bert_rLs, 'chrf': bert_chrf}\n",
    "scores = pd.DataFrame(data)\n",
    "scores.to_csv(r'BERT_3_scores.csv', index=False)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29baf035-e761-40da-abc0-9dd6ac2de9b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('rouge1 average :', np.mean(bert_r1))\n",
    "print('rouge2 average :', np.mean(bert_r2))\n",
    "print('rougeL average :', np.mean(bert_rL))\n",
    "print('rougeLs average :', np.mean(bert_rLs))\n",
    "print('chrf average:', np.mean(bert_chrf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1715530b-d2c9-45bb-9152-423e3acc7394",
   "metadata": {},
   "source": [
    "4. Setting use_first = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1bd98a-1738-4785-8d76-d463896cfc53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from summarizer import Summarizer\n",
    "\n",
    "model = Summarizer(model='bert-base-uncased',\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ef153b-ad2e-4059-b24a-0dd2db495bc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "bert_r1 = []\n",
    "bert_r2 = []\n",
    "bert_rL = []\n",
    "bert_rLs = []\n",
    "\n",
    "for i in range(int(len(df['article'])/2)):\n",
    "    \n",
    "    # Limiting number sentences in each summary generated to 2 sentences \n",
    "    candidate = model(df['article'][i], \n",
    "                      num_sentences = round(df[\"summary_num_sentences\"][:1000].mean()), \n",
    "                      min_length = min(df[\"summary_num_characters\"][:1000]),\n",
    "                      max_length = max(df[\"summary_num_characters\"][:1000]),        \n",
    "                      ratio = None,\n",
    "                      use_first = True,\n",
    "                     )\n",
    "    candidate = [candidate]\n",
    "    #pprint(candidate[0], compact=True)\n",
    "    \n",
    "    ref = [df['summary'][i]]\n",
    "    \n",
    "    results = rouge.compute(predictions=candidate,\n",
    "                            references=ref)\n",
    "    \n",
    "    results2 = chrf.compute(predictions=candidate,\n",
    "                            references= ref)\n",
    "    \n",
    "    bert_chrf.append(results2['score'])\n",
    "    \n",
    "    bert_r1.append(results['rouge1'])\n",
    "    bert_r2.append(results['rouge2'])\n",
    "    bert_rL.append(results['rougeL'])\n",
    "    bert_rLs.append(results['rougeLsum'])\n",
    "    \n",
    "    if i in np.arange(0, (len(df['article']) + 101), 100):\n",
    "        data = {'rouge1': bert_r1, 'rouge2': bert_r2, 'rogueL': bert_rL, 'rogueLs': bert_rLs, 'chrf': bert_chrf}\n",
    "        scores = pd.DataFrame(data)\n",
    "        scores.to_csv(r'BERT_3_scores.csv', index=False)\n",
    "        print(i)\n",
    "\n",
    "data = {'rouge1': bert_r1, 'rouge2': bert_r2, 'rogueL': bert_rL, 'rogueLs': bert_rLs, 'chrf': bert_chrf}\n",
    "scores = pd.DataFrame(data)\n",
    "scores.to_csv(r'BERT_3_scores.csv', index=False)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082a64a6-0e87-4e36-8b47-b65f4942e139",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('rouge1 average :', np.mean(bert_r1))\n",
    "print('rouge2 average :', np.mean(bert_r2))\n",
    "print('rougeL average :', np.mean(bert_rL))\n",
    "print('rougeLs average :', np.mean(bert_rLs))\n",
    "print('chrf average:', np.mean(bert_chrf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a566379-110d-4741-8439-1738fa5e3389",
   "metadata": {},
   "source": [
    "5. Use bert-large-uncased w/ best from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a140b7-6255-4b2a-93e8-fbb10dcf912d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from summarizer import Summarizer\n",
    "\n",
    "model = Summarizer(model='bert-large-uncased',\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2934abbd-5dae-4f94-8e90-dc2e45a6fe6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "bert_r1 = []\n",
    "bert_r2 = []\n",
    "bert_rL = []\n",
    "bert_rLs = []\n",
    "\n",
    "for i in range(int(len(df['article'])/2)):\n",
    "    \n",
    "    # Limiting number sentences in each summary generated to 2 sentences \n",
    "    candidate = model(df['article'][i], \n",
    "                      num_sentences = round(df[\"summary_num_sentences\"][:1000].mean()), \n",
    "                      min_length = min(df[\"summary_num_characters\"][:1000]),\n",
    "                      max_length = max(df[\"summary_num_characters\"][:1000]),        \n",
    "                      ratio = None,\n",
    "                      use_first = False,\n",
    "                     )\n",
    "    candidate = [candidate]\n",
    "    #pprint(candidate[0], compact=True)\n",
    "    \n",
    "    ref = [df['summary'][i]]\n",
    "    \n",
    "    results = rouge.compute(predictions=candidate,\n",
    "                            references=ref)\n",
    "    \n",
    "    results2 = chrf.compute(predictions=candidate,\n",
    "                            references= ref)\n",
    "    \n",
    "    bert_chrf.append(results2['score'])\n",
    "    \n",
    "    bert_r1.append(results['rouge1'])\n",
    "    bert_r2.append(results['rouge2'])\n",
    "    bert_rL.append(results['rougeL'])\n",
    "    bert_rLs.append(results['rougeLsum'])\n",
    "    \n",
    "    if i in np.arange(0, (len(df['article']) + 101), 100):\n",
    "        data = {'rouge1': bert_r1, 'rouge2': bert_r2, 'rogueL': bert_rL, 'rogueLs': bert_rLs, 'chrf': bert_chrf}\n",
    "        scores = pd.DataFrame(data)\n",
    "        scores.to_csv(r'BERT_4_scores.csv', index=False)\n",
    "        print(i)\n",
    "\n",
    "data = {'rouge1': bert_r1, 'rouge2': bert_r2, 'rogueL': bert_rL, 'rogueLs': bert_rLs, 'chrf': bert_chrf}\n",
    "scores = pd.DataFrame(data)\n",
    "scores.to_csv(r'BERT_4_scores.csv', index=False)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7192f7f4-028a-4abc-aa1a-925a1a8c3616",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this model took longer and performed worse\n",
    "print('rouge1 average :', np.mean(bert_r1))\n",
    "print('rouge2 average :', np.mean(bert_r2))\n",
    "print('rougeL average :', np.mean(bert_rL))\n",
    "print('rougeLs average :', np.mean(bert_rLs))\n",
    "print('chrf average:', np.mean(bert_chrf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cab172-dc0a-4962-990e-cefbec9f1366",
   "metadata": {},
   "source": [
    "6. Reduce option median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5fa0c9-a090-4dff-b250-459de6983da5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from summarizer import Summarizer\n",
    "\n",
    "model = Summarizer(model='bert-base-uncased', reduce_option = 'median'\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cad742a-6f5b-4add-b9b3-a6ab0c856630",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "bert_r1 = []\n",
    "bert_r2 = []\n",
    "bert_rL = []\n",
    "bert_rLs = []\n",
    "\n",
    "for i in range(int(len(df['article'])/2)):\n",
    "    \n",
    "    # Limiting number sentences in each summary generated to 2 sentences \n",
    "    candidate = model(df['article'][i], \n",
    "                      num_sentences = round(df[\"summary_num_sentences\"][:1000].mean()), \n",
    "                      min_length = min(df[\"summary_num_characters\"][:1000]),\n",
    "                      max_length = max(df[\"summary_num_characters\"][:1000]),        \n",
    "                      ratio = None,\n",
    "                      use_first = None,\n",
    "                     )\n",
    "    candidate = [candidate]\n",
    "    #pprint(candidate[0], compact=True)\n",
    "    \n",
    "    ref = [df['summary'][i]]\n",
    "    \n",
    "    results = rouge.compute(predictions=candidate,\n",
    "                            references=ref)\n",
    "    \n",
    "    results2 = chrf.compute(predictions=candidate,\n",
    "                            references= ref)\n",
    "    \n",
    "    bert_chrf.append(results2['score'])\n",
    "    \n",
    "    bert_r1.append(results['rouge1'])\n",
    "    bert_r2.append(results['rouge2'])\n",
    "    bert_rL.append(results['rougeL'])\n",
    "    bert_rLs.append(results['rougeLsum'])\n",
    "    \n",
    "    if i in np.arange(0, (len(df['article']) + 101), 100):\n",
    "        data = {'rouge1': bert_r1, 'rouge2': bert_r2, 'rogueL': bert_rL, 'rogueLs': bert_rLs, 'chrf': bert_chrf}\n",
    "        scores = pd.DataFrame(data)\n",
    "        scores.to_csv(r'BERT_4_scores.csv', index=False)\n",
    "        print(i)\n",
    "\n",
    "data = {'rouge1': bert_r1, 'rouge2': bert_r2, 'rogueL': bert_rL, 'rogueLs': bert_rLs, 'chrf': bert_chrf}\n",
    "scores = pd.DataFrame(data)\n",
    "scores.to_csv(r'BERT_6_scores.csv', index=False)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81108fe5-f4f9-4509-ade6-75b9cb09815a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('rouge1 average :', np.mean(bert_r1))\n",
    "print('rouge2 average :', np.mean(bert_r2))\n",
    "print('rougeL average :', np.mean(bert_rL))\n",
    "print('rougeLs average :', np.mean(bert_rLs))\n",
    "print('chrf average:', np.mean(bert_chrf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd379e9-9b75-49c2-a336-f132b63281e1",
   "metadata": {},
   "source": [
    "**7. Reduce option max THIS WORKED THIS BEST!!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382d244f-a422-49b0-b141-0a7b55c4c163",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from summarizer import Summarizer\n",
    "\n",
    "model = Summarizer(model='bert-base-uncased', reduce_option = 'max'\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92f9a41-6fd4-4320-b51c-e026c01e01a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "bert_r1 = []\n",
    "bert_r2 = []\n",
    "bert_rL = []\n",
    "bert_rLs = []\n",
    "\n",
    "for i in range(int(len(df['article'])/2)):\n",
    "    \n",
    "    # Limiting number sentences in each summary generated to 2 sentences \n",
    "    candidate = model(df['article'][i], \n",
    "                      num_sentences = round(df[\"summary_num_sentences\"][:1000].mean()), \n",
    "                      min_length = min(df[\"summary_num_characters\"][:1000]),\n",
    "                      max_length = max(df[\"summary_num_characters\"][:1000]),        \n",
    "                      ratio = None,\n",
    "                      use_first = None,\n",
    "                     )\n",
    "    candidate = [candidate]\n",
    "    #pprint(candidate[0], compact=True)\n",
    "    \n",
    "    ref = [df['summary'][i]]\n",
    "    \n",
    "    results = rouge.compute(predictions=candidate,\n",
    "                            references=ref)\n",
    "    \n",
    "    results2 = chrf.compute(predictions=candidate,\n",
    "                            references= ref)\n",
    "    \n",
    "    bert_chrf.append(results2['score'])\n",
    "    \n",
    "    bert_r1.append(results['rouge1'])\n",
    "    bert_r2.append(results['rouge2'])\n",
    "    bert_rL.append(results['rougeL'])\n",
    "    bert_rLs.append(results['rougeLsum'])\n",
    "    \n",
    "    if i in np.arange(0, (len(df['article']) + 101), 100):\n",
    "        data = {'rouge1': bert_r1, 'rouge2': bert_r2, 'rogueL': bert_rL, 'rogueLs': bert_rLs, 'chrf': bert_chrf}\n",
    "        scores = pd.DataFrame(data)\n",
    "        scores.to_csv(r'BERT_7_scores.csv', index=False)\n",
    "        print(i)\n",
    "\n",
    "data = {'rouge1': bert_r1, 'rouge2': bert_r2, 'rogueL': bert_rL, 'rogueLs': bert_rLs, 'chrf': bert_chrf}\n",
    "scores = pd.DataFrame(data)\n",
    "scores.to_csv(r'BERT_7_scores.csv', index=False)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cd8b50-8555-4b77-9a56-edc169ccc0eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('rouge1 average :', np.mean(bert_r1))\n",
    "print('rouge2 average :', np.mean(bert_r2))\n",
    "print('rougeL average :', np.mean(bert_rL))\n",
    "print('rougeLs average :', np.mean(bert_rLs))\n",
    "print('chrf average:', np.mean(bert_chrf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50baf0e3-b028-4533-bc6c-7be20529119e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('num_sentences', round(df[\"summary_num_sentences\"][:1000].mean()) \n",
    "print('min_length', min(df[\"summary_num_characters\"][:1000])\n",
    "print('max_length', max(df[\"summary_num_characters\"][:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fbb598-7393-4006-8886-707879a490e1",
   "metadata": {},
   "source": [
    "**Best BERT Extractive model from finetuning above by category**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40eb831-0089-44bd-aeaf-441de4acf8c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_indices(list_to_check, item_to_find):\n",
    "    indices = []\n",
    "    for idx, value in enumerate(list_to_check):\n",
    "        if value == item_to_find:\n",
    "            indices.append(idx)\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593b516b-48f1-43fa-af11-997604ee9072",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "categories = []\n",
    "\n",
    "for i in range(len(dataset['train'])):\n",
    "    cat = dataset['train'][i]['id']\n",
    "    result = re.sub('\\d','',cat)[:-1]\n",
    "    result = result.split('-')[0].split('.')[0]\n",
    "    categories.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05fdfde-349d-4598-b490-1cbd3fda6c75",
   "metadata": {},
   "source": [
    "**Category 1: uk**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8837067b-6bcb-477c-9f31-c52038232b44",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>103144</th>\n",
       "      <td>184549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135979</th>\n",
       "      <td>242139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122918</th>\n",
       "      <td>219346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41576</th>\n",
       "      <td>76571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23230</th>\n",
       "      <td>44271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index\n",
       "103144  184549\n",
       "135979  242139\n",
       "122918  219346\n",
       "41576    76571\n",
       "23230    44271"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uk = find_indices(categories, 'uk')\n",
    "index = pd.DataFrame({\"index\": uk})\n",
    "sample_index = index.sample(n=1000, replace=False, random_state=1004)\n",
    "sample_index[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a64fecc1-9498-4a9c-821b-c4a02827b42a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "id = []\n",
    "url = []\n",
    "title = []\n",
    "article = []\n",
    "summary = []\n",
    "\n",
    "for i in sample_index[\"index\"]:\n",
    "    id.append(dataset[\"train\"][i]['id'])\n",
    "    url.append(dataset[\"train\"][i]['url'])\n",
    "    title.append(dataset[\"train\"][i]['title'])\n",
    "    summary.append(dataset[\"train\"][i]['summary'])\n",
    "    article.append(dataset[\"train\"][i]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "19da3f13-2c99-4d97-814f-682d2dda99db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>article</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>uk-england-bristol-51032231</td>\n",
       "      <td>https://www.bbc.com/news/uk-england-bristol-51...</td>\n",
       "      <td>Author Emily Koch: 'I'm not angry at the drive...</td>\n",
       "      <td>Emily Koch suffered two broken legs and ligame...</td>\n",
       "      <td>A woman left seriously injured after being hit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>uk-england-birmingham-54264699</td>\n",
       "      <td>https://www.bbc.com/news/uk-england-birmingham...</td>\n",
       "      <td>Blind TikTok star Lucy Edwards says reaction t...</td>\n",
       "      <td>Lucy Edwards, who became Radio 1's first blind...</td>\n",
       "      <td>A blind vlogger hopes her TikTok videos on liv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>uk-england-london-16091997</td>\n",
       "      <td>https://www.bbc.com/news/uk-england-london-160...</td>\n",
       "      <td>Bendy bus makes final journey for Transport fo...</td>\n",
       "      <td>The vehicles were used on 12 routes over the p...</td>\n",
       "      <td>The last of London's bendy buses was taken off...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>uk-england-norfolk-54058083</td>\n",
       "      <td>https://www.bbc.com/news/uk-england-norfolk-54...</td>\n",
       "      <td>Horsey seals: Volunteers remove rubber ring fr...</td>\n",
       "      <td>Four members of Friends of Horsey Seals netted...</td>\n",
       "      <td>Volunteers have helped capture a \"feisty\" seal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>uk-scotland-edinburgh-east-fife-28838287</td>\n",
       "      <td>https://www.bbc.com/news/uk-scotland-edinburgh...</td>\n",
       "      <td>Tim Vine wins funniest Edinburgh Fringe joke a...</td>\n",
       "      <td>He won with the one-liner: \"I decided to sell ...</td>\n",
       "      <td>A joke by comedian Tim Vine about a vacuum cle...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         id  \\\n",
       "0               uk-england-bristol-51032231   \n",
       "1            uk-england-birmingham-54264699   \n",
       "2                uk-england-london-16091997   \n",
       "3               uk-england-norfolk-54058083   \n",
       "4  uk-scotland-edinburgh-east-fife-28838287   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.bbc.com/news/uk-england-bristol-51...   \n",
       "1  https://www.bbc.com/news/uk-england-birmingham...   \n",
       "2  https://www.bbc.com/news/uk-england-london-160...   \n",
       "3  https://www.bbc.com/news/uk-england-norfolk-54...   \n",
       "4  https://www.bbc.com/news/uk-scotland-edinburgh...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Author Emily Koch: 'I'm not angry at the drive...   \n",
       "1  Blind TikTok star Lucy Edwards says reaction t...   \n",
       "2  Bendy bus makes final journey for Transport fo...   \n",
       "3  Horsey seals: Volunteers remove rubber ring fr...   \n",
       "4  Tim Vine wins funniest Edinburgh Fringe joke a...   \n",
       "\n",
       "                                             article  \\\n",
       "0  Emily Koch suffered two broken legs and ligame...   \n",
       "1  Lucy Edwards, who became Radio 1's first blind...   \n",
       "2  The vehicles were used on 12 routes over the p...   \n",
       "3  Four members of Friends of Horsey Seals netted...   \n",
       "4  He won with the one-liner: \"I decided to sell ...   \n",
       "\n",
       "                                             summary  \n",
       "0  A woman left seriously injured after being hit...  \n",
       "1  A blind vlogger hopes her TikTok videos on liv...  \n",
       "2  The last of London's bendy buses was taken off...  \n",
       "3  Volunteers have helped capture a \"feisty\" seal...  \n",
       "4  A joke by comedian Tim Vine about a vacuum cle...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'id': id, 'url': url, \"title\": title, 'article': article, 'summary': summary}\n",
    "df = pd.DataFrame(data=d)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "34265006-89d9-43b0-a9bf-8e12ffd174ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "999\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "bert_r1 = []\n",
    "bert_r2 = []\n",
    "bert_rL = []\n",
    "bert_rLs = []\n",
    "\n",
    "for i in range(int(len(df['article'])/2)):\n",
    "    \n",
    "    # Limiting number sentences in each summary generated to 2 sentences \n",
    "    candidate = model(df['article'][i], \n",
    "                      num_sentences = round(df[\"summary_num_sentences\"][:1000].mean()), \n",
    "                      min_length = min(df[\"summary_num_characters\"][:1000]),\n",
    "                      max_length = max(df[\"summary_num_characters\"][:1000]),        \n",
    "                      ratio = None,\n",
    "                      use_first = None,\n",
    "                     )\n",
    "    candidate = [candidate]\n",
    "    #pprint(candidate[0], compact=True)\n",
    "    \n",
    "    ref = [df['summary'][i]]\n",
    "    \n",
    "    results = rouge.compute(predictions=candidate,\n",
    "                            references=ref)\n",
    "    \n",
    "    results2 = chrf.compute(predictions=candidate,\n",
    "                            references= ref)\n",
    "    \n",
    "    bert_chrf.append(results2['score'])\n",
    "    \n",
    "    bert_r1.append(results['rouge1'])\n",
    "    bert_r2.append(results['rouge2'])\n",
    "    bert_rL.append(results['rougeL'])\n",
    "    bert_rLs.append(results['rougeLsum'])\n",
    "    \n",
    "    if i in np.arange(0, (len(df['article']) + 101), 100):\n",
    "        data = {'rouge1': bert_r1, 'rouge2': bert_r2, 'rogueL': bert_rL, 'rogueLs': bert_rLs, 'chrf': bert_chrf}\n",
    "        scores = pd.DataFrame(data)\n",
    "        scores.to_csv(r'BERT_7_scores_uk.csv', index=False)\n",
    "        print(i)\n",
    "\n",
    "data = {'rouge1': bert_r1, 'rouge2': bert_r2, 'rogueL': bert_rL, 'rogueLs': bert_rLs, 'chrf': bert_chrf}\n",
    "scores = pd.DataFrame(data)\n",
    "scores.to_csv(r'BERT_7_scores_uk.csv', index=False)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9549992c-d3d4-42d8-a3a2-57b774e36e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rouge1 average:  0.18939253006007692\n",
      "rouge2 average:  0.027133586978308793\n",
      "rougeL average:  0.12278381086366534\n",
      "rougeLs average: 0.12278381086366534\n",
      "chrf average: 26.572484469570067\n"
     ]
    }
   ],
   "source": [
    "print('rouge1 average: ', np.mean(base_r1))\n",
    "print('rouge2 average: ', np.mean(base_r2))\n",
    "print('rougeL average: ', np.mean(base_rL))\n",
    "print('rougeLs average:', np.mean(base_rLs))\n",
    "print('chrf average:', np.mean(base_chrf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ff031d-c333-4c0e-a319-6cba1f8b5da6",
   "metadata": {},
   "source": [
    "**Category 2: world**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "edff48ba-f34a-401b-bf1a-e22ccf5f173e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38266</th>\n",
       "      <td>209050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5910</th>\n",
       "      <td>25805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14047</th>\n",
       "      <td>71645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23996</th>\n",
       "      <td>127936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25699</th>\n",
       "      <td>137681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        index\n",
       "38266  209050\n",
       "5910    25805\n",
       "14047   71645\n",
       "23996  127936\n",
       "25699  137681"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_inx = find_indices(categories, 'world')\n",
    "index = pd.DataFrame({\"index\": cat_inx})\n",
    "sample_index = index.sample(n=1000, replace=False, random_state=1004)\n",
    "sample_index[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4b287371-9892-4a1f-84af-229c0037e7d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "id = []\n",
    "url = []\n",
    "title = []\n",
    "article = []\n",
    "summary = []\n",
    "\n",
    "for i in sample_index[\"index\"]:\n",
    "    id.append(dataset[\"train\"][i]['id'])\n",
    "    url.append(dataset[\"train\"][i]['url'])\n",
    "    title.append(dataset[\"train\"][i]['title'])\n",
    "    summary.append(dataset[\"train\"][i]['summary'])\n",
    "    article.append(dataset[\"train\"][i]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ff9d1553-d738-49a0-a63d-1e5ebc8db46e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>article</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>world-asia-53847400</td>\n",
       "      <td>https://www.bbc.com/news/world-asia-53847400</td>\n",
       "      <td>Kim Jong-un gives sister Yo-jong 'more respons...</td>\n",
       "      <td>Mr Kim still maintains \"absolute authority\", b...</td>\n",
       "      <td>North Korean leader Kim Jong-un has delegated ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>world-europe-guernsey-18129181</td>\n",
       "      <td>https://www.bbc.com/news/world-europe-guernsey...</td>\n",
       "      <td>Guernsey overgrown trees prompt road crash fears</td>\n",
       "      <td>Overgrown bushes and trees could result in peo...</td>\n",
       "      <td>Residents are being urged to trim vegetation o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>world-africa-44629681</td>\n",
       "      <td>https://www.bbc.co.uk/news/world-africa-44629681</td>\n",
       "      <td>Bringing Gay Pride to Africa's last absolute m...</td>\n",
       "      <td>And anyone doubting the determination needed t...</td>\n",
       "      <td>Africa's last absolute monarchy is holding its...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>world-asia-41840069</td>\n",
       "      <td>https://www.bbc.com/news/world-asia-41840069</td>\n",
       "      <td>Pakistan polygamy: Lahore man jailed over unap...</td>\n",
       "      <td>The court in Lahore also ordered Shahzad Saqib...</td>\n",
       "      <td>A Pakistan court has jailed a man for six mont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>world-europe-guernsey-13052445</td>\n",
       "      <td>https://www.bbc.com/news/world-europe-guernsey...</td>\n",
       "      <td>Alternative recycling bank site proposed</td>\n",
       "      <td>The old facility at Manor Stores closed last y...</td>\n",
       "      <td>Work is continuing to try to find a permanent ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               id  \\\n",
       "0             world-asia-53847400   \n",
       "1  world-europe-guernsey-18129181   \n",
       "2           world-africa-44629681   \n",
       "3             world-asia-41840069   \n",
       "4  world-europe-guernsey-13052445   \n",
       "\n",
       "                                                 url  \\\n",
       "0       https://www.bbc.com/news/world-asia-53847400   \n",
       "1  https://www.bbc.com/news/world-europe-guernsey...   \n",
       "2   https://www.bbc.co.uk/news/world-africa-44629681   \n",
       "3       https://www.bbc.com/news/world-asia-41840069   \n",
       "4  https://www.bbc.com/news/world-europe-guernsey...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Kim Jong-un gives sister Yo-jong 'more respons...   \n",
       "1   Guernsey overgrown trees prompt road crash fears   \n",
       "2  Bringing Gay Pride to Africa's last absolute m...   \n",
       "3  Pakistan polygamy: Lahore man jailed over unap...   \n",
       "4           Alternative recycling bank site proposed   \n",
       "\n",
       "                                             article  \\\n",
       "0  Mr Kim still maintains \"absolute authority\", b...   \n",
       "1  Overgrown bushes and trees could result in peo...   \n",
       "2  And anyone doubting the determination needed t...   \n",
       "3  The court in Lahore also ordered Shahzad Saqib...   \n",
       "4  The old facility at Manor Stores closed last y...   \n",
       "\n",
       "                                             summary  \n",
       "0  North Korean leader Kim Jong-un has delegated ...  \n",
       "1  Residents are being urged to trim vegetation o...  \n",
       "2  Africa's last absolute monarchy is holding its...  \n",
       "3  A Pakistan court has jailed a man for six mont...  \n",
       "4  Work is continuing to try to find a permanent ...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'id': id, 'url': url, \"title\": title, 'article': article, 'summary': summary}\n",
    "df = pd.DataFrame(data=d)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f322b098-139a-487e-9078-7ad6de108469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "999\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "bert_r1 = []\n",
    "bert_r2 = []\n",
    "bert_rL = []\n",
    "bert_rLs = []\n",
    "\n",
    "for i in range(int(len(df['article'])/2)):\n",
    "    \n",
    "    # Limiting number sentences in each summary generated to 2 sentences \n",
    "    candidate = model(df['article'][i], \n",
    "                      num_sentences = round(df[\"summary_num_sentences\"][:1000].mean()), \n",
    "                      min_length = min(df[\"summary_num_characters\"][:1000]),\n",
    "                      max_length = max(df[\"summary_num_characters\"][:1000]),        \n",
    "                      ratio = None,\n",
    "                      use_first = None,\n",
    "                     )\n",
    "    candidate = [candidate]\n",
    "    #pprint(candidate[0], compact=True)\n",
    "    \n",
    "    ref = [df['summary'][i]]\n",
    "    \n",
    "    results = rouge.compute(predictions=candidate,\n",
    "                            references=ref)\n",
    "    \n",
    "    results2 = chrf.compute(predictions=candidate,\n",
    "                            references= ref)\n",
    "    \n",
    "    bert_chrf.append(results2['score'])\n",
    "    \n",
    "    bert_r1.append(results['rouge1'])\n",
    "    bert_r2.append(results['rouge2'])\n",
    "    bert_rL.append(results['rougeL'])\n",
    "    bert_rLs.append(results['rougeLsum'])\n",
    "    \n",
    "    if i in np.arange(0, (len(df['article']) + 101), 100):\n",
    "        data = {'rouge1': bert_r1, 'rouge2': bert_r2, 'rogueL': bert_rL, 'rogueLs': bert_rLs, 'chrf': bert_chrf}\n",
    "        scores = pd.DataFrame(data)\n",
    "        scores.to_csv(r'BERT_7_scores_world.csv', index=False)\n",
    "        print(i)\n",
    "\n",
    "data = {'rouge1': bert_r1, 'rouge2': bert_r2, 'rogueL': bert_rL, 'rogueLs': bert_rLs, 'chrf': bert_chrf}\n",
    "scores = pd.DataFrame(data)\n",
    "scores.to_csv(r'BERT_7_scores_world.csv', index=False)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7bb5d47e-fd5a-4b36-a84b-cdce83404763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rouge1 average:  0.19131117325937153\n",
      "rouge2 average:  0.026498254102528457\n",
      "rougeL average:  0.12255157736810432\n",
      "rougeLs average: 0.12255157736810432\n",
      "chrf average: 27.301136246709188\n"
     ]
    }
   ],
   "source": [
    "print('rouge1 average: ', np.mean(base_r1))\n",
    "print('rouge2 average: ', np.mean(base_r2))\n",
    "print('rougeL average: ', np.mean(base_rL))\n",
    "print('rougeLs average:', np.mean(base_rLs))\n",
    "print('chrf average:', np.mean(base_chrf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9c3dcc-ecb5-434c-979f-3e60174819cf",
   "metadata": {},
   "source": [
    "**Category 3: business**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "278c4350-fda9-41af-b3df-01c05c05dfaa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17751</th>\n",
       "      <td>250222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8987</th>\n",
       "      <td>132229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2855</th>\n",
       "      <td>46895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17482</th>\n",
       "      <td>246643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13624</th>\n",
       "      <td>194415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        index\n",
       "17751  250222\n",
       "8987   132229\n",
       "2855    46895\n",
       "17482  246643\n",
       "13624  194415"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_inx = find_indices(categories, 'business')\n",
    "index = pd.DataFrame({\"index\": cat_inx})\n",
    "sample_index = index.sample(n=1000, replace=False, random_state=1004)\n",
    "sample_index[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e819c047-8508-4c2b-8c75-66d6053b9e3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "id = []\n",
    "url = []\n",
    "title = []\n",
    "article = []\n",
    "summary = []\n",
    "\n",
    "for i in sample_index[\"index\"]:\n",
    "    id.append(dataset[\"train\"][i]['id'])\n",
    "    url.append(dataset[\"train\"][i]['url'])\n",
    "    title.append(dataset[\"train\"][i]['title'])\n",
    "    summary.append(dataset[\"train\"][i]['summary'])\n",
    "    article.append(dataset[\"train\"][i]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fc111fb4-f3ea-4441-a4b8-eda56fcb3dc6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>article</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business-51487191</td>\n",
       "      <td>https://www.bbc.co.uk/news/business-51487191</td>\n",
       "      <td>British Gas owner Centrica hit by energy price...</td>\n",
       "      <td>Centrica made a loss of £849m in the year ende...</td>\n",
       "      <td>British Gas owner Centrica has blamed a big lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business-18289184</td>\n",
       "      <td>https://www.bbc.com/news/business-18289184</td>\n",
       "      <td>Pakistan economy at a crossroads</td>\n",
       "      <td>By Shahzeb JillaniBBC News The good news is th...</td>\n",
       "      <td>Pakistan is a nuclear weapon state with a popu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business-48524850</td>\n",
       "      <td>https://www.bbc.com/news/business-48524850</td>\n",
       "      <td>Green secures rescue deal for Topshop empire</td>\n",
       "      <td>The plan, covering stores including Topshop, M...</td>\n",
       "      <td>Sir Philip Green's Arcadia retail empire has b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business-54004709</td>\n",
       "      <td>https://www.bbc.com/news/business-54004709</td>\n",
       "      <td>Coronavirus: 'I took a £1,000 flight to beat P...</td>\n",
       "      <td>By Simon ReadBusiness reporter But he had to s...</td>\n",
       "      <td>John Cushing is cutting his Portugal holiday s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>business-37339981</td>\n",
       "      <td>https://www.bbc.com/news/business-37339981</td>\n",
       "      <td>Tax credits mum 'falsely accused of marriage t...</td>\n",
       "      <td>By Peter Whittlesea &amp; John OwenVictoria Derbys...</td>\n",
       "      <td>A teenage mother had her child tax credits sto...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id                                           url  \\\n",
       "0  business-51487191  https://www.bbc.co.uk/news/business-51487191   \n",
       "1  business-18289184    https://www.bbc.com/news/business-18289184   \n",
       "2  business-48524850    https://www.bbc.com/news/business-48524850   \n",
       "3  business-54004709    https://www.bbc.com/news/business-54004709   \n",
       "4  business-37339981    https://www.bbc.com/news/business-37339981   \n",
       "\n",
       "                                               title  \\\n",
       "0  British Gas owner Centrica hit by energy price...   \n",
       "1                   Pakistan economy at a crossroads   \n",
       "2       Green secures rescue deal for Topshop empire   \n",
       "3  Coronavirus: 'I took a £1,000 flight to beat P...   \n",
       "4  Tax credits mum 'falsely accused of marriage t...   \n",
       "\n",
       "                                             article  \\\n",
       "0  Centrica made a loss of £849m in the year ende...   \n",
       "1  By Shahzeb JillaniBBC News The good news is th...   \n",
       "2  The plan, covering stores including Topshop, M...   \n",
       "3  By Simon ReadBusiness reporter But he had to s...   \n",
       "4  By Peter Whittlesea & John OwenVictoria Derbys...   \n",
       "\n",
       "                                             summary  \n",
       "0  British Gas owner Centrica has blamed a big lo...  \n",
       "1  Pakistan is a nuclear weapon state with a popu...  \n",
       "2  Sir Philip Green's Arcadia retail empire has b...  \n",
       "3  John Cushing is cutting his Portugal holiday s...  \n",
       "4  A teenage mother had her child tax credits sto...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'id': id, 'url': url, \"title\": title, 'article': article, 'summary': summary}\n",
    "df = pd.DataFrame(data=d)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2d219fd4-ba87-4828-bf37-407f78ec44e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "999\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "bert_r1 = []\n",
    "bert_r2 = []\n",
    "bert_rL = []\n",
    "bert_rLs = []\n",
    "\n",
    "for i in range(int(len(df['article'])/2)):\n",
    "    \n",
    "    # Limiting number sentences in each summary generated to 2 sentences \n",
    "    candidate = model(df['article'][i], \n",
    "                      num_sentences = round(df[\"summary_num_sentences\"][:1000].mean()), \n",
    "                      min_length = min(df[\"summary_num_characters\"][:1000]),\n",
    "                      max_length = max(df[\"summary_num_characters\"][:1000]),        \n",
    "                      ratio = None,\n",
    "                      use_first = None,\n",
    "                     )\n",
    "    candidate = [candidate]\n",
    "    #pprint(candidate[0], compact=True)\n",
    "    \n",
    "    ref = [df['summary'][i]]\n",
    "    \n",
    "    results = rouge.compute(predictions=candidate,\n",
    "                            references=ref)\n",
    "    \n",
    "    results2 = chrf.compute(predictions=candidate,\n",
    "                            references= ref)\n",
    "    \n",
    "    bert_chrf.append(results2['score'])\n",
    "    \n",
    "    bert_r1.append(results['rouge1'])\n",
    "    bert_r2.append(results['rouge2'])\n",
    "    bert_rL.append(results['rougeL'])\n",
    "    bert_rLs.append(results['rougeLsum'])\n",
    "    \n",
    "    if i in np.arange(0, (len(df['article']) + 101), 100):\n",
    "        data = {'rouge1': bert_r1, 'rouge2': bert_r2, 'rogueL': bert_rL, 'rogueLs': bert_rLs, 'chrf': bert_chrf}\n",
    "        scores = pd.DataFrame(data)\n",
    "        scores.to_csv(r'BERT_7_scores_business.csv', index=False)\n",
    "        print(i)\n",
    "\n",
    "data = {'rouge1': bert_r1, 'rouge2': bert_r2, 'rogueL': bert_rL, 'rogueLs': bert_rLs, 'chrf': bert_chrf}\n",
    "scores = pd.DataFrame(data)\n",
    "scores.to_csv(r'BERT_7_scores_business.csv', index=False)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "56801ea6-6e55-41e7-b984-c38c67221ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rouge1 average:  0.1873668697599981\n",
      "rouge2 average:  0.026998209932834666\n",
      "rougeL average:  0.12229664365938817\n",
      "rougeLs average: 0.12229664365938817\n",
      "chrf average: 26.8081030850095\n"
     ]
    }
   ],
   "source": [
    "print('rouge1 average: ', np.mean(base_r1))\n",
    "print('rouge2 average: ', np.mean(base_r2))\n",
    "print('rougeL average: ', np.mean(base_rL))\n",
    "print('rougeLs average:', np.mean(base_rLs))\n",
    "print('chrf average:', np.mean(base_chrf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7408e182-dd09-4de7-8d0d-b7a349fe156d",
   "metadata": {},
   "source": [
    "**Category 4: entertainment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "53d9ba2f-bf45-444d-b325-a9dcac8a979d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5668</th>\n",
       "      <td>127955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7275</th>\n",
       "      <td>163834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4655</th>\n",
       "      <td>106634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12025</th>\n",
       "      <td>266862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2458</th>\n",
       "      <td>58192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        index\n",
       "5668   127955\n",
       "7275   163834\n",
       "4655   106634\n",
       "12025  266862\n",
       "2458    58192"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_inx = find_indices(categories, 'entertainment')\n",
    "index = pd.DataFrame({\"index\": cat_inx})\n",
    "sample_index = index.sample(n=1000, replace=False, random_state=1004)\n",
    "sample_index[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e42bb9e3-017a-481e-819c-c4a62ac80e43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "id = []\n",
    "url = []\n",
    "title = []\n",
    "article = []\n",
    "summary = []\n",
    "\n",
    "for i in sample_index[\"index\"]:\n",
    "    id.append(dataset[\"train\"][i]['id'])\n",
    "    url.append(dataset[\"train\"][i]['url'])\n",
    "    title.append(dataset[\"train\"][i]['title'])\n",
    "    summary.append(dataset[\"train\"][i]['summary'])\n",
    "    article.append(dataset[\"train\"][i]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a4dedd09-a0d1-443a-a326-6a0d4c974a70",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>article</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>entertainment-arts-19783861</td>\n",
       "      <td>https://www.bbc.com/news/entertainment-arts-19...</td>\n",
       "      <td>National Theatre reports record annual takings...</td>\n",
       "      <td>By Helen BushbyBBC Entertainment and Arts repo...</td>\n",
       "      <td>The National Theatre has reported record yearl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>entertainment-arts-38290366</td>\n",
       "      <td>https://www.bbc.com/news/entertainment-arts-38...</td>\n",
       "      <td>Golden Globes: La La Land leads nominations</td>\n",
       "      <td>Damien Chazelle's movie is up for best musical...</td>\n",
       "      <td>Musical film La La Land leads the pack in this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>entertainment-arts-28228750</td>\n",
       "      <td>https://www.bbc.com/news/entertainment-arts-28...</td>\n",
       "      <td>Yorkshire Sculpture Park wins museum of the ye...</td>\n",
       "      <td>By Tim MastersArts and entertainment correspon...</td>\n",
       "      <td>The open-air Yorkshire Sculpture Park has been...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>entertainment-arts-36979491</td>\n",
       "      <td>https://www.bbc.com/news/entertainment-arts-36...</td>\n",
       "      <td>New Alf Garnett seen in Till Death Us Do Part ...</td>\n",
       "      <td>Simon Day, who has previously appeared in The ...</td>\n",
       "      <td>Alf Garnett has lost his signature moustache b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entertainment-arts-28834671</td>\n",
       "      <td>https://www.bbc.com/news/entertainment-arts-28...</td>\n",
       "      <td>BSkyB makes 20% ethnic minorities pledge</td>\n",
       "      <td>The target applies to all home-grown programme...</td>\n",
       "      <td>The broadcaster, Sky, has pledged that 20% of ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            id  \\\n",
       "0  entertainment-arts-19783861   \n",
       "1  entertainment-arts-38290366   \n",
       "2  entertainment-arts-28228750   \n",
       "3  entertainment-arts-36979491   \n",
       "4  entertainment-arts-28834671   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.bbc.com/news/entertainment-arts-19...   \n",
       "1  https://www.bbc.com/news/entertainment-arts-38...   \n",
       "2  https://www.bbc.com/news/entertainment-arts-28...   \n",
       "3  https://www.bbc.com/news/entertainment-arts-36...   \n",
       "4  https://www.bbc.com/news/entertainment-arts-28...   \n",
       "\n",
       "                                               title  \\\n",
       "0  National Theatre reports record annual takings...   \n",
       "1        Golden Globes: La La Land leads nominations   \n",
       "2  Yorkshire Sculpture Park wins museum of the ye...   \n",
       "3  New Alf Garnett seen in Till Death Us Do Part ...   \n",
       "4           BSkyB makes 20% ethnic minorities pledge   \n",
       "\n",
       "                                             article  \\\n",
       "0  By Helen BushbyBBC Entertainment and Arts repo...   \n",
       "1  Damien Chazelle's movie is up for best musical...   \n",
       "2  By Tim MastersArts and entertainment correspon...   \n",
       "3  Simon Day, who has previously appeared in The ...   \n",
       "4  The target applies to all home-grown programme...   \n",
       "\n",
       "                                             summary  \n",
       "0  The National Theatre has reported record yearl...  \n",
       "1  Musical film La La Land leads the pack in this...  \n",
       "2  The open-air Yorkshire Sculpture Park has been...  \n",
       "3  Alf Garnett has lost his signature moustache b...  \n",
       "4  The broadcaster, Sky, has pledged that 20% of ...  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'id': id, 'url': url, \"title\": title, 'article': article, 'summary': summary}\n",
    "df = pd.DataFrame(data=d)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c569a8a3-f050-4e8d-bf0a-1fe3f570077a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "bert_r1 = []\n",
    "bert_r2 = []\n",
    "bert_rL = []\n",
    "bert_rLs = []\n",
    "\n",
    "for i in range(int(len(df['article'])/2)):\n",
    "    \n",
    "    # Limiting number sentences in each summary generated to 2 sentences \n",
    "    candidate = model(df['article'][i], \n",
    "                      num_sentences = round(df[\"summary_num_sentences\"][:1000].mean()), \n",
    "                      min_length = min(df[\"summary_num_characters\"][:1000]),\n",
    "                      max_length = max(df[\"summary_num_characters\"][:1000]),        \n",
    "                      ratio = None,\n",
    "                      use_first = None,\n",
    "                     )\n",
    "    candidate = [candidate]\n",
    "    #pprint(candidate[0], compact=True)\n",
    "    \n",
    "    ref = [df['summary'][i]]\n",
    "    \n",
    "    results = rouge.compute(predictions=candidate,\n",
    "                            references=ref)\n",
    "    \n",
    "    results2 = chrf.compute(predictions=candidate,\n",
    "                            references= ref)\n",
    "    \n",
    "    bert_chrf.append(results2['score'])\n",
    "    \n",
    "    bert_r1.append(results['rouge1'])\n",
    "    bert_r2.append(results['rouge2'])\n",
    "    bert_rL.append(results['rougeL'])\n",
    "    bert_rLs.append(results['rougeLsum'])\n",
    "    \n",
    "    if i in np.arange(0, (len(df['article']) + 101), 100):\n",
    "        data = {'rouge1': bert_r1, 'rouge2': bert_r2, 'rogueL': bert_rL, 'rogueLs': bert_rLs, 'chrf': bert_chrf}\n",
    "        scores = pd.DataFrame(data)\n",
    "        scores.to_csv(r'BERT_7_scores.csv', index=False)\n",
    "        print(i)\n",
    "\n",
    "data = {'rouge1': bert_r1, 'rouge2': bert_r2, 'rogueL': bert_rL, 'rogueLs': bert_rLs, 'chrf': bert_chrf}\n",
    "scores = pd.DataFrame(data)\n",
    "scores.to_csv(r'BERT_7_scores.csv', index=False)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e690109b-3068-4607-92de-a3af82689194",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('rouge1 average: ', np.mean(base_r1))\n",
    "print('rouge2 average: ', np.mean(base_r2))\n",
    "print('rougeL average: ', np.mean(base_rL))\n",
    "print('rougeLs average:', np.mean(base_rLs))\n",
    "print('chrf average:', np.mean(base_chrf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9728c1f3-c8c7-4a86-97cd-65c9ad25bbc9",
   "metadata": {},
   "source": [
    "**Category 5: technology**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358d05ca-9d4f-451c-9203-69486e68fc21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cat_inx = find_indices(categories, 'technology')\n",
    "index = pd.DataFrame({\"index\": cat_inx})\n",
    "sample_index = index.sample(n=1000, replace=False, random_state=1004)\n",
    "sample_index[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d38b0ff-bc23-4bbc-b359-406f9615036e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "id = []\n",
    "url = []\n",
    "title = []\n",
    "article = []\n",
    "summary = []\n",
    "\n",
    "for i in sample_index[\"index\"]:\n",
    "    id.append(dataset[\"train\"][i]['id'])\n",
    "    url.append(dataset[\"train\"][i]['url'])\n",
    "    title.append(dataset[\"train\"][i]['title'])\n",
    "    summary.append(dataset[\"train\"][i]['summary'])\n",
    "    article.append(dataset[\"train\"][i]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88911c48-3f86-43b7-b620-fd9d3e6bec73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "d = {'id': id, 'url': url, \"title\": title, 'article': article, 'summary': summary}\n",
    "df = pd.DataFrame(data=d)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d48b76-35fd-41a3-ad6b-2fb5f516321f",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_r1 = []\n",
    "base_r2 = []\n",
    "base_rL = []\n",
    "base_rLs = []\n",
    "base_chrf = []\n",
    "\n",
    "for i in range(len(df['article'])): \n",
    "    \n",
    "    \n",
    "    # first three sentences \n",
    "    candidate = \". \".join(df[\"article\"][i].split('. ')[0:3]) + \".\"\n",
    "    candidate = [candidate]\n",
    "    \n",
    "    ref = [df['summary'][i]]\n",
    "    \n",
    "    results = rouge.compute(predictions=candidate,\n",
    "                            references= ref)\n",
    "    \n",
    "    results2 = chrf.compute(predictions=candidate,\n",
    "                            references= ref)\n",
    "    \n",
    "    base_r1.append(results['rouge1'])\n",
    "    base_r2.append(results['rouge2'])\n",
    "    base_rL.append(results['rougeL'])\n",
    "    base_rLs.append(results['rougeLsum'])\n",
    "    \n",
    "    base_chrf.append(results2['score'])\n",
    "    \n",
    "    if i in np.arange(0, 2000, 100):\n",
    "        data = {'rouge1': base_r1, 'rouge2': base_r2, 'rogueL': base_rL, 'rogueLs': base_rLs, 'chrf': base_chrf}\n",
    "        scores = pd.DataFrame(data)\n",
    "        scores.to_csv(r'base_scores_tech.csv', index=False)\n",
    "        print(i)\n",
    "        \n",
    "data = {'rouge1': base_r1, 'rouge2': base_r2, 'rogueL': base_rL, 'rogueLs': base_rLs, 'chrf': base_chrf}\n",
    "scores = pd.DataFrame(data)\n",
    "scores.to_csv(r'base_scores_tech.csv', index=False)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf940ada-ad3b-41ba-a68e-df45eef6b897",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('rouge1 average: ', np.mean(base_r1))\n",
    "print('rouge2 average: ', np.mean(base_r2))\n",
    "print('rougeL average: ', np.mean(base_rL))\n",
    "print('rougeLs average:', np.mean(base_rLs))\n",
    "print('chrf average:', np.mean(base_chrf))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
