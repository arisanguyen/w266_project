{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b049999-077d-4d48-a02d-94c842050121",
   "metadata": {
    "tags": []
   },
   "source": [
    "**BART Trained on XL SUM**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d1de3e-85a6-4307-8abf-fbfcae0be263",
   "metadata": {},
   "source": [
    "**Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0dfe809d-a7a8-47b6-a2e0-2d7bf7d74fd7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/w266/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import math\n",
    "\n",
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "\n",
    "import inspect\n",
    "\n",
    "#let's make longer output readable without horizontal scrolling\n",
    "from pprint import pprint\n",
    "\n",
    "import warnings\n",
    "\n",
    "import regex as re\n",
    "\n",
    "import os, re\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# These auto classes load the right type of tokenizer and model based on a model name\n",
    "from transformers import AutoTokenizer, TFAutoModel\n",
    "from transformers import pipeline\n",
    "from transformers import AutoModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ef6ab7-aa59-479f-a0e8-e0e34a21dc7f",
   "metadata": {},
   "source": [
    "**Necessary Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce3330d3-069e-48dc-8a0b-e2ef7d72a2bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rouge = evaluate.load('rouge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "216551a6-cb1e-4516-aa9b-b18d88807a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "chrf = evaluate.load(\"chrf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a32aaf5-c5bb-4052-8b50-af66dbb96312",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_default_args(func):\n",
    "    signature = inspect.signature(func)\n",
    "    return {\n",
    "        k: v.default\n",
    "        for k, v in signature.parameters.items()\n",
    "        if v.default is not inspect.Parameter.empty\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44de8cc2-471c-4ad3-b94d-8473c6c3c244",
   "metadata": {
    "tags": []
   },
   "source": [
    "**BART Resources**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6b616e-4e2b-46eb-83b7-75930d6a43ee",
   "metadata": {},
   "source": [
    "https://github.com/huggingface/transformers/blob/main/examples/pytorch/summarization/run_summarization.py\n",
    "\n",
    "https://www.databricks.com/blog/2023/03/20/fine-tuning-large-language-models-hugging-face-and-deepspeed.html\n",
    "\n",
    "https://gitlab.com/nicolalandro/summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18e1260",
   "metadata": {},
   "source": [
    "**Untrained Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "449d56b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'w266_project'\n",
      "/home/ubuntu/w266_project\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/w266_project'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd\n",
    "%cd w266_project\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a565c954",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anthony ZurcherNorth America reporter@awzurche...</td>\n",
       "      <td>On day three of public hearings in the impeach...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It made a net profit of $281m (£185m) in the t...</td>\n",
       "      <td>Yum Brands, owner of KFC and Pizza Hut restaur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Police sources told local media that the boy h...</td>\n",
       "      <td>Four members of the same family have been arre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Zelda Perkins told the Financial Times she sig...</td>\n",
       "      <td>A British former assistant of Harvey Weinstein...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bus workers walked out on Monday over changes ...</td>\n",
       "      <td>Bus drivers in Jersey have agreed to meet with...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Anthony ZurcherNorth America reporter@awzurche...   \n",
       "1  It made a net profit of $281m (£185m) in the t...   \n",
       "2  Police sources told local media that the boy h...   \n",
       "3  Zelda Perkins told the Financial Times she sig...   \n",
       "4  Bus workers walked out on Monday over changes ...   \n",
       "\n",
       "                                             summary  \n",
       "0  On day three of public hearings in the impeach...  \n",
       "1  Yum Brands, owner of KFC and Pizza Hut restaur...  \n",
       "2  Four members of the same family have been arre...  \n",
       "3  A British former assistant of Harvey Weinstein...  \n",
       "4  Bus drivers in Jersey have agreed to meet with...  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Datasets/xl_sum_sample_val.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3cd29df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dft = pd.read_csv('Datasets/xl_sum_sample_test.csv')\n",
    "#dft.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e53bea3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#remember to push new model to huggingface repo after running prev cell so that this cell uses the most recent model!!!!!!!\n",
    "\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f7af645-28d9-4177-bd58-c2a1564d8f35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/w266/lib/python3.8/site-packages/transformers/generation/utils.py:1219: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n",
      "Your max_length is set to 256, but you input_length is only 86. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=43)\n",
      "Your max_length is set to 256, but you input_length is only 92. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=46)\n",
      "Your max_length is set to 256, but you input_length is only 193. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=96)\n",
      "Your max_length is set to 256, but you input_length is only 254. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=127)\n",
      "Your max_length is set to 256, but you input_length is only 187. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=93)\n",
      "Your max_length is set to 256, but you input_length is only 226. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=113)\n",
      "Your max_length is set to 256, but you input_length is only 178. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=89)\n",
      "Your max_length is set to 256, but you input_length is only 224. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=112)\n",
      "Your max_length is set to 256, but you input_length is only 182. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=91)\n",
      "Your max_length is set to 256, but you input_length is only 198. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=99)\n",
      "Your max_length is set to 256, but you input_length is only 173. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=86)\n",
      "Your max_length is set to 256, but you input_length is only 209. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=104)\n",
      "Your max_length is set to 256, but you input_length is only 70. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=35)\n",
      "Your max_length is set to 256, but you input_length is only 251. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=125)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last Article By Alice EvansBBC News 1. Value for money For the men's World Cup last summer, your pockets had to be bulging with Russian roubles if you wanted a chance to see football come home (or not) with your own eyes. The best seats in the house for the France v Croatia men's final cost an eye-watering 66,000 roubles (£824.44). But don't despair. If you don't have a spare 800 quid jangling around, it's still possible for you to go to a World Cup final. The most expensive seats in the women's final at the Stade de Lyon on 7 July are more than 10 times cheaper than in the men's tournament at £75.12 (84EUR). At the Women's World Cup in France this year, you can actually watch a game for as little as £8.05 (9EUR). C'est magnifique, non? This pricing imbalance manifests itself in merchandise, too. Perhaps to Nike's credit, the official shirts of the men's and women's World Cups both cost £89.95. However, while it is free to add the name of a Lioness to the women's shirt, it costs £13 to splash names such as Kane, Rashford or Vardy across your shoulders. Nike hasn't responded to a request for clarification on why this is the case. 2. More goals The stats speak for themselves on this one. For a start, Brazilian women's forward Marta is the all-time World Cup top scorer for both men and women, with 17 goals to her name across 19 matches. So far in this year's tournament the women have scored 2.69 goals per game - just edging out the men, who scored 2.64 goals per game in last year's World Cup. The women are even further ahead in the top leagues. Over the last three seasons of the Women's Super League there were 3.05 goals per match, compared with a measly 2.76 goals in the men's top tournament, the Premier League. 3. Women stick to the rules We're not saying women are angels on the pitch (in fact, Cameroon were described as quite the opposite when they played England on Sunday). But they break the rules less often than men do. Fifa didn't provide stats for bookings in World Cup games, but we did manage to pull some together from data provided by Opta Sports for the FA, which runs England's top league games. It turns out, in the 2018-19 season, Premier League players (men) were three times more likely than players in the Women's Super League to be sent off in matches. Men were also handed yellow cards twice as often. Over the last three seasons, there were 3,777 yellow cards given to Premier League players - a rate of 3.3 per game - compared with 399 given to Women's Super League players (1.5 per game). Janie Frampton, who has refereed both men's and women's international matches in her 30-year career, said the \"streak of cheating\" that so many top male players express is in part down to \"far too much money and far too many big egos\". However, the data from the Football Association (FA) also suggests the amount of yellow cards given for fouls per women's match is creeping up. It went from 1.3 per game in 2016-17 to 1.5 in the following year and 1.6 last season. Frampton believes an increase in rule-breaking is inevitable as women's football becomes more popular. \"The women's game is becoming far more professional, and by that happening, the skill factor, the determination and challenge of the game is getting much higher,\" she said. \"Women's football has become far more important, and that's going to bring the more competitive edge, which is going to bring tougher challenges and more cards,\" she added. So if the upward trend continues, it won't be long until the women are making Zinedine Zidane's head-butt look like an Eskimo kiss. Only kidding. There's no way you can make that infamous moment look any less brutal. 4. Global competition Men's World Cup winners have only ever come from eight countries across two continents - Europe and South America. There have been four times as many men's World Cups as women's, but the women's tournament has already produced four countries as winners from North America, Europe and Asia. The greater number of teams with a genuine chance to lift that treasured golden trophy arguably makes the women's game all the more exciting. 5. LGBT+ support It's a widely accepted shame that there is not one openly gay footballer in the Premier League. In 1990, former England Under-21 international Justin Fashanu was the first professional footballer in Britain to come out as gay. The ex-Aston Villa midfielder Thomas Hitzlsperger, who came out following his retirement in 2014, said there is a \"long way to go\" before men come out while playing in a top league. By contrast, the women's game is considered far more inclusive. When ex-England player Casey Stoney spoke out about being gay for the first time just months after Hitzlsperger, she said homosexuality was more accepted in the women's game. And West Ham United women's captain Gilly Flaherty said last season: \"Everyone has accepted me for who I am. Women's football is a sport where a player can be openly gay and no one acts any differently towards you because of it, which is a great thing.\" The better levels of tolerance and acceptance in the women's game could be partly thanks to pioneer, Lily Parr. The 6ft chain-smoker - whose wages from Dick, Kerr Ladies FC, were reputedly supplemented by packets of Woodbine cigarettes - was gay, although some dispute how open she was about this. Parr paved the way for English women's footballing success and was the first woman to feature in the National Football Museum's Hall of Fame. Are England women better than men? In the last three Women's World Cups, England came third once and got into the final eight twice. The men finished fourth in 2018, were knocked out of the group stages in 2014 and made the final 16 in 2010. The stats behind these results show an almost identical track record. In 2018 England men scored 12 goals in seven matches, while the women scored 10 in seven matches in the 2015 tournament. Both teams received a total of eight yellow cards. The men conceded eight goals while the women conceded seven. It might be too tough to call which is the better team for now, but the women have everything to prove when they face Norway in the quarter-finals on Thursday. Watch this space - perhaps we'll be singing \"three Lionesses on a shirt\" and naming train stations after Phil Neville before the summer's over.\n",
      "Last Reference Summary [\"The widespread coverage and high drama of the Fifa Women's World Cup has sparked football fever across the UK, with a record-breaking 6.9 million people watching England's most recent clash. There were still far more people watching men's World Cup matches, with 26.5 million viewers tuning in to see England knocked out last year. But there are some ways women's football is hitting the back of the net - while the male strand of the sometimes-beautiful game bounces disappointingly off the crossbar.\"]\n",
      "Last Candidate Summary [\"By Alice EvansBBC News 1. Value for money For the men's World Cup last summer, your pockets had to be bulging with Russian roubles if you wanted a chance to see football come home (or not) with your own eyes. The best seats in the house for the France v Croatia men's final cost an eye-watering 66,000 roubles (£824.44). But don't despair. If you don't have a spare 800 quid jangling around, it's still possible for you to go to a World Cup final. The most expensive seats in a women's final at the Stade de Lyon on 7 July are more than 10 times cheaper than in the men, at £75.12 (84EUR). At the Women's World cup in France this year, you can actually watch a game for as little as £8.05 (9EUR), which is a bargain for a woman's final. C'est magnifique, non? This pricing imbalance manifests itself in merchandise, too. Perhaps to Nike's credit, the official shirts of the men and women's World Cups both cost £89.95. However, while it is free to add the name of a Lioness to the women's\"]\n",
      "rouge1 average : 0.12176148442471194\n",
      "rouge2 average : 0.029695977948519067\n",
      "rougeL average : 0.08052143316107378\n",
      "rougeLs average : 0.08052143316107378\n",
      "chrf average : 20.497366577145943\n"
     ]
    }
   ],
   "source": [
    "bart_scores(summarizer, dft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a044380d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bart_untrained(dataframe):\n",
    "\n",
    "    bart_r1 = []\n",
    "    bart_r2 = []\n",
    "    bart_rL = []\n",
    "    bart_rLs = []\n",
    "    bart_chrf = []\n",
    "\n",
    "    for i in range(int(len(dataframe['text']))):\n",
    "\n",
    "        candidate = summarizer(dataframe['text'][i], \n",
    "                               truncation = True, #truncated to first 1024 words, because that is all the model can handle\n",
    "                               max_length = 256, # same as pegasus\n",
    "                               min_length = 0, \n",
    "                                )[0]\n",
    "        candidate = [candidate['summary_text']]\n",
    "        #pprint(candidate[0], compact=True)\n",
    "\n",
    "        ref = [dataframe['summary'][i]]\n",
    "\n",
    "        results = rouge.compute(predictions=candidate,\n",
    "                                references=ref)\n",
    "\n",
    "        bart_r1.append(results['rouge1'])\n",
    "        bart_r2.append(results['rouge2'])\n",
    "        bart_rL.append(results['rougeL'])\n",
    "        bart_rLs.append(results['rougeLsum'])\n",
    "\n",
    "        results = chrf.compute(predictions=candidate,\n",
    "                                references=ref)\n",
    "\n",
    "        bart_chrf.append(results['score'])\n",
    "\n",
    "    print('rouge1 average :', np.mean(bart_r1))\n",
    "    print('rouge2 average :', np.mean(bart_r2))\n",
    "    print('rougeL average :', np.mean(bart_rL))\n",
    "    print('rougeLs average :', np.mean(bart_rLs))\n",
    "    print('chrf average :', np.mean(bart_chrf))\n",
    "        \n",
    "    #     if i in np.arange(0, 2000, 100):\n",
    "    #         data = {'rouge1': bart_r1, 'rouge2': bart_r2, 'rogueL': bart_rL, 'rogueLs': bart_rLs, 'chrf': bart_chrf}\n",
    "    #         scores = pd.DataFrame(data)\n",
    "    #         scores.to_csv(r'BART_trained_0_scores.csv', index=False)\n",
    "    #         print(i)\n",
    "\n",
    "    # data = {'rouge1': bart_r1, 'rouge2': bart_r2, 'rogueL': bart_rL, 'rogueLs': bart_rLs,'chrf': bart_chrf}\n",
    "    # scores = pd.DataFrame(data)\n",
    "    # scores.to_csv(r'BART_trained_0_scores.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90588b89",
   "metadata": {},
   "source": [
    "All Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "edc58be5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/w266/lib/python3.8/site-packages/transformers/generation/utils.py:1219: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n",
      "Your max_length is set to 256, but you input_length is only 86. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=43)\n",
      "Your max_length is set to 256, but you input_length is only 92. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=46)\n",
      "Your max_length is set to 256, but you input_length is only 193. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=96)\n",
      "Your max_length is set to 256, but you input_length is only 254. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=127)\n",
      "Your max_length is set to 256, but you input_length is only 187. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=93)\n",
      "Your max_length is set to 256, but you input_length is only 226. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=113)\n",
      "Your max_length is set to 256, but you input_length is only 178. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=89)\n",
      "Your max_length is set to 256, but you input_length is only 224. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=112)\n",
      "Your max_length is set to 256, but you input_length is only 182. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=91)\n",
      "Your max_length is set to 256, but you input_length is only 198. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=99)\n",
      "Your max_length is set to 256, but you input_length is only 173. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=86)\n",
      "Your max_length is set to 256, but you input_length is only 209. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=104)\n",
      "Your max_length is set to 256, but you input_length is only 70. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=35)\n",
      "Your max_length is set to 256, but you input_length is only 251. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=125)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rouge1 average : 0.1223548369492104\n",
      "rouge2 average : 0.03007936547579612\n",
      "rougeL average : 0.08099594851409213\n",
      "rougeLs average : 0.08099594851409213\n",
      "chrf average : 20.607812911329166\n"
     ]
    }
   ],
   "source": [
    "bart_untrained(dft)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220375a5",
   "metadata": {},
   "source": [
    "Technology Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5c0b9799",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tech = pd.read_csv('Datasets/xl_sum_sample_test_technology.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6acfcaef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 256, but you input_length is only 187. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=93)\n",
      "Your max_length is set to 256, but you input_length is only 175. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=87)\n",
      "Your max_length is set to 256, but you input_length is only 217. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=108)\n",
      "Your max_length is set to 256, but you input_length is only 244. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=122)\n",
      "Your max_length is set to 256, but you input_length is only 234. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=117)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rouge1 average : 0.26467407462886744\n",
      "rouge2 average : 0.07949470580163175\n",
      "rougeL average : 0.2153170488745322\n",
      "rougeLs average : 0.2153170488745322\n",
      "chrf average : 27.50620894169297\n"
     ]
    }
   ],
   "source": [
    "bart_untrained(df_tech)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3168e22",
   "metadata": {},
   "source": [
    "**Trained**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdae58a-e4c0-4a6c-8f67-b8309a24c665",
   "metadata": {},
   "source": [
    "**All Categories: Model 0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41489617-caa3-421b-861a-7716cb853985",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 transformers/examples/pytorch/summarization/run_summarization.py \\\n",
    "    --model_name_or_path=facebook/bart-base \\\n",
    "    --do_train \\\n",
    "    --do_eval \\\n",
    "    --train_file 'w266_project/xl_sum_sample_train.csv' \\\n",
    "    --validation_file 'w266_project/xl_sum_sample_val.csv' \\\n",
    "    --text_column text \\\n",
    "    --summary_column summary \\\n",
    "    --push_to_hub=True \\\n",
    "    --max_source_length 128 \\\n",
    "    --max_target_length 32 \\\n",
    "    --num_train_epochs 1 \\\n",
    "    --per_device_train_batch_size=32 \\\n",
    "    --per_device_eval_batch_size=32 \\\n",
    "    --output_dir='w266_project/finetuned-BART-all-categories/model 0/finetuned-BART-all-categories' \\\n",
    "    --overwrite_output_dir=True \\\n",
    "    --predict_with_generate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7a1f378c-07b9-48ec-b77c-c4bc558143af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#remember to push new model to huggingface repo after running prev cell so that this cell uses the most recent model!!!!!!!\n",
    "\n",
    "summarizer = pipeline(\"summarization\", model=\"arisanguyen/finetuned-BART-all-categories\", revision = 'model_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c26b8a9c-6385-4f29-b3fc-caa2bbbd1c10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/w266/lib/python3.8/site-packages/transformers/generation/utils.py:1219: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n",
      "Your max_length is set to 128, but you input_length is only 123. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=61)\n",
      "Your max_length is set to 128, but you input_length is only 56. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=28)\n",
      "Your max_length is set to 128, but you input_length is only 80. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=40)\n"
     ]
    }
   ],
   "source": [
    "bart_r1 = []\n",
    "bart_r2 = []\n",
    "bart_rL = []\n",
    "bart_rLs = []\n",
    "bart_chrf = []\n",
    "\n",
    "for i in range(int(len(df['text']))):\n",
    "    \n",
    "    #art = ' '.join(df['article'][i].split(' ')[:1024]) #truncated to first 1024 words, because that is all the model can handle\n",
    "    \n",
    "    candidate = summarizer(df['text'][i], \n",
    "                           truncation = True, #truncated to first 1024 words, because that is all the model can handle\n",
    "                             #max_length=130, min_length=30, do_sample=False\n",
    "                            )[0]\n",
    "    candidate = [candidate['summary_text']]\n",
    "    #pprint(candidate[0], compact=True)\n",
    "    \n",
    "    ref = [df['summary'][i]]\n",
    "    \n",
    "    results = rouge.compute(predictions=candidate,\n",
    "                            references=ref)\n",
    "    \n",
    "    bart_r1.append(results['rouge1'])\n",
    "    bart_r2.append(results['rouge2'])\n",
    "    bart_rL.append(results['rougeL'])\n",
    "    bart_rLs.append(results['rougeLsum'])\n",
    "    \n",
    "    results = chrf.compute(predictions=candidate,\n",
    "                            references=ref)\n",
    "    \n",
    "    bart_chrf.append(results['score'])\n",
    "    \n",
    "#     if i in np.arange(0, 2000, 100):\n",
    "#         data = {'rouge1': bart_r1, 'rouge2': bart_r2, 'rogueL': bart_rL, 'rogueLs': bart_rLs, 'chrf': bart_chrf}\n",
    "#         scores = pd.DataFrame(data)\n",
    "#         scores.to_csv(r'BART_trained_0_scores.csv', index=False)\n",
    "#         print(i)\n",
    "        \n",
    "# data = {'rouge1': bart_r1, 'rouge2': bart_r2, 'rogueL': bart_rL, 'rogueLs': bart_rLs,'chrf': bart_chrf}\n",
    "# scores = pd.DataFrame(data)\n",
    "# scores.to_csv(r'BART_trained_0_scores.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5ed12cd2-800e-43b2-b5d3-445b531d7326",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last Article She tweeted that the clothes would be \"archived & expertly cared for in the spirit & love of Michael Jackson, his bravery, & fans worldwide\". The auction included a jacket worn during Jackson's Bad tour, that went for $240,000 (£148,000) and two crystal gloves. The items were all made by designers Dennis Tompkins and Michael Bush. Lady Gaga also tweeted a picture of herself and her bidding paddle at the auction. More than $5m (£3.1m) was raised by the sale, according to LA-based Julien's Auctions. Other items that went under the hammer included jackets from Michael Jackson's Dangerous and Thriller tours and a pair of jeans that went for $50,000 (£31,000). Some of the money raised by the auction is being donated to a guide dogs charity and a hospice in Las Vegas. American costume designers Michael Bush and Dennis Tompkins created thousands of original pieces for Michael Jackson during his career. However, despite Lady Gaga's assurances, some fans expressed their anger online, claiming that Jackson wanted his costumes to end up in a museum. The singer died on 25 June 2009 from an overdose of the powerful anaesthetic propofol. His personal doctor, Conrad Murray, was later found guilty of his involuntary manslaughter and sentenced to four years in jail. Follow @BBCNewsbeat on Twitter\n",
      "Last Reference Summary ['Lady Gaga has bought 55 items at an auction of Michael Jackson costumes in Los Angeles.']\n",
      "Last Candidate Summary [\"Lady Gaga has announced that she will be auctioning off a collection of Michael Jackson's costumes at an auction in Las Vegas.\"]\n"
     ]
    }
   ],
   "source": [
    "print('Last Article', df['text'][i])\n",
    "print('Last Reference Summary', ref)\n",
    "print('Last Candidate Summary', candidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9ae281a4-5d2e-48fa-a4a4-0a500d69e539",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rouge1 average : 0.3192639042917483\n",
      "rouge2 average : 0.10466960084268205\n",
      "rougeL average : 0.24501046685959502\n",
      "rougeLs average : 0.24501046685959502\n",
      "chrf average : 27.774860738085867\n"
     ]
    }
   ],
   "source": [
    "print('rouge1 average :', np.mean(bart_r1))\n",
    "print('rouge2 average :', np.mean(bart_r2))\n",
    "print('rougeL average :', np.mean(bart_rL))\n",
    "print('rougeLs average :', np.mean(bart_rLs))\n",
    "print('chrf average :', np.mean(bart_chrf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d130492-21d3-4af9-b626-9fa36e271252",
   "metadata": {},
   "source": [
    "**All Categories: Model 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea7edaa-d918-4c59-8750-f70dc45e7527",
   "metadata": {},
   "source": [
    "Added revision version. Set the max source length to 512, target length to 256, and number of epochs to 62 (~2k steps total) to be same as PEGASUS. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9182eab-2816-4040-82cb-9b85b74ceded",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 transformers/examples/pytorch/summarization/run_summarization.py \\\n",
    "    --model_name_or_path=facebook/bart-base \\\n",
    "    --do_train \\\n",
    "    --train_file 'w266_project/xl_sum_sample_train.csv' \\\n",
    "    --text_column text \\\n",
    "    --summary_column summary \\\n",
    "    --max_source_length 512 \\\n",
    "    --max_target_length 256 \\\n",
    "    --num_train_epochs 62 \\\n",
    "    --per_device_train_batch_size=32 \\\n",
    "    --push_to_hub=True \\\n",
    "    --output_dir='w266_project/finetuned-BART-all-categories/model 1/finetuned-BART-all-categories' \\\n",
    "    --overwrite_output_dir=True \\\n",
    "    --predict_with_generate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "06c6c9a2-07fa-48ac-bb37-2395345a49a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#remember to push new model to huggingface repo after running prev cell so that this cell uses the most recent model!!!!!!!\n",
    "\n",
    "# model = AutoModel.from_pretrained(\n",
    "#     \"julien-c/EsperBERTo-small\", revision=\"v2.0.1\"  # tag name, or branch name, or commit hash\n",
    "# )\n",
    "\n",
    "summarizer = pipeline(\"summarization\", model=\"arisanguyen/finetuned-BART-all-categories\", revision = \"model_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001c815f-2455-4d9c-8e83-fdeb7e200a78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "get_default_args(summarizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "23b4ba40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu\n"
     ]
    }
   ],
   "source": [
    "%pwd\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9062b049-9393-44a7-86ec-c5d0cdacdba9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/w266/lib/python3.8/site-packages/transformers/generation/utils.py:1219: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 256, but you input_length is only 172. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=86)\n",
      "Your max_length is set to 256, but you input_length is only 123. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=61)\n",
      "Your max_length is set to 256, but you input_length is only 221. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=110)\n",
      "Your max_length is set to 256, but you input_length is only 255. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=127)\n",
      "Your max_length is set to 256, but you input_length is only 56. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=28)\n",
      "Your max_length is set to 256, but you input_length is only 151. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=75)\n",
      "Your max_length is set to 256, but you input_length is only 220. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=110)\n",
      "Your max_length is set to 256, but you input_length is only 219. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=109)\n",
      "Your max_length is set to 256, but you input_length is only 191. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=95)\n",
      "Your max_length is set to 256, but you input_length is only 240. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=120)\n",
      "Your max_length is set to 256, but you input_length is only 212. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=106)\n",
      "Your max_length is set to 256, but you input_length is only 227. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=113)\n",
      "Your max_length is set to 256, but you input_length is only 80. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=40)\n",
      "Your max_length is set to 256, but you input_length is only 163. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=81)\n",
      "Your max_length is set to 256, but you input_length is only 202. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=101)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last Article She tweeted that the clothes would be \"archived & expertly cared for in the spirit & love of Michael Jackson, his bravery, & fans worldwide\". The auction included a jacket worn during Jackson's Bad tour, that went for $240,000 (£148,000) and two crystal gloves. The items were all made by designers Dennis Tompkins and Michael Bush. Lady Gaga also tweeted a picture of herself and her bidding paddle at the auction. More than $5m (£3.1m) was raised by the sale, according to LA-based Julien's Auctions. Other items that went under the hammer included jackets from Michael Jackson's Dangerous and Thriller tours and a pair of jeans that went for $50,000 (£31,000). Some of the money raised by the auction is being donated to a guide dogs charity and a hospice in Las Vegas. American costume designers Michael Bush and Dennis Tompkins created thousands of original pieces for Michael Jackson during his career. However, despite Lady Gaga's assurances, some fans expressed their anger online, claiming that Jackson wanted his costumes to end up in a museum. The singer died on 25 June 2009 from an overdose of the powerful anaesthetic propofol. His personal doctor, Conrad Murray, was later found guilty of his involuntary manslaughter and sentenced to four years in jail. Follow @BBCNewsbeat on Twitter\n",
      "Last Reference Summary ['Lady Gaga has bought 55 items at an auction of Michael Jackson costumes in Los Angeles.']\n",
      "Last Candidate Summary ['Lady Gaga has auctioned off hundreds of items worth more than $190,000 (£152,000) at an auction in Las Vegas.']\n",
      "rouge1 average : 0.31336770582535894\n",
      "rouge2 average : 0.09975946851022606\n",
      "rougeL average : 0.23881053257054677\n",
      "rougeLs average : 0.23881053257054677\n",
      "chrf average : 28.86864045130219\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./w266_project/Datasets/xl_sum_sample_val.csv')\n",
    "\n",
    "bart_r1 = []\n",
    "bart_r2 = []\n",
    "bart_rL = []\n",
    "bart_rLs = []\n",
    "bart_chrf = []\n",
    "\n",
    "for i in range(int(len(df['text']))):\n",
    "    \n",
    "    #art = ' '.join(df['article'][i].split(' ')[:1024]) #truncated to first 1024 words, because that is all the model can handle\n",
    "    \n",
    "    candidate = summarizer(df['text'][i], \n",
    "                           truncation = True, #truncated to first 1024 words, because that is all the model can handle\n",
    "                           max_length = 256, # same as pegasus\n",
    "                           min_length = 0, \n",
    "                             #max_length=130, min_length=30, do_sample=False\n",
    "                            )[0]\n",
    "    candidate = [candidate['summary_text']]\n",
    "    #pprint(candidate[0], compact=True)\n",
    "    \n",
    "    ref = [df['summary'][i]]\n",
    "    \n",
    "    results = rouge.compute(predictions=candidate,\n",
    "                            references=ref)\n",
    "    \n",
    "    bart_r1.append(results['rouge1'])\n",
    "    bart_r2.append(results['rouge2'])\n",
    "    bart_rL.append(results['rougeL'])\n",
    "    bart_rLs.append(results['rougeLsum'])\n",
    "    \n",
    "    results = chrf.compute(predictions=candidate,\n",
    "                            references=ref)\n",
    "    \n",
    "    bart_chrf.append(results['score'])\n",
    "    \n",
    "    if i in np.arange(0, 2000, 100):\n",
    "        data = {'rouge1': bart_r1, 'rouge2': bart_r2, 'rogueL': bart_rL, 'rogueLs': bart_rLs, 'chrf': bart_chrf}\n",
    "        scores = pd.DataFrame(data)\n",
    "        scores.to_csv(r'BART_trained_1_scores.csv', index=False)\n",
    "        print(i)\n",
    "        \n",
    "data = {'rouge1': bart_r1, 'rouge2': bart_r2, 'rogueL': bart_rL, 'rogueLs': bart_rLs,'chrf': bart_chrf}\n",
    "scores = pd.DataFrame(data)\n",
    "scores.to_csv(r'BART_trained_1_scores.csv', index=False)\n",
    "\n",
    "print('Last Article', df['text'][i])\n",
    "print('Last Reference Summary', ref)\n",
    "print('Last Candidate Summary', candidate)\n",
    "\n",
    "print('rouge1 average :', np.mean(bart_r1))\n",
    "print('rouge2 average :', np.mean(bart_r2))\n",
    "print('rougeL average :', np.mean(bart_rL))\n",
    "print('rougeLs average :', np.mean(bart_rLs))\n",
    "print('chrf average :', np.mean(bart_chrf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5276d8de",
   "metadata": {},
   "source": [
    "**All Categories: Model 2 (added beams, chagned epochs, added validation target length)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d9163574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd\n",
    "%cd ..\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6bffb3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/home/ubuntu/w266/lib/python3.8/site-packages/torch/cuda/__init__.py:546: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "04/07/2023 15:57:38 - WARNING - __main__ - Process rank: -1, device: cpu, n_gpu: 0distributed training: False, 16-bits training: False\n",
      "04/07/2023 15:57:38 - INFO - __main__ - Training/evaluation parameters Seq2SeqTrainingArguments(\n",
      "_n_gpu=0,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "generation_config=None,\n",
      "generation_max_length=None,\n",
      "generation_num_beams=None,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=5e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=w266_project/finetuned-BART-all-categories/model 2/finetuned-BART-all-categories/runs/Apr07_15-57-38_ip-172-31-55-240,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=500,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=linear,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=5.0,\n",
      "optim=adamw_hf,\n",
      "optim_args=None,\n",
      "output_dir=w266_project/finetuned-BART-all-categories/model 2/finetuned-BART-all-categories,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=32,\n",
      "predict_with_generate=True,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=True,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=['tensorboard'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=w266_project/finetuned-BART-all-categories/model 2/finetuned-BART-all-categories,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=steps,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "sortish_sampler=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "04/07/2023 15:57:38 - INFO - datasets.builder - Using custom data configuration default-6794da18f7676227\n",
      "04/07/2023 15:57:38 - INFO - datasets.info - Loading Dataset Infos from /home/ubuntu/w266/lib/python3.8/site-packages/datasets/packaged_modules/csv\n",
      "04/07/2023 15:57:38 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "04/07/2023 15:57:38 - INFO - datasets.info - Loading Dataset info from /home/ubuntu/.cache/huggingface/datasets/csv/default-6794da18f7676227/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\n",
      "04/07/2023 15:57:38 - WARNING - datasets.builder - Found cached dataset csv (/home/ubuntu/.cache/huggingface/datasets/csv/default-6794da18f7676227/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n",
      "04/07/2023 15:57:38 - INFO - datasets.info - Loading Dataset info from /home/ubuntu/.cache/huggingface/datasets/csv/default-6794da18f7676227/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 684.78it/s]\n",
      "[INFO|configuration_utils.py:668] 2023-04-07 15:57:38,934 >> loading configuration file config.json from cache at /home/ubuntu/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-04-07 15:57:38,941 >> Model config BartConfig {\n",
      "  \"_name_or_path\": \"facebook/bart-base\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.28.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "[INFO|tokenization_auto.py:494] 2023-04-07 15:57:38,973 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "[INFO|configuration_utils.py:668] 2023-04-07 15:57:39,000 >> loading configuration file config.json from cache at /home/ubuntu/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-04-07 15:57:39,000 >> Model config BartConfig {\n",
      "  \"_name_or_path\": \"facebook/bart-base\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.28.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1809] 2023-04-07 15:57:39,070 >> loading file vocab.json from cache at /home/ubuntu/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/vocab.json\n",
      "[INFO|tokenization_utils_base.py:1809] 2023-04-07 15:57:39,070 >> loading file merges.txt from cache at /home/ubuntu/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/merges.txt\n",
      "[INFO|tokenization_utils_base.py:1809] 2023-04-07 15:57:39,070 >> loading file tokenizer.json from cache at /home/ubuntu/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:1809] 2023-04-07 15:57:39,070 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1809] 2023-04-07 15:57:39,070 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1809] 2023-04-07 15:57:39,070 >> loading file tokenizer_config.json from cache at None\n",
      "[INFO|configuration_utils.py:668] 2023-04-07 15:57:39,070 >> loading configuration file config.json from cache at /home/ubuntu/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-04-07 15:57:39,071 >> Model config BartConfig {\n",
      "  \"_name_or_path\": \"facebook/bart-base\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.28.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:2451] 2023-04-07 15:57:39,172 >> loading weights file pytorch_model.bin from cache at /home/ubuntu/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/pytorch_model.bin\n",
      "[INFO|configuration_utils.py:575] 2023-04-07 15:57:42,695 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.28.0.dev0\"\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3100] 2023-04-07 15:57:45,076 >> All model checkpoint weights were used when initializing BartForConditionalGeneration.\n",
      "\n",
      "[INFO|modeling_utils.py:3108] 2023-04-07 15:57:45,076 >> All the weights of BartForConditionalGeneration were initialized from the model checkpoint at facebook/bart-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BartForConditionalGeneration for predictions without further training.\n",
      "[INFO|modeling_utils.py:2753] 2023-04-07 15:57:45,114 >> Generation config file not found, using a generation config created from the model config.\n",
      "04/07/2023 15:57:45 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/ubuntu/.cache/huggingface/datasets/csv/default-6794da18f7676227/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-6f5dbeec5a6410bc.arrow\n",
      "/home/ubuntu/w266_project/finetuned-BART-all-categories/model 2/finetuned-BART-all-categories is already a clone of https://huggingface.co/arisanguyen/finetuned-BART-all-categories. Make sure you pull the latest changes with `repo.git_pull()`.\n",
      "04/07/2023 15:57:45 - WARNING - huggingface_hub.repository - /home/ubuntu/w266_project/finetuned-BART-all-categories/model 2/finetuned-BART-all-categories is already a clone of https://huggingface.co/arisanguyen/finetuned-BART-all-categories. Make sure you pull the latest changes with `repo.git_pull()`.\n",
      "/home/ubuntu/w266/lib/python3.8/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "[INFO|trainer.py:1746] 2023-04-07 15:57:47,848 >> ***** Running training *****\n",
      "[INFO|trainer.py:1747] 2023-04-07 15:57:47,848 >>   Num examples = 1000\n",
      "[INFO|trainer.py:1748] 2023-04-07 15:57:47,848 >>   Num Epochs = 5\n",
      "[INFO|trainer.py:1749] 2023-04-07 15:57:47,848 >>   Instantaneous batch size per device = 32\n",
      "[INFO|trainer.py:1750] 2023-04-07 15:57:47,848 >>   Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "[INFO|trainer.py:1751] 2023-04-07 15:57:47,848 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1752] 2023-04-07 15:57:47,849 >>   Total optimization steps = 160\n",
      "[INFO|trainer.py:1753] 2023-04-07 15:57:47,849 >>   Number of trainable parameters = 139420416\n",
      "  0%|                                                   | 0/160 [00:00<?, ?it/s][WARNING|logging.py:280] 2023-04-07 15:57:47,875 >> You're using a BartTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "100%|█████████████████████████████████████████| 160/160 [44:03<00:00, 13.19s/it][INFO|trainer.py:2016] 2023-04-07 16:41:50,888 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "{'train_runtime': 2643.0389, 'train_samples_per_second': 1.892, 'train_steps_per_second': 0.061, 'train_loss': 2.1022010803222657, 'epoch': 5.0}\n",
      "100%|█████████████████████████████████████████| 160/160 [44:03<00:00, 16.52s/it]\n",
      "[INFO|trainer.py:2821] 2023-04-07 16:41:50,890 >> Saving model checkpoint to w266_project/finetuned-BART-all-categories/model 2/finetuned-BART-all-categories\n",
      "[INFO|configuration_utils.py:457] 2023-04-07 16:41:50,891 >> Configuration saved in w266_project/finetuned-BART-all-categories/model 2/finetuned-BART-all-categories/config.json\n",
      "[INFO|configuration_utils.py:362] 2023-04-07 16:41:50,892 >> Configuration saved in w266_project/finetuned-BART-all-categories/model 2/finetuned-BART-all-categories/generation_config.json\n",
      "[INFO|modeling_utils.py:1812] 2023-04-07 16:41:54,602 >> Model weights saved in w266_project/finetuned-BART-all-categories/model 2/finetuned-BART-all-categories/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2170] 2023-04-07 16:41:54,603 >> tokenizer config file saved in w266_project/finetuned-BART-all-categories/model 2/finetuned-BART-all-categories/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2177] 2023-04-07 16:41:54,603 >> Special tokens file saved in w266_project/finetuned-BART-all-categories/model 2/finetuned-BART-all-categories/special_tokens_map.json\n",
      "[INFO|trainer.py:2821] 2023-04-07 16:41:54,702 >> Saving model checkpoint to w266_project/finetuned-BART-all-categories/model 2/finetuned-BART-all-categories\n",
      "[INFO|configuration_utils.py:457] 2023-04-07 16:41:54,703 >> Configuration saved in w266_project/finetuned-BART-all-categories/model 2/finetuned-BART-all-categories/config.json\n",
      "[INFO|configuration_utils.py:362] 2023-04-07 16:41:54,704 >> Configuration saved in w266_project/finetuned-BART-all-categories/model 2/finetuned-BART-all-categories/generation_config.json\n",
      "[INFO|modeling_utils.py:1812] 2023-04-07 16:41:58,804 >> Model weights saved in w266_project/finetuned-BART-all-categories/model 2/finetuned-BART-all-categories/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2170] 2023-04-07 16:41:58,805 >> tokenizer config file saved in w266_project/finetuned-BART-all-categories/model 2/finetuned-BART-all-categories/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2177] 2023-04-07 16:41:58,805 >> Special tokens file saved in w266_project/finetuned-BART-all-categories/model 2/finetuned-BART-all-categories/special_tokens_map.json\n",
      "To https://huggingface.co/arisanguyen/finetuned-BART-all-categories\n",
      "   910e579..35a942e  main -> main\n",
      "\n",
      "04/07/2023 16:42:05 - WARNING - huggingface_hub.repository - To https://huggingface.co/arisanguyen/finetuned-BART-all-categories\n",
      "   910e579..35a942e  main -> main\n",
      "\n",
      "[INFO|modelcard.py:451] 2023-04-07 16:42:08,413 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Sequence-to-sequence Language Modeling', 'type': 'text2text-generation'}}\n",
      "***** train metrics *****\n",
      "  epoch                    =        5.0\n",
      "  train_loss               =     2.1022\n",
      "  train_runtime            = 0:44:03.03\n",
      "  train_samples            =       1000\n",
      "  train_samples_per_second =      1.892\n",
      "  train_steps_per_second   =      0.061\n",
      "[INFO|trainer.py:2821] 2023-04-07 16:42:08,566 >> Saving model checkpoint to w266_project/finetuned-BART-all-categories/model 2/finetuned-BART-all-categories\n",
      "[INFO|configuration_utils.py:457] 2023-04-07 16:42:08,567 >> Configuration saved in w266_project/finetuned-BART-all-categories/model 2/finetuned-BART-all-categories/config.json\n",
      "[INFO|configuration_utils.py:362] 2023-04-07 16:42:08,569 >> Configuration saved in w266_project/finetuned-BART-all-categories/model 2/finetuned-BART-all-categories/generation_config.json\n",
      "[INFO|modeling_utils.py:1812] 2023-04-07 16:42:12,367 >> Model weights saved in w266_project/finetuned-BART-all-categories/model 2/finetuned-BART-all-categories/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2170] 2023-04-07 16:42:12,367 >> tokenizer config file saved in w266_project/finetuned-BART-all-categories/model 2/finetuned-BART-all-categories/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2177] 2023-04-07 16:42:12,368 >> Special tokens file saved in w266_project/finetuned-BART-all-categories/model 2/finetuned-BART-all-categories/special_tokens_map.json\n",
      "To https://huggingface.co/arisanguyen/finetuned-BART-all-categories\n",
      "   35a942e..f71b33c  main -> main\n",
      "\n",
      "04/07/2023 16:42:18 - WARNING - huggingface_hub.repository - To https://huggingface.co/arisanguyen/finetuned-BART-all-categories\n",
      "   35a942e..f71b33c  main -> main\n",
      "\n",
      "[INFO|modelcard.py:451] 2023-04-07 16:42:22,289 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Summarization', 'type': 'summarization'}}\n"
     ]
    }
   ],
   "source": [
    "!python3 transformers/examples/pytorch/summarization/run_summarization.py \\\n",
    "    --model_name_or_path=facebook/bart-base \\\n",
    "    --do_train \\\n",
    "    --train_file 'w266_project/Datasets/xl_sum_sample_train.csv' \\\n",
    "    --text_column text \\\n",
    "    --summary_column summary \\\n",
    "    --max_source_length 512 \\\n",
    "    --max_target_length 256 \\\n",
    "    --val_max_target_length 256 \\\n",
    "    --num_beams 5 \\\n",
    "    --num_train_epochs 5 \\\n",
    "    --per_device_train_batch_size=32 \\\n",
    "    --push_to_hub=True \\\n",
    "    --output_dir='w266_project/finetuned-BART-all-categories/model 2/finetuned-BART-all-categories' \\\n",
    "    --overwrite_output_dir=True \\\n",
    "    --predict_with_generate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3043b773",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#remember to push new model to huggingface repo after running prev cell so that this cell uses the most recent model!!!!!!!\n",
    "\n",
    "summarizer = pipeline(\"summarization\", model=\"arisanguyen/finetuned-BART-all-categories\", revision = \"model_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7102e2f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hyperparameters defaults to huggingface defaults \n",
    "# https://huggingface.co/docs/transformers/main_classes/text_generation\n",
    "def bart_scores(mod, data, do_sample = False, num_beams = 1, top_k = 50, num_beam_groups = 1):\n",
    "\n",
    "    bart_r1 = []\n",
    "    bart_r2 = []\n",
    "    bart_rL = []\n",
    "    bart_rLs = []\n",
    "    bart_chrf = []\n",
    "    texts = []\n",
    "    references = []\n",
    "    candidates = []\n",
    "\n",
    "    for i in range(int(len(data['text']))):\n",
    "\n",
    "        #art = ' '.join(df['article'][i].split(' ')[:1024]) #truncated to first 1024 words, because that is all the model can handle\n",
    "\n",
    "        candidate = mod(data['text'][i], \n",
    "                               truncation = True, #truncated to first 1024 words, because that is all the model can handle\n",
    "                               max_length = 256, # same as pegasus\n",
    "                               min_length = 0, \n",
    "                               do_sample = do_sample,\n",
    "                               num_beams = num_beams, \n",
    "                               top_k = top_k,\n",
    "                               num_beam_groups = num_beam_groups,\n",
    "                                )[0]\n",
    "        candidate = [candidate['summary_text']]\n",
    "        #pprint(candidate[0], compact=True)\n",
    "\n",
    "        ref = [data['summary'][i]]\n",
    "\n",
    "        references.append(ref)\n",
    "        \n",
    "        candidates.append(candidate)\n",
    "        \n",
    "        texts.append(data['text'][i])\n",
    "        \n",
    "        results = rouge.compute(predictions=candidate,\n",
    "                                references=ref)\n",
    "\n",
    "        bart_r1.append(results['rouge1'])\n",
    "        bart_r2.append(results['rouge2'])\n",
    "        bart_rL.append(results['rougeL'])\n",
    "        bart_rLs.append(results['rougeLsum'])\n",
    "\n",
    "        results = chrf.compute(predictions=candidate,\n",
    "                                references=ref)\n",
    "\n",
    "        bart_chrf.append(results['score'])\n",
    "    \n",
    "    print('Last Article', data['text'][i])\n",
    "    print('Last Reference Summary', ref)\n",
    "    print('Last Candidate Summary', candidate)\n",
    "\n",
    "    print('rouge1 average :', np.mean(bart_r1))\n",
    "    print('rouge2 average :', np.mean(bart_r2))\n",
    "    print('rougeL average :', np.mean(bart_rL))\n",
    "    print('rougeLs average :', np.mean(bart_rLs))\n",
    "    print('chrf average :', np.mean(bart_chrf))\n",
    "    \n",
    "    data = {'articles': texts, 'refs': references, 'candidate':candidates, 'rouge1': bart_r1, 'rouge2': bart_r2, 'rogueL': bart_rL, 'rogueLs': bart_rLs,'chrf': bart_chrf}\n",
    "    scores = pd.DataFrame(data)\n",
    "    scores.to_csv(r'BART_untrained_scores.csv', index=False)\n",
    "    \n",
    "#     if i in np.arange(0, 2000, 100):\n",
    "#         data = {'rouge1': bart_r1, 'rouge2': bart_r2, 'rogueL': bart_rL, 'rogueLs': bart_rLs, 'chrf': bart_chrf}\n",
    "#         scores = pd.DataFrame(data)\n",
    "#         scores.to_csv(r'BART_trained_0_scores.csv', index=False)\n",
    "#         print(i)\n",
    "        \n",
    "# data = {'rouge1': bart_r1, 'rouge2': bart_r2, 'rogueL': bart_rL, 'rogueLs': bart_rLs,'chrf': bart_chrf}\n",
    "# scores = pd.DataFrame(data)\n",
    "# scores.to_csv(r'BART_trained_0_scores.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9bd6a2f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 256, but you input_length is only 172. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=86)\n",
      "Your max_length is set to 256, but you input_length is only 123. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=61)\n",
      "Your max_length is set to 256, but you input_length is only 221. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=110)\n",
      "Your max_length is set to 256, but you input_length is only 255. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=127)\n",
      "Your max_length is set to 256, but you input_length is only 56. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=28)\n",
      "Your max_length is set to 256, but you input_length is only 151. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=75)\n",
      "Your max_length is set to 256, but you input_length is only 220. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=110)\n",
      "Your max_length is set to 256, but you input_length is only 219. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=109)\n",
      "Your max_length is set to 256, but you input_length is only 191. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=95)\n",
      "Your max_length is set to 256, but you input_length is only 240. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=120)\n",
      "Your max_length is set to 256, but you input_length is only 212. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=106)\n",
      "Your max_length is set to 256, but you input_length is only 227. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=113)\n",
      "Your max_length is set to 256, but you input_length is only 80. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=40)\n",
      "Your max_length is set to 256, but you input_length is only 163. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=81)\n",
      "Your max_length is set to 256, but you input_length is only 202. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=101)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last Article She tweeted that the clothes would be \"archived & expertly cared for in the spirit & love of Michael Jackson, his bravery, & fans worldwide\". The auction included a jacket worn during Jackson's Bad tour, that went for $240,000 (£148,000) and two crystal gloves. The items were all made by designers Dennis Tompkins and Michael Bush. Lady Gaga also tweeted a picture of herself and her bidding paddle at the auction. More than $5m (£3.1m) was raised by the sale, according to LA-based Julien's Auctions. Other items that went under the hammer included jackets from Michael Jackson's Dangerous and Thriller tours and a pair of jeans that went for $50,000 (£31,000). Some of the money raised by the auction is being donated to a guide dogs charity and a hospice in Las Vegas. American costume designers Michael Bush and Dennis Tompkins created thousands of original pieces for Michael Jackson during his career. However, despite Lady Gaga's assurances, some fans expressed their anger online, claiming that Jackson wanted his costumes to end up in a museum. The singer died on 25 June 2009 from an overdose of the powerful anaesthetic propofol. His personal doctor, Conrad Murray, was later found guilty of his involuntary manslaughter and sentenced to four years in jail. Follow @BBCNewsbeat on Twitter\n",
      "Last Reference Summary ['Lady Gaga has bought 55 items at an auction of Michael Jackson costumes in Los Angeles.']\n",
      "Last Candidate Summary ['Lady Gaga has sold more than 100 pieces of clothing at an auction in Las Vegas.']\n",
      "rouge1 average : 0.32314773160661303\n",
      "rouge2 average : 0.10284455778759283\n",
      "rougeL average : 0.24857874693267637\n",
      "rougeLs average : 0.24857874693267637\n",
      "chrf average : 28.11065337271046\n"
     ]
    }
   ],
   "source": [
    "bart_scores(summarizer, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1799676d",
   "metadata": {},
   "source": [
    "**All Categories: Model 3 (using one of the best models above, changing the hyperparamters) THIS IS THE BEST OVERALL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f4219e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer = pipeline(\"summarization\", model=\"arisanguyen/finetuned-BART-all-categories\", revision = \"model_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0bd3c231",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 256, but you input_length is only 172. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=86)\n",
      "Your max_length is set to 256, but you input_length is only 123. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=61)\n",
      "Your max_length is set to 256, but you input_length is only 221. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=110)\n",
      "Your max_length is set to 256, but you input_length is only 255. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=127)\n",
      "Your max_length is set to 256, but you input_length is only 56. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=28)\n",
      "Your max_length is set to 256, but you input_length is only 151. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=75)\n",
      "Your max_length is set to 256, but you input_length is only 220. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=110)\n",
      "Your max_length is set to 256, but you input_length is only 219. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=109)\n",
      "Your max_length is set to 256, but you input_length is only 191. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=95)\n",
      "Your max_length is set to 256, but you input_length is only 240. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=120)\n",
      "Your max_length is set to 256, but you input_length is only 212. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=106)\n",
      "Your max_length is set to 256, but you input_length is only 227. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=113)\n",
      "Your max_length is set to 256, but you input_length is only 80. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=40)\n",
      "Your max_length is set to 256, but you input_length is only 163. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=81)\n",
      "Your max_length is set to 256, but you input_length is only 202. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=101)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last Article She tweeted that the clothes would be \"archived & expertly cared for in the spirit & love of Michael Jackson, his bravery, & fans worldwide\". The auction included a jacket worn during Jackson's Bad tour, that went for $240,000 (£148,000) and two crystal gloves. The items were all made by designers Dennis Tompkins and Michael Bush. Lady Gaga also tweeted a picture of herself and her bidding paddle at the auction. More than $5m (£3.1m) was raised by the sale, according to LA-based Julien's Auctions. Other items that went under the hammer included jackets from Michael Jackson's Dangerous and Thriller tours and a pair of jeans that went for $50,000 (£31,000). Some of the money raised by the auction is being donated to a guide dogs charity and a hospice in Las Vegas. American costume designers Michael Bush and Dennis Tompkins created thousands of original pieces for Michael Jackson during his career. However, despite Lady Gaga's assurances, some fans expressed their anger online, claiming that Jackson wanted his costumes to end up in a museum. The singer died on 25 June 2009 from an overdose of the powerful anaesthetic propofol. His personal doctor, Conrad Murray, was later found guilty of his involuntary manslaughter and sentenced to four years in jail. Follow @BBCNewsbeat on Twitter\n",
      "Last Reference Summary ['Lady Gaga has bought 55 items at an auction of Michael Jackson costumes in Los Angeles.']\n",
      "Last Candidate Summary ['Lady Gaga has sold more than 100 pieces of clothing at an auction in Las Vegas.']\n",
      "rouge1 average : 0.3376935100553818\n",
      "rouge2 average : 0.11338485717992809\n",
      "rougeL average : 0.26158516350143535\n",
      "rougeLs average : 0.26158516350143535\n",
      "chrf average : 29.11464182430708\n"
     ]
    }
   ],
   "source": [
    "bart_scores(summarizer, df, do_sample = True, num_beams = 4, top_k = 75)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbfafa8",
   "metadata": {},
   "source": [
    "**Testing best model from experiments above**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5284696d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "summarizer = pipeline(\"summarization\", model=\"arisanguyen/finetuned-BART-all-categories\", revision = \"model_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31d79f2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 256, but you input_length is only 86. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=43)\n",
      "Your max_length is set to 256, but you input_length is only 92. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=46)\n",
      "Your max_length is set to 256, but you input_length is only 193. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=96)\n",
      "Your max_length is set to 256, but you input_length is only 254. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=127)\n",
      "Your max_length is set to 256, but you input_length is only 187. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=93)\n",
      "Your max_length is set to 256, but you input_length is only 226. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=113)\n",
      "Your max_length is set to 256, but you input_length is only 178. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=89)\n",
      "Your max_length is set to 256, but you input_length is only 224. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=112)\n",
      "Your max_length is set to 256, but you input_length is only 182. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=91)\n",
      "Your max_length is set to 256, but you input_length is only 198. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=99)\n",
      "Your max_length is set to 256, but you input_length is only 173. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=86)\n",
      "Your max_length is set to 256, but you input_length is only 209. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=104)\n",
      "Your max_length is set to 256, but you input_length is only 70. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=35)\n",
      "Your max_length is set to 256, but you input_length is only 251. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=125)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last Article By Alice EvansBBC News 1. Value for money For the men's World Cup last summer, your pockets had to be bulging with Russian roubles if you wanted a chance to see football come home (or not) with your own eyes. The best seats in the house for the France v Croatia men's final cost an eye-watering 66,000 roubles (£824.44). But don't despair. If you don't have a spare 800 quid jangling around, it's still possible for you to go to a World Cup final. The most expensive seats in the women's final at the Stade de Lyon on 7 July are more than 10 times cheaper than in the men's tournament at £75.12 (84EUR). At the Women's World Cup in France this year, you can actually watch a game for as little as £8.05 (9EUR). C'est magnifique, non? This pricing imbalance manifests itself in merchandise, too. Perhaps to Nike's credit, the official shirts of the men's and women's World Cups both cost £89.95. However, while it is free to add the name of a Lioness to the women's shirt, it costs £13 to splash names such as Kane, Rashford or Vardy across your shoulders. Nike hasn't responded to a request for clarification on why this is the case. 2. More goals The stats speak for themselves on this one. For a start, Brazilian women's forward Marta is the all-time World Cup top scorer for both men and women, with 17 goals to her name across 19 matches. So far in this year's tournament the women have scored 2.69 goals per game - just edging out the men, who scored 2.64 goals per game in last year's World Cup. The women are even further ahead in the top leagues. Over the last three seasons of the Women's Super League there were 3.05 goals per match, compared with a measly 2.76 goals in the men's top tournament, the Premier League. 3. Women stick to the rules We're not saying women are angels on the pitch (in fact, Cameroon were described as quite the opposite when they played England on Sunday). But they break the rules less often than men do. Fifa didn't provide stats for bookings in World Cup games, but we did manage to pull some together from data provided by Opta Sports for the FA, which runs England's top league games. It turns out, in the 2018-19 season, Premier League players (men) were three times more likely than players in the Women's Super League to be sent off in matches. Men were also handed yellow cards twice as often. Over the last three seasons, there were 3,777 yellow cards given to Premier League players - a rate of 3.3 per game - compared with 399 given to Women's Super League players (1.5 per game). Janie Frampton, who has refereed both men's and women's international matches in her 30-year career, said the \"streak of cheating\" that so many top male players express is in part down to \"far too much money and far too many big egos\". However, the data from the Football Association (FA) also suggests the amount of yellow cards given for fouls per women's match is creeping up. It went from 1.3 per game in 2016-17 to 1.5 in the following year and 1.6 last season. Frampton believes an increase in rule-breaking is inevitable as women's football becomes more popular. \"The women's game is becoming far more professional, and by that happening, the skill factor, the determination and challenge of the game is getting much higher,\" she said. \"Women's football has become far more important, and that's going to bring the more competitive edge, which is going to bring tougher challenges and more cards,\" she added. So if the upward trend continues, it won't be long until the women are making Zinedine Zidane's head-butt look like an Eskimo kiss. Only kidding. There's no way you can make that infamous moment look any less brutal. 4. Global competition Men's World Cup winners have only ever come from eight countries across two continents - Europe and South America. There have been four times as many men's World Cups as women's, but the women's tournament has already produced four countries as winners from North America, Europe and Asia. The greater number of teams with a genuine chance to lift that treasured golden trophy arguably makes the women's game all the more exciting. 5. LGBT+ support It's a widely accepted shame that there is not one openly gay footballer in the Premier League. In 1990, former England Under-21 international Justin Fashanu was the first professional footballer in Britain to come out as gay. The ex-Aston Villa midfielder Thomas Hitzlsperger, who came out following his retirement in 2014, said there is a \"long way to go\" before men come out while playing in a top league. By contrast, the women's game is considered far more inclusive. When ex-England player Casey Stoney spoke out about being gay for the first time just months after Hitzlsperger, she said homosexuality was more accepted in the women's game. And West Ham United women's captain Gilly Flaherty said last season: \"Everyone has accepted me for who I am. Women's football is a sport where a player can be openly gay and no one acts any differently towards you because of it, which is a great thing.\" The better levels of tolerance and acceptance in the women's game could be partly thanks to pioneer, Lily Parr. The 6ft chain-smoker - whose wages from Dick, Kerr Ladies FC, were reputedly supplemented by packets of Woodbine cigarettes - was gay, although some dispute how open she was about this. Parr paved the way for English women's footballing success and was the first woman to feature in the National Football Museum's Hall of Fame. Are England women better than men? In the last three Women's World Cups, England came third once and got into the final eight twice. The men finished fourth in 2018, were knocked out of the group stages in 2014 and made the final 16 in 2010. The stats behind these results show an almost identical track record. In 2018 England men scored 12 goals in seven matches, while the women scored 10 in seven matches in the 2015 tournament. Both teams received a total of eight yellow cards. The men conceded eight goals while the women conceded seven. It might be too tough to call which is the better team for now, but the women have everything to prove when they face Norway in the quarter-finals on Thursday. Watch this space - perhaps we'll be singing \"three Lionesses on a shirt\" and naming train stations after Phil Neville before the summer's over.\n",
      "Last Reference Summary [\"The widespread coverage and high drama of the Fifa Women's World Cup has sparked football fever across the UK, with a record-breaking 6.9 million people watching England's most recent clash. There were still far more people watching men's World Cup matches, with 26.5 million viewers tuning in to see England knocked out last year. But there are some ways women's football is hitting the back of the net - while the male strand of the sometimes-beautiful game bounces disappointingly off the crossbar.\"]\n",
      "Last Candidate Summary [\"Women's World Cup tickets are more expensive than men's and men's World Cups.\"]\n",
      "rouge1 average : 0.30108404437301606\n",
      "rouge2 average : 0.0965466726052213\n",
      "rougeL average : 0.22728172530200644\n",
      "rougeLs average : 0.22728172530200644\n",
      "chrf average : 27.31116550968596\n"
     ]
    }
   ],
   "source": [
    "bart_scores(summarizer, dft, do_sample = True, num_beams = 4, top_k = 75)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86c7dcd",
   "metadata": {},
   "source": [
    "**Testing Technology Only Using Best Model from Above**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9b5d5da2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "731de272",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('w266_project/Datasets/xl_sum_sample_test_technology.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "5f51b2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer = pipeline(\"summarization\", model=\"arisanguyen/finetuned-BART-all-categories\", revision = \"model_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a50b4724",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/w266/lib/python3.8/site-packages/transformers/generation/utils.py:1219: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n",
      "Your max_length is set to 256, but you input_length is only 187. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=93)\n",
      "Your max_length is set to 256, but you input_length is only 175. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=87)\n",
      "Your max_length is set to 256, but you input_length is only 217. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=108)\n",
      "Your max_length is set to 256, but you input_length is only 244. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=122)\n",
      "Your max_length is set to 256, but you input_length is only 234. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=117)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last Article She tweeted that the clothes would be \"archived & expertly cared for in the spirit & love of Michael Jackson, his bravery, & fans worldwide\". The auction included a jacket worn during Jackson's Bad tour, that went for $240,000 (£148,000) and two crystal gloves. The items were all made by designers Dennis Tompkins and Michael Bush. Lady Gaga also tweeted a picture of herself and her bidding paddle at the auction. More than $5m (£3.1m) was raised by the sale, according to LA-based Julien's Auctions. Other items that went under the hammer included jackets from Michael Jackson's Dangerous and Thriller tours and a pair of jeans that went for $50,000 (£31,000). Some of the money raised by the auction is being donated to a guide dogs charity and a hospice in Las Vegas. American costume designers Michael Bush and Dennis Tompkins created thousands of original pieces for Michael Jackson during his career. However, despite Lady Gaga's assurances, some fans expressed their anger online, claiming that Jackson wanted his costumes to end up in a museum. The singer died on 25 June 2009 from an overdose of the powerful anaesthetic propofol. His personal doctor, Conrad Murray, was later found guilty of his involuntary manslaughter and sentenced to four years in jail. Follow @BBCNewsbeat on Twitter\n",
      "Last Reference Summary ['It has a good claim to being the most daring and innovative technology company of the last 20 years. It has launched at least two world-changing businesses - an online retailer of breathtaking scale and efficiency and a cloud computing service that has changed the way thousands of businesses work. But why on Earth is Amazon launching another Kindle, and who on Earth is going to pay £270 for it?']\n",
      "Last Candidate Summary [\"Amazon's new e-reader, the Kindle Oasis, is more than just a thing of beauty.\"]\n",
      "rouge1 average : 0.2916408543118181\n",
      "rouge2 average : 0.08903048836381396\n",
      "rougeL average : 0.23257909717097885\n",
      "rougeLs average : 0.23257909717097885\n",
      "chrf average : 27.827404168154025\n"
     ]
    }
   ],
   "source": [
    "bart_scores(summarizer, df_test, do_sample = True, num_beams = 4, top_k = 75)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
