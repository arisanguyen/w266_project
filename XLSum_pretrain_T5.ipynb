{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YS9mJeu74l3"
      },
      "source": [
        "To save in google drive"
      ],
      "id": "7YS9mJeu74l3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJNi3yS_74Gx"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "id": "iJNi3yS_74Gx"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0d870553"
      },
      "source": [
        "**Packages**"
      ],
      "id": "0d870553"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BnAggqyOCae4"
      },
      "outputs": [],
      "source": [
        "! pip install datasets --quiet\n",
        "! pip install evaluate --quiet\n",
        "! pip install rouge_score --quiet\n",
        "! pip install transformers --quiet\n",
        "! pip install -q sentencepiece --quiet\n",
        "! pip install summarizer"
      ],
      "id": "BnAggqyOCae4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dacdaf3d"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "from datasets import load_dataset\n",
        "import evaluate\n",
        "\n",
        "#let's make longer output readable without horizontal scrolling\n",
        "from pprint import pprint"
      ],
      "id": "dacdaf3d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5f29e293"
      },
      "source": [
        "**Necessary Functions**"
      ],
      "id": "5f29e293"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0f96edd6"
      },
      "outputs": [],
      "source": [
        "rouge = evaluate.load('rouge')"
      ],
      "id": "0f96edd6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "586a6d00"
      },
      "source": [
        "**Data**"
      ],
      "id": "586a6d00"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ec6c665e"
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset(\"csebuetnlp/xlsum\", \"english\")"
      ],
      "id": "ec6c665e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "111f7985"
      },
      "outputs": [],
      "source": [
        "# EDA\n",
        "len(dataset['train'])"
      ],
      "id": "111f7985"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5f538fd8"
      },
      "outputs": [],
      "source": [
        "# EDA\n",
        "dataset['train'][1]"
      ],
      "id": "5f538fd8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6656d7bc"
      },
      "outputs": [],
      "source": [
        "# category = []\n",
        "title = []\n",
        "article = []\n",
        "summary = []\n",
        "\n",
        "for data in dataset['train']:\n",
        "    title.append(data['title']) \n",
        "    article.append(data['text'])\n",
        "    summary.append(data['summary'])"
      ],
      "id": "6656d7bc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "66def3a2"
      },
      "outputs": [],
      "source": [
        "d = {'title': title, 'article': article, 'summary': summary}\n",
        "df = pd.DataFrame(data=d)\n",
        "df.head(5)"
      ],
      "id": "66def3a2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnOdIJ2P_lV_"
      },
      "source": [
        "Get a sample for training"
      ],
      "id": "hnOdIJ2P_lV_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6tm182tu_n_O"
      },
      "outputs": [],
      "source": [
        "df = df.sample(n=1000)"
      ],
      "id": "6tm182tu_n_O"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06a0a517"
      },
      "source": [
        "**Baseline**"
      ],
      "id": "06a0a517"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c151fd43"
      },
      "outputs": [],
      "source": [
        "base_r1 = []\n",
        "base_r2 = []\n",
        "base_rL = []\n",
        "base_rLs = []\n",
        "\n",
        "for i in df.index:\n",
        "\n",
        "    string = df['article'][i].replace('...', '. ')\n",
        "    \n",
        "    # first three sentences \n",
        "    candidate = \". \".join(string.split('. ')[0:3]) + \".\"\n",
        "    candidate = [candidate]\n",
        "    \n",
        "    ref = [df['summary'][i]]\n",
        "    \n",
        "    results = rouge.compute(predictions=candidate,\n",
        "                            references= ref)\n",
        "    \n",
        "    base_r1.append(results['rouge1'])\n",
        "    base_r2.append(results['rouge2'])\n",
        "    base_rL.append(results['rougeL'])\n",
        "    base_rLs.append(results['rougeLsum'])"
      ],
      "id": "c151fd43"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "888889b5"
      },
      "outputs": [],
      "source": [
        "print('rouge1 average: ', np.mean(base_r1))\n",
        "print('rouge2 average: ', np.mean(base_r2))\n",
        "print('rougeL average: ', np.mean(base_rL))\n",
        "print('rougeLs average:', np.mean(base_rLs))"
      ],
      "id": "888889b5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5b4352f7"
      },
      "source": [
        "**T5**"
      ],
      "id": "5b4352f7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ccdd1faf",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "from transformers import T5Tokenizer, TFT5ForConditionalGeneration\n",
        "\n",
        "t5model = TFT5ForConditionalGeneration.from_pretrained(\"t5-base\")\n",
        "t5tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")"
      ],
      "id": "ccdd1faf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8NBlaSiwJ_wz"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)"
      ],
      "id": "8NBlaSiwJ_wz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kDtfi6sbKuoq"
      },
      "outputs": [],
      "source": [
        "input_ids = None\n",
        "for i in df.index:\n",
        "    encoded = t5tokenizer.encode_plus(df['article'][i], return_tensors='tf')\n",
        "    if input_ids is None:\n",
        "        input_ids = encoded['input_ids']\n",
        "    else:\n",
        "        input_ids = tf.concat([input_ids, encoded['input_ids']], axis=1)"
      ],
      "id": "kDtfi6sbKuoq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGfaHQoKKyiO"
      },
      "outputs": [],
      "source": [
        "num_epochs = 100"
      ],
      "id": "hGfaHQoKKyiO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7FhY34kKa5B"
      },
      "outputs": [],
      "source": [
        "for epoch in range(num_epochs):\n",
        "    with tf.GradientTape() as tape:\n",
        "        outputs = t5model(input_ids=input_ids)\n",
        "        logits = outputs.inputs\n",
        "        loss = loss_fn(input_ids, logits)\n",
        "    gradients = tape.gradient(loss, t5model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, t5model.trainable_variables))"
      ],
      "id": "i7FhY34kKa5B"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### T5 - summarize on val\n",
        "###### This needs to be edited to actually run on the val set"
      ],
      "metadata": {
        "id": "VVb-v6LYqsSb"
      },
      "id": "VVb-v6LYqsSb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "944f6c88",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "t5_r1 = []\n",
        "t5_r2 = []\n",
        "t5_rL = []\n",
        "t5_rLs = []\n",
        "\n",
        "for i in df.index:\n",
        "\n",
        "    T5ARTICLE_TO_SUMMARIZE = 'summarize: ' + df['article'][i]\n",
        "\n",
        "    inputs = t5tokenizer(T5ARTICLE_TO_SUMMARIZE, \n",
        "                         #max_length=1024, \n",
        "                         truncation=True, \n",
        "                         return_tensors=\"tf\")\n",
        "\n",
        "    summary_ids = t5model.generate(inputs[\"input_ids\"], \n",
        "                                  # ADD HYPER PARAMETERS HERE \n",
        "                                    num_beams = 4,\n",
        "                                    no_repeat_ngram_size = 3,  \n",
        "                                    min_length = 10\n",
        "                                  )\n",
        "    \n",
        "    candidate = t5tokenizer.batch_decode(summary_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
        "    #pprint(candidate[0], compact=True)\n",
        "    \n",
        "    ref = [df['summary'][i]]\n",
        "    \n",
        "    results = rouge.compute(predictions=candidate,\n",
        "                            references=ref)\n",
        "    \n",
        "    t5_r1.append(results['rouge1'])\n",
        "    t5_r2.append(results['rouge2'])\n",
        "    t5_rL.append(results['rougeL'])\n",
        "    t5_rLs.append(results['rougeLsum'])\n",
        "    \n",
        "    if i in np.arange(0, 2200, 100):\n",
        "        data = {'rouge1': t5_r1, 'rouge2': t5_r2, 'rogueL': t5_rL, 'rogueLs': t5_rLs}\n",
        "        scores = pd.DataFrame(data)\n",
        "        scores.to_csv(r'T5_scores.csv', index=False)\n",
        "        print(i)"
      ],
      "id": "944f6c88"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6b7675aa"
      },
      "outputs": [],
      "source": [
        "print('rouge1 average :', np.mean(t5_r1))\n",
        "print('rouge2 average :', np.mean(t5_r2))\n",
        "print('rougeL average :', np.mean(t5_rL))\n",
        "print('rougeLs average :', np.mean(t5_rLs))"
      ],
      "id": "6b7675aa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8f0c0297-db1d-4c41-86b3-3ebb8829bf20"
      },
      "outputs": [],
      "source": [
        "data = {'rouge1': t5_r1, 'rouge2': t5_r2, 'rogueL': t5_rL, 'rogueLs': t5_rLs}\n",
        "\n",
        "scores = pd.DataFrame(data)\n",
        "\n",
        "scores.to_csv(r'/content/drive/MyDrive/W266FinalProject/T5_scores_hyps.csv', index=False)"
      ],
      "id": "8f0c0297-db1d-4c41-86b3-3ebb8829bf20"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}